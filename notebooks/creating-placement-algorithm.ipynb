{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWa0BvJHEdDb"
      },
      "source": [
        "# Creating a Placement Algorithm\n",
        "\n",
        "This tutorial demonstrates how we can create a simple placement algorithm on EdgeSimPy.\n",
        "\n",
        "Let's start by importing the EdgeSimPy modules:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EdgeSimPy Import Debugging Script\n",
        "\n",
        "# Explicit dependency installation\n",
        "\n",
        "!pip install tqdm\n",
        "!pip install numpy rich\n",
        "!pip install rich\n",
        "!pip install rich --upgrade\n",
        "!pip install networkx==2.6.2\n",
        "!pip install matplotlib pandas numpy\n",
        "!pip install git+https://github.com/EdgeSimPy/EdgeSimPy.git@v1.1.0\n",
        "\n",
        "# Python and package information\n",
        "!python --version\n",
        "!pip list | grep -E \"networkx|edge_sim_py\"\n",
        "\n",
        "# Comprehensive import and debugging script\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "def print_module_structure(module_name):\n",
        "    \"\"\"\n",
        "    Recursively print the structure of a module\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Module Structure for {module_name} ---\")\n",
        "    try:\n",
        "        # Import the module\n",
        "        module = importlib.import_module(module_name)\n",
        "\n",
        "        # Get the module's file path\n",
        "        module_file = getattr(module, '__file__', 'No __file__ attribute')\n",
        "        print(f\"Module file path: {module_file}\")\n",
        "\n",
        "        # Get the module's directory\n",
        "        module_dir = os.path.dirname(module_file) if hasattr(module, '__file__') else 'Unknown'\n",
        "        print(f\"Module directory: {module_dir}\")\n",
        "\n",
        "        # List all attributes and their types\n",
        "        print(\"\\nModule Contents:\")\n",
        "        for attr_name in dir(module):\n",
        "            try:\n",
        "                attr = getattr(module, attr_name)\n",
        "                print(f\"  {attr_name}: {type(attr)}\")\n",
        "            except Exception as attr_err:\n",
        "                print(f\"  {attr_name}: Could not retrieve (Error: {attr_err})\")\n",
        "\n",
        "        # List files in the module directory\n",
        "        if os.path.isdir(module_dir):\n",
        "            print(\"\\nFiles in module directory:\")\n",
        "            try:\n",
        "                for item in os.listdir(module_dir):\n",
        "                    print(f\"  {item}\")\n",
        "            except Exception as list_err:\n",
        "                print(f\"  Could not list directory contents: {list_err}\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"Could not import {module_name}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error examining {module_name}: {e}\")\n",
        "\n",
        "# Print Python path and sys.path for debugging\n",
        "print(\"--- Python Path ---\")\n",
        "print(sys.path)\n",
        "\n",
        "# Attempt to import and examine EdgeSimPy\n",
        "print_module_structure('edge_sim_py')\n",
        "\n",
        "# Attempt alternative import methods\n",
        "print(\"\\n--- Alternative Import Attempts ---\")\n",
        "import_attempts = [\n",
        "    'edge_sim_py',\n",
        "    'edge_sim_py.core',\n",
        "    'edge_sim_py.components',\n",
        "    'edge_sim_py.device',\n",
        "    'edge_sim_py.server'\n",
        "]\n",
        "\n",
        "for attempt in import_attempts:\n",
        "    print(f\"\\nTrying to import {attempt}\")\n",
        "    try:\n",
        "        module = importlib.import_module(attempt)\n",
        "        print(f\"Successfully imported {attempt}\")\n",
        "        print(f\"Module file: {getattr(module, '__file__', 'No file attribute')}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"Import failed: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# List installed packages with their paths\n",
        "print(\"\\n--- Installed Packages Paths ---\")\n",
        "for package_name in ['edge_sim_py', 'networkx', 'numpy', 'pandas']:\n",
        "    try:\n",
        "        package = importlib.import_module(package_name)\n",
        "        print(f\"{package_name}: {package.__file__}\")\n",
        "    except ImportError:\n",
        "        print(f\"{package_name}: Not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"{package_name}: Error - {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90E_iTShFiLr",
        "outputId": "d81d6363-b07c-4d95-9a00-4cb54bb1f505"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Collecting networkx==2.6.2\n",
            "  Downloading networkx-2.6.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading networkx-2.6.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.6.2 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.6.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-2.6.2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting git+https://github.com/EdgeSimPy/EdgeSimPy.git@v1.1.0\n",
            "  Cloning https://github.com/EdgeSimPy/EdgeSimPy.git (to revision v1.1.0) to /tmp/pip-req-build-796_ytvq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EdgeSimPy/EdgeSimPy.git /tmp/pip-req-build-796_ytvq\n",
            "  Running command git checkout -q 5ea400b39390490b25dabf8be711fe559cb2cbff\n",
            "  Resolved https://github.com/EdgeSimPy/EdgeSimPy.git to commit 5ea400b39390490b25dabf8be711fe559cb2cbff\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Mesa<2.0.0,>=1.0.0 (from edge_sim_py==1.1.0)\n",
            "  Downloading Mesa-1.2.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from edge_sim_py==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: networkx==2.6.2 in /usr/local/lib/python3.11/dist-packages (from edge_sim_py==1.1.0) (2.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (8.1.8)\n",
            "Collecting cookiecutter (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading cookiecutter-2.6.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.2.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (6.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (4.67.1)\n",
            "Collecting binaryornot>=0.4.4 (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading binaryornot-0.4.4-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.1.5)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (6.0.2)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (8.0.4)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.32.3)\n",
            "Collecting arrow (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (13.9.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2025.1)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from binaryornot>=0.4.4->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (5.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify>=4.0.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2025.1.31)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->cookiecutter->Mesa<2.0.0,>=1.0.0->edge_sim_py==1.1.0) (0.1.2)\n",
            "Downloading Mesa-1.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cookiecutter-2.6.0-py3-none-any.whl (39 kB)\n",
            "Downloading binaryornot-0.4.4-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: edge_sim_py\n",
            "  Building wheel for edge_sim_py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for edge_sim_py: filename=edge_sim_py-1.1.0-py3-none-any.whl size=83422 sha256=e80153516a96f9952a533d896963b4874d4f97dcdd7b9f695907f27c06a6e25f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-67iiyzjd/wheels/61/c9/89/e9391d9c3ba4605a52feea00568aa6ad5471dee92dfe375987\n",
            "Successfully built edge_sim_py\n",
            "Installing collected packages: types-python-dateutil, binaryornot, arrow, cookiecutter, Mesa, edge_sim_py\n",
            "Successfully installed Mesa-1.2.1 arrow-1.3.0 binaryornot-0.4.4 cookiecutter-2.6.0 edge_sim_py-1.1.0 types-python-dateutil-2.9.0.20241206\n",
            "Python 3.11.11\n",
            "edge_sim_py                        1.1.0\n",
            "networkx                           2.6.2\n",
            "--- Python Path ---\n",
            "['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython']\n",
            "\n",
            "--- Module Structure for edge_sim_py ---\n",
            "Module file path: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "Module directory: /usr/local/lib/python3.11/dist-packages/edge_sim_py\n",
            "\n",
            "Module Contents:\n",
            "  Application: <class 'type'>\n",
            "  BaseStation: <class 'type'>\n",
            "  CircularDurationAndIntervalAccessPattern: <class 'type'>\n",
            "  ComponentManager: <class 'type'>\n",
            "  ContainerImage: <class 'type'>\n",
            "  ContainerLayer: <class 'type'>\n",
            "  ContainerRegistry: <class 'type'>\n",
            "  ConteratoNetworkPowerModel: <class 'type'>\n",
            "  CubicServerPowerModel: <class 'type'>\n",
            "  EdgeServer: <class 'type'>\n",
            "  LinearServerPowerModel: <class 'type'>\n",
            "  NetworkFlow: <class 'type'>\n",
            "  NetworkLink: <class 'type'>\n",
            "  NetworkSwitch: <class 'type'>\n",
            "  RandomDurationAndIntervalAccessPattern: <class 'type'>\n",
            "  Service: <class 'type'>\n",
            "  Simulator: <class 'type'>\n",
            "  SquareServerPowerModel: <class 'type'>\n",
            "  Topology: <class 'type'>\n",
            "  User: <class 'type'>\n",
            "  __builtins__: <class 'dict'>\n",
            "  __cached__: <class 'str'>\n",
            "  __doc__: <class 'str'>\n",
            "  __file__: <class 'str'>\n",
            "  __loader__: <class '_frozen_importlib_external.SourceFileLoader'>\n",
            "  __name__: <class 'str'>\n",
            "  __package__: <class 'str'>\n",
            "  __path__: <class 'list'>\n",
            "  __spec__: <class '_frozen_importlib.ModuleSpec'>\n",
            "  __version__: <class 'str'>\n",
            "  activation_schedulers: <class 'module'>\n",
            "  application: <class 'module'>\n",
            "  barabasi_albert: <class 'function'>\n",
            "  base_station: <class 'module'>\n",
            "  best_fit_registries: <class 'function'>\n",
            "  best_fit_services: <class 'function'>\n",
            "  builder_helpers: <class 'module'>\n",
            "  circular_duration_and_interval_access_pattern: <class 'module'>\n",
            "  component_manager: <class 'module'>\n",
            "  components: <class 'module'>\n",
            "  container_image: <class 'module'>\n",
            "  container_layer: <class 'module'>\n",
            "  container_registries: <class 'module'>\n",
            "  container_registry: <class 'module'>\n",
            "  conterato_network_power_model: <class 'module'>\n",
            "  create_container_registries: <class 'function'>\n",
            "  cubic_server_power_model: <class 'module'>\n",
            "  dataset_generator: <class 'module'>\n",
            "  e5430: <class 'function'>\n",
            "  e5507: <class 'function'>\n",
            "  e5645: <class 'function'>\n",
            "  edge_server: <class 'module'>\n",
            "  edge_servers: <class 'module'>\n",
            "  equal_share: <class 'function'>\n",
            "  flow_scheduling: <class 'module'>\n",
            "  hexagonal_grid: <class 'function'>\n",
            "  jetson_nano: <class 'function'>\n",
            "  jetson_tx2: <class 'function'>\n",
            "  linear_server_power_model: <class 'module'>\n",
            "  map: <class 'module'>\n",
            "  max_min_fairness: <class 'function'>\n",
            "  mobility_models: <class 'module'>\n",
            "  network: <class 'module'>\n",
            "  network_flow: <class 'module'>\n",
            "  network_link: <class 'module'>\n",
            "  network_switch: <class 'module'>\n",
            "  network_switches: <class 'module'>\n",
            "  network_topologies: <class 'module'>\n",
            "  partially_connected_hexagonal_mesh: <class 'function'>\n",
            "  pathway: <class 'function'>\n",
            "  placement: <class 'module'>\n",
            "  power_models: <class 'module'>\n",
            "  provision_container_registry: <class 'function'>\n",
            "  quadratic_grid: <class 'function'>\n",
            "  random_duration_and_interval_access_pattern: <class 'module'>\n",
            "  random_fit_registries: <class 'function'>\n",
            "  random_fit_services: <class 'function'>\n",
            "  random_mobility: <class 'function'>\n",
            "  raspberry_pi4: <class 'function'>\n",
            "  sample_switch: <class 'function'>\n",
            "  servers: <class 'module'>\n",
            "  service: <class 'module'>\n",
            "  services: <class 'module'>\n",
            "  simulator: <class 'module'>\n",
            "  square_server_power_model: <class 'module'>\n",
            "  topology: <class 'module'>\n",
            "  user: <class 'module'>\n",
            "  user_access_patterns: <class 'module'>\n",
            "  worst_fit_registries: <class 'function'>\n",
            "  worst_fit_services: <class 'function'>\n",
            "\n",
            "Files in module directory:\n",
            "  activation_schedulers\n",
            "  component_manager.py\n",
            "  dataset_generator\n",
            "  __pycache__\n",
            "  components\n",
            "  simulator.py\n",
            "  __init__.py\n",
            "\n",
            "--- Alternative Import Attempts ---\n",
            "\n",
            "Trying to import edge_sim_py\n",
            "Successfully imported edge_sim_py\n",
            "Module file: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "\n",
            "Trying to import edge_sim_py.core\n",
            "Import failed: No module named 'edge_sim_py.core'\n",
            "\n",
            "Trying to import edge_sim_py.components\n",
            "Successfully imported edge_sim_py.components\n",
            "Module file: /usr/local/lib/python3.11/dist-packages/edge_sim_py/components/__init__.py\n",
            "\n",
            "Trying to import edge_sim_py.device\n",
            "Import failed: No module named 'edge_sim_py.device'\n",
            "\n",
            "Trying to import edge_sim_py.server\n",
            "Import failed: No module named 'edge_sim_py.server'\n",
            "\n",
            "--- Installed Packages Paths ---\n",
            "edge_sim_py: /usr/local/lib/python3.11/dist-packages/edge_sim_py/__init__.py\n",
            "networkx: /usr/local/lib/python3.11/dist-packages/networkx/__init__.py\n",
            "numpy: /usr/local/lib/python3.11/dist-packages/numpy/__init__.py\n",
            "pandas: /usr/local/lib/python3.11/dist-packages/pandas/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OekA2N9EdDe"
      },
      "source": [
        "## Implementing the Placement Algorithm\n",
        "\n",
        "In this example, we are going to create a simple placement algorithm that works according to the well-known First-Fit heuristic. In a nutshell, our algorithm will provision each service to the first edge server with available resources to host them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMjHk8QGEdDf"
      },
      "outputs": [],
      "source": [
        "def my_algorithm(parameters):\n",
        "    # We can always call the 'all()' method to get a list with all created instances of a given class\n",
        "    for service in Service.all():\n",
        "        # We don't want to migrate services are are already being migrated\n",
        "        if service.server == None and not service.being_provisioned:\n",
        "\n",
        "            # Let's iterate over the list of edge servers to find a suitable host for our service\n",
        "            for edge_server in EdgeServer.all():\n",
        "\n",
        "                # We must check if the edge server has enough resources to host the service\n",
        "                if edge_server.has_capacity_to_host(service=service):\n",
        "\n",
        "                    # Start provisioning the service in the edge server\n",
        "                    service.provision(target_server=edge_server)\n",
        "\n",
        "                    # After start migrating the service we can move on to the next service\n",
        "                    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-cM8aGFEdDf"
      },
      "source": [
        "## Running the Simulation\n",
        "\n",
        "As we're creating a placement algorithm, we must instruct EdgeSimPy that it needs to continue the simulation until all services are provisioned within the infrastructure.\n",
        "\n",
        "To do so, let's create a simple function that will be used as the simulation's stopping criterion. EdgeSimPy will run that function at the end of each time step, halting the simulation as soon as it returns `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Tl2gzLhEdDf"
      },
      "outputs": [],
      "source": [
        "def stopping_criterion(model: object):\n",
        "    # Defining a variable that will help us to count the number of services successfully provisioned within the infrastructure\n",
        "    provisioned_services = 0\n",
        "\n",
        "    # Iterating over the list of services to count the number of services provisioned within the infrastructure\n",
        "    for service in Service.all():\n",
        "\n",
        "        # Initially, services are not hosted by any server (i.e., their \"server\" attribute is None).\n",
        "        # Once that value changes, we know that it has been successfully provisioned inside an edge server.\n",
        "        if service.server != None:\n",
        "            provisioned_services += 1\n",
        "\n",
        "    # As EdgeSimPy will halt the simulation whenever this function returns True, its output will be a boolean expression\n",
        "    # that checks if the number of provisioned services equals to the number of services spawned in our simulation\n",
        "    return provisioned_services == Service.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab Setup for FCFS Task Processing\n",
        "\n"
      ],
      "metadata": {
        "id": "eAhUsANCM7I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab Setup for FCFS Task Processing\n",
        "\n",
        "# Install required libraries\n",
        "!pip install numpy\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List files in the task sets directory\n",
        "import os\n",
        "task_sets_dir = '/content/drive/My Drive/FCFS_Task_Sets/'\n",
        "print(\"Available task set files:\")\n",
        "for filename in os.listdir(task_sets_dir):\n",
        "    print(filename)\n",
        "\n",
        "# Note: After running this, copy the full path of the desired JSON file\n",
        "# and use it in the main FCFS scheduler script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "58DabUIvM_9q",
        "outputId": "3634fc84-0615-49ef-e09b-ddb5ca72235e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d903f8878320>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# List files in the task sets directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCFS Algorithm Logic\n"
      ],
      "metadata": {
        "id": "5eHWaH4xIzc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# Configure logging to print to console\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)  # Explicitly add console output\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Print function to ensure output\n",
        "def print_to_console(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Wrapper function to ensure printing\n",
        "    \"\"\"\n",
        "    print(*args, **kwargs)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "        self.task_class = self.details.get('task_class', 'generic')\n",
        "        self.cpu_intensity = self.details.get('cpu_intensity', 'medium')\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with enhanced tracking and visualization\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "\n",
        "    def process_queue(self, current_time: float):\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking\n",
        "        \"\"\"\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            processing_result = task.process(self.cpu_rating)\n",
        "\n",
        "            # Detailed task processing output\n",
        "            self._log_task_processing(task, processing_result)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "        # If resource has available capacity, move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:  # Limit concurrent tasks\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        return len(self.current_tasks)\n",
        "\n",
        "    def _log_task_processing(self, task: Task, processing_result: Dict):\n",
        "        \"\"\"\n",
        "        Log detailed task processing information\n",
        "        \"\"\"\n",
        "        print_to_console(\n",
        "            f\"Resource {self.id} ({self.type}) - \"\n",
        "            f\"Task {task.id} ({task.task_name}): \"\n",
        "            f\"Processed {processing_result['processed']:.2f} MI, \"\n",
        "            f\"Remaining {processing_result['remaining']:.2f} MI, \"\n",
        "            f\"Completion: {processing_result['completion_percentage']:.2f}%\"\n",
        "        )\n",
        "\n",
        "class AdvancedFCFSScheduler:\n",
        "    \"\"\"\n",
        "    Advanced First-Come-First-Serve Scheduler with Real-Time Visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_time = 0\n",
        "\n",
        "        # Metrics tracking with enhanced details\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'queued_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'resource_utilization': {},\n",
        "            'average_wait_time': 0,\n",
        "            'max_wait_time': 0\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks from JSON with comprehensive parsing\n",
        "        \"\"\"\n",
        "        print_to_console(f\"Attempting to load tasks from: {json_path}\")\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),  # Default 10 MB\n",
        "                cpu_required=task_dict.get('instructions', 50000),  # Default 50,000 MI\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            task.arrival_time = self.current_time\n",
        "            tasks.append(task)\n",
        "\n",
        "        print_to_console(f\"Loaded {len(tasks)} tasks from JSON\")\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources with advanced visualization\n",
        "        \"\"\"\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin task distribution with visualization\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            # Select resource\n",
        "            resource = self.resources[resource_index]\n",
        "\n",
        "            # Enqueue task\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "\n",
        "            # Cycle through resources\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        # Update metrics\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "        self.metrics['queued_tasks'] = sum(len(resource.task_queue) for resource in self.resources)\n",
        "\n",
        "        # Print initial distribution\n",
        "        print_to_console(\"\\n--- Initial Task Distribution ---\")\n",
        "        for resource_type, count in task_distribution.items():\n",
        "            print_to_console(f\"{resource_type}: {count} tasks\")\n",
        "\n",
        "        print_to_console(\"\\n--- Resource Queue Lengths ---\")\n",
        "        for i, resource in enumerate(self.resources, 1):\n",
        "            print_to_console(f\"Resource {i} ({resource.type}) Queue Length: {len(resource.task_queue)} tasks\")\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 1000):\n",
        "        \"\"\"\n",
        "        Run scheduling simulation with real-time visualization\n",
        "        \"\"\"\n",
        "        # Distribute tasks initially\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Simulation loop with enhanced visualization\n",
        "        start_time = time.time()\n",
        "        for iteration in range(max_iterations):\n",
        "            print_to_console(f\"\\n--- Iteration {iteration} ---\")\n",
        "\n",
        "            # Process queues for all resources\n",
        "            completed_in_iteration = 0\n",
        "            resource_utilization = {}\n",
        "\n",
        "            for resource in self.resources:\n",
        "                # Track resource utilization\n",
        "                initial_completed = len(resource.completed_tasks)\n",
        "                resource.process_queue(self.current_time)\n",
        "                completed_this_resource = len(resource.completed_tasks) - initial_completed\n",
        "                completed_in_iteration += completed_this_resource\n",
        "\n",
        "                # Calculate resource utilization\n",
        "                resource_utilization[resource.type] = {\n",
        "                    'completed_tasks': completed_this_resource,\n",
        "                    'current_tasks': len(resource.current_tasks),\n",
        "                    'queue_length': len(resource.task_queue)\n",
        "                }\n",
        "\n",
        "            # Update metrics\n",
        "            self.metrics['completed_tasks'] = sum(\n",
        "                len(resource.completed_tasks) for resource in self.resources\n",
        "            )\n",
        "            self.metrics['resource_utilization'] = resource_utilization\n",
        "\n",
        "            # Print real-time resource utilization\n",
        "            print_to_console(\"\\n--- Resource Utilization ---\")\n",
        "            for resource_type, stats in resource_utilization.items():\n",
        "                print_to_console(\n",
        "                    f\"{resource_type}: \"\n",
        "                    f\"Completed: {stats['completed_tasks']}, \"\n",
        "                    f\"Current Tasks: {stats['current_tasks']}, \"\n",
        "                    f\"Queue Length: {stats['queue_length']}\"\n",
        "                )\n",
        "\n",
        "            # Check if all tasks are processed\n",
        "            if self.metrics['completed_tasks'] == self.metrics['total_tasks']:\n",
        "                print_to_console(\"\\n--- All Tasks Processed! ---\")\n",
        "                break\n",
        "\n",
        "            # Increment time\n",
        "            self.current_time += 1\n",
        "\n",
        "            # Optional: Add a small delay to simulate real-time processing\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        # Calculate total processing time\n",
        "        total_processing_time = time.time() - start_time\n",
        "        self.metrics['total_processing_time'] = total_processing_time\n",
        "\n",
        "        # Calculate wait time metrics\n",
        "        self.calculate_wait_time_metrics()\n",
        "\n",
        "        return self.metrics\n",
        "\n",
        "    def calculate_wait_time_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive wait time metrics\n",
        "        \"\"\"\n",
        "        all_completed_tasks = []\n",
        "        for resource in self.resources:\n",
        "            all_completed_tasks.extend(resource.completed_tasks)\n",
        "\n",
        "        if all_completed_tasks:\n",
        "            wait_times = [task.wait_time for task in all_completed_tasks]\n",
        "            self.metrics['average_wait_time'] = sum(wait_times) / len(wait_times)\n",
        "            self.metrics['max_wait_time'] = max(wait_times)\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Explicitly set print to console\n",
        "    print = print_to_console\n",
        "\n",
        "    # Create resources matching original configuration\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Print initial resource details\n",
        "    print(\"\\n--- Resource Configurations ---\")\n",
        "    for resource in resources:\n",
        "        print(f\"Resource {resource.id} ({resource.type}):\")\n",
        "        print(f\"  CPU Rating: {resource.cpu_rating} MI/s\")\n",
        "        print(f\"  Memory: {resource.memory} GB\")\n",
        "        print(f\"  Bandwidth: {resource.bandwidth} MB/s\")\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = AdvancedFCFSScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    metrics = scheduler.run_simulation()\n",
        "\n",
        "    # Print final detailed metrics\n",
        "    print(\"\\n--- Final Scheduling Metrics ---\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "\n",
        "    # Detailed resource reporting\n",
        "    print(\"\\n--- Final Resource Status ---\")\n",
        "    for resource in scheduler.resources:\n",
        "        print(f\"\\nResource {resource.id} ({resource.type}):\")\n",
        "        print(f\"Completed Tasks: {len(resource.completed_tasks)}\")\n",
        "        print(f\"Remaining Queue: {len(resource.task_queue)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "collapsed": true,
        "id": "Mt0lGxw0I4Y0",
        "outputId": "7ebd6944-e322-4ae6-b9be-614d43dd944e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resource Configurations ---\n",
            "Resource 1 (Edge_Raspberry_Pi):\n",
            "  CPU Rating: 80000 MI/s\n",
            "  Memory: 1 GB\n",
            "  Bandwidth: 5 MB/s\n",
            "Resource 2 (Edge_Smartphone):\n",
            "  CPU Rating: 400000 MI/s\n",
            "  Memory: 4 GB\n",
            "  Bandwidth: 20 MB/s\n",
            "Resource 3 (Cloud_Host):\n",
            "  CPU Rating: 1000000 MI/s\n",
            "  Memory: 32 GB\n",
            "  Bandwidth: 80 MB/s\n",
            "Attempting to load tasks from: /content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# Print final detailed metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, max_iterations)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Distribute tasks initially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Simulation loop with enhanced visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mdistribute_tasks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mDistribute\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0macross\u001b[0m \u001b[0mresources\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0madvanced\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         tasks = self.load_tasks_from_json(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;34m'/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-9-05ec8868f771>\u001b[0m in \u001b[0;36mload_tasks_from_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mprint_to_console\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to load tasks from: {json_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Rich in FCFS"
      ],
      "metadata": {
        "id": "o9zVR42wVLWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 task_type: str,\n",
        "                 data_size: float,     # in GB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.type = task_type\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = f\"{task_type}_Task_{task_id}\"\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with comprehensive tracking and utilization metrics\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int,     # in MB/s\n",
        "                 num_cpus: int = 1):  # Number of CPUs, defaulting to 1\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # CPU configuration\n",
        "        self.num_cpus = num_cpus\n",
        "        self.available_cpus = num_cpus\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Utilization tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Additional tracking\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "    def can_process_task(self, task: Task) -> bool:\n",
        "        \"\"\"\n",
        "        Check if the resource can process the given task\n",
        "        \"\"\"\n",
        "        # Check if CPUs are available\n",
        "        if self.available_cpus <= 0:\n",
        "            return False\n",
        "\n",
        "        # Cloud host can process all task types\n",
        "        if self.type == \"Cloud_Host\":\n",
        "            return True\n",
        "\n",
        "        # Edge nodes (Raspberry Pi and Smartphone) can only process RT2 tasks\n",
        "        if self.type in [\"Edge_Raspberry_Pi\", \"Edge_Smartphone\"]:\n",
        "            # Explicitly fail RT1 and RT3 tasks on edge resources\n",
        "            if task.type in [\"RT1\", \"RT3\"]:\n",
        "                logger.warning(f\"Task {task.id} of type {task.type} FAILED on {self.type}\")\n",
        "                return False\n",
        "\n",
        "            # Additional memory check for RT2 tasks\n",
        "            if task.data_size > self.total_memory:\n",
        "                logger.warning(f\"Task {task.id} requires {task.data_size} GB, exceeding {self.type}'s memory of {self.total_memory} GB\")\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue if it can be processed\n",
        "        \"\"\"\n",
        "        if self.can_process_task(task):\n",
        "            task.queue_position = len(self.task_queue)\n",
        "            task.arrival_time = time.time()\n",
        "            self.task_queue.append(task)\n",
        "        else:\n",
        "            # Mark task as failed\n",
        "            task.status = 'failed'\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking and utilization update\n",
        "        \"\"\"\n",
        "        # Reset current usage and task tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "        # Reset available CPUs\n",
        "        self.available_cpus = self.num_cpus\n",
        "\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            # Skip if no CPUs available\n",
        "            if self.available_cpus <= 0:\n",
        "                break\n",
        "\n",
        "            # Determine how much CPU can be used for this task\n",
        "            task_cpu = min(self.cpu_rating, task.remaining_cpu)\n",
        "\n",
        "            processing_result = task.process(task_cpu)\n",
        "\n",
        "            # Update CPU usage\n",
        "            processed_amount = processing_result['processed']\n",
        "            self.current_cpu_usage += processed_amount\n",
        "\n",
        "            # Track detailed task information\n",
        "            task_info = {\n",
        "                'id': task.id,\n",
        "                'name': task.task_name,\n",
        "                'type': task.type,\n",
        "                'processed': processed_amount,\n",
        "                'total_required': task.total_cpu_required,\n",
        "                'completion_percentage': processing_result['completion_percentage']\n",
        "            }\n",
        "            self.detailed_task_tracking.append(task_info)\n",
        "\n",
        "            # Calculate task CPU demand\n",
        "            task_demand = processed_amount / self.cpu_rating\n",
        "            self.task_cpu_demands.append(task_demand)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "                # Free up a CPU\n",
        "                self.available_cpus += 1\n",
        "\n",
        "        # Move tasks from queue to current tasks if CPUs are available\n",
        "        while self.task_queue and self.available_cpus > 0:\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "            # Use up a CPU\n",
        "            self.available_cpus -= 1\n",
        "\n",
        "        # Calculate CPU utilization\n",
        "        if self.task_cpu_demands:\n",
        "            cpu_utilization = min(sum(self.task_cpu_demands) * 100, 100)\n",
        "        else:\n",
        "            cpu_utilization = 0\n",
        "\n",
        "        # Estimate memory usage\n",
        "        self.current_memory_usage = len(self.current_tasks) * (self.total_memory / 10)\n",
        "        memory_utilization = min((self.current_memory_usage / self.total_memory) * 100, 100)\n",
        "\n",
        "        # Return detailed resource state with utilization\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'cpu_utilization': cpu_utilization,\n",
        "            'memory_utilization': memory_utilization,\n",
        "            'raw_cpu_usage': self.current_cpu_usage,\n",
        "            'task_demands': self.task_cpu_demands,\n",
        "            'detailed_tasks': self.detailed_task_tracking,\n",
        "            'available_cpus': self.available_cpus\n",
        "        }\n",
        "\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources with 10 Smartphones, 5 Raspberry Pis, and 5 Cloud Hosts\n",
        "    \"\"\"\n",
        "    resources = []\n",
        "\n",
        "    # Create 10 Smartphone Edge Nodes\n",
        "    for i in range(1, 11):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i,\n",
        "                resource_type=f\"Edge_{i}\",\n",
        "                cpu_rating=400000,   # 400,000 MI/s\n",
        "                memory=4,            # 4 GB\n",
        "                bandwidth=20         # 20 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Raspberry Pi Edge Nodes\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+10,  # IDs 11-15\n",
        "                resource_type=f\"Raspberry_{i}\",\n",
        "                cpu_rating=80000,    # 80,000 MI/s\n",
        "                memory=1,            # 1 GB\n",
        "                bandwidth=5          # 5 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Cloud Hosts\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+15,  # IDs 16-20\n",
        "                resource_type=f\"Cloud_{i}\",\n",
        "                cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "                memory=32,           # 32 GB\n",
        "                bandwidth=80         # 80 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return resources\n",
        "\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        self.console = Console()\n",
        "\n",
        "        # Poisson process parameters\n",
        "        self.arrival_rate = 0.8  # λ = 0.8 tasks per second\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'failed_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'makespan': 0,\n",
        "            'throughput': 0\n",
        "        }\n",
        "\n",
        "    def generate_tasks(self, simulation_time: float = 100) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate tasks using Poisson process\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate task arrival times using Poisson process\n",
        "        num_tasks = np.random.poisson(self.arrival_rate * simulation_time)\n",
        "\n",
        "        tasks = []\n",
        "        for i in range(num_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time\n",
        "            task.arrival_time = np.random.uniform(0, simulation_time)\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        return sorted(tasks, key=lambda x: x.arrival_time)\n",
        "\n",
        "    def distribute_tasks(self, total_tasks: int = 1500) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Generate and distribute a fixed number of tasks\n",
        "        \"\"\"\n",
        "        # Task types and their characteristics based on the paper\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"data_size\": 5.0, \"cpu_required\": 2_000_000},   # CPU-intensive, memory-intensive\n",
        "            {\"type\": \"RT2\", \"data_size\": 0.2, \"cpu_required\": 4_000_000},   # CPU-intensive, memory-light\n",
        "            {\"type\": \"RT3\", \"data_size\": 5.0, \"cpu_required\": 200_000},     # CPU-light, memory-intensive\n",
        "            {\"type\": \"RT4\", \"data_size\": 0.5, \"cpu_required\": 500_000}      # CPU-light, memory-light\n",
        "        ]\n",
        "\n",
        "        # Generate tasks\n",
        "        tasks = []\n",
        "        for i in range(total_tasks):\n",
        "            # Randomly select task type\n",
        "            task_type_data = np.random.choice(task_types)\n",
        "\n",
        "            task = Task(\n",
        "                task_id=i+1,\n",
        "                task_type=task_type_data['type'],\n",
        "                data_size=task_type_data['data_size'],\n",
        "                cpu_required=task_type_data['cpu_required']\n",
        "            )\n",
        "\n",
        "            # Set arrival time with uniform distribution\n",
        "            task.arrival_time = np.random.uniform(0, 100)  # Distribute over 100 seconds\n",
        "\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Sort tasks by arrival time\n",
        "        tasks.sort(key=lambda x: x.arrival_time)\n",
        "\n",
        "        # Update metrics\n",
        "        self.metrics['total_tasks'] = total_tasks\n",
        "\n",
        "        # Explicitly select edge, raspberry, and cloud resources\n",
        "        edge_resources = [r for r in self.resources if r.type.startswith(\"Edge_\")]\n",
        "        raspberry_resources = [r for r in self.resources if r.type.startswith(\"Raspberry_\")]\n",
        "        cloud_resources = [r for r in self.resources if r.type.startswith(\"Cloud_\")]\n",
        "\n",
        "        # Define resource order as specified in the paper\n",
        "        # Order: Smartphone, Raspberry Pi, Cloud\n",
        "        resource_order = edge_resources + raspberry_resources + cloud_resources\n",
        "\n",
        "        # Track task distribution and failures\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "        failed_tasks_by_resource = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Circular resource selection\n",
        "        resource_index = 0\n",
        "        num_resources = len(resource_order)\n",
        "\n",
        "        for task in tasks:\n",
        "            # Select resource in the specified order\n",
        "            resource = resource_order[resource_index]\n",
        "\n",
        "            # Attempt to enqueue task\n",
        "            if resource.can_process_task(task):\n",
        "                resource.enqueue_task(task)\n",
        "                task_distribution[resource.type] += 1\n",
        "            else:\n",
        "                # Increment failed tasks for the specific resource type\n",
        "                failed_tasks_by_resource[resource.type] += 1\n",
        "                self.metrics['failed_tasks'] += 1\n",
        "\n",
        "            # Move to next resource in circular manner\n",
        "            resource_index = (resource_index + 1) % num_resources\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        # Print distribution table\n",
        "        distribution_table = Table(title=\"Task Distribution\")\n",
        "        distribution_table.add_column(\"Resource\", style=\"cyan\")\n",
        "        distribution_table.add_column(\"Tasks\", style=\"magenta\")\n",
        "        distribution_table.add_column(\"Failed Tasks\", style=\"red\")\n",
        "\n",
        "        for resource_type in task_distribution:\n",
        "            distribution_table.add_row(\n",
        "                resource_type,\n",
        "                str(task_distribution[resource_type]),\n",
        "                str(failed_tasks_by_resource[resource_type])\n",
        "            )\n",
        "\n",
        "        self.console.print(distribution_table)\n",
        "\n",
        "        return tasks\n",
        "    def run_simulation(self, total_tasks: int = 1500, max_iterations: int = 10000):\n",
        "            \"\"\"\n",
        "            Run simulation with a fixed number of tasks\n",
        "            \"\"\"\n",
        "            # Record start time\n",
        "            self.start_time = time.time()\n",
        "\n",
        "            # Distribute tasks\n",
        "            tasks = self.distribute_tasks(total_tasks)\n",
        "\n",
        "            # Prepare layout for live visualization\n",
        "            layout = Layout()\n",
        "            layout.split_row(\n",
        "                Layout(name=\"resource1\"),\n",
        "                Layout(name=\"resource2\"),\n",
        "                Layout(name=\"resource3\")\n",
        "            )\n",
        "\n",
        "            # Live visualization\n",
        "            with Live(layout, console=self.console, refresh_per_second=10) as live:\n",
        "                for iteration in range(max_iterations):\n",
        "                    # Calculate current simulation time\n",
        "                    current_simulation_time = time.time() - self.start_time\n",
        "\n",
        "                    # Process tasks on each resource\n",
        "                    for i, resource in enumerate(self.resources, 1):\n",
        "                        # Process resource queue\n",
        "                        resource_status = resource.process_queue(current_simulation_time)\n",
        "\n",
        "                        # Update layout with resource-specific panel\n",
        "                        layout[f\"resource{i}\"].update(\n",
        "                            self._create_resource_panel(resource, resource_status)\n",
        "                        )\n",
        "\n",
        "                    # Update live display\n",
        "                    live.update(layout)\n",
        "\n",
        "                    # Track completed and failed tasks across all resources\n",
        "                    total_processed_tasks = sum(\n",
        "                        len(resource.completed_tasks) for resource in self.resources\n",
        "                    ) + self.metrics['failed_tasks']\n",
        "\n",
        "                    # Check if all tasks are processed (completed or failed)\n",
        "                    if total_processed_tasks >= total_tasks:\n",
        "                        logger.info(f\"Simulation completed in {iteration} iterations\")\n",
        "                        break\n",
        "\n",
        "                    time.sleep(0.1)\n",
        "\n",
        "            # Calculate final metrics\n",
        "            completed_tasks = sum(len(resource.completed_tasks) for resource in self.resources)\n",
        "            self.metrics['completed_tasks'] = completed_tasks\n",
        "            self.metrics['makespan'] = time.time() - self.start_time\n",
        "\n",
        "            return self.metrics\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with utilization metrics\n",
        "        \"\"\"\n",
        "        # Create table for resource details\n",
        "        table = Table(show_header=False)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['raw_cpu_usage']:.2f}/{resource.cpu_rating} MI/s)\"\n",
        "        )\n",
        "\n",
        "        # Detailed task tracking\n",
        "        if status['detailed_tasks']:\n",
        "            table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "            for task in status['detailed_tasks']:\n",
        "                table.add_row(                f\"[blue]Task {task['id']} ({task['type']}):[/blue] \"\n",
        "                f\"Processed {task['processed']:.2f}/{task['total_required']} MI \"\n",
        "                f\"({task['completion_percentage']:.2f}%)\"\n",
        "                )\n",
        "\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['memory_utilization']:.2f}% \"\n",
        "            f\"({resource.current_memory_usage:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "\n",
        "        # Task processing status\n",
        "        table.add_row(\"\\n[bold]Task Processing[/bold]\")\n",
        "        table.add_row(f\"[green]Completed Tasks:[/green] {status['completed_tasks']}\")\n",
        "        table.add_row(f\"[yellow]Current Tasks:[/yellow] {status['current_tasks']}\")\n",
        "        table.add_row(f\"[red]Queue Length:[/red] {status['queue_length']}\")\n",
        "\n",
        "        # Create panel with resource-specific styling\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main simulation entry point\n",
        "    \"\"\"\n",
        "    # Create resources\n",
        "    resources = create_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    try:\n",
        "        # Run simulation for 1500 tasks\n",
        "        metrics = scheduler.run_simulation(total_tasks=1500)\n",
        "\n",
        "        # Print final metrics\n",
        "        print(\"\\n--- Simulation Metrics ---\")\n",
        "        print(f\"Total Tasks Generated: {metrics['total_tasks']}\")\n",
        "        print(f\"Completed Tasks: {metrics['completed_tasks']}\")\n",
        "        print(f\"Failed Tasks: {metrics['failed_tasks']}\")\n",
        "        print(\"\\nTask Distribution:\")\n",
        "        for resource_type, count in metrics['task_distribution'].items():\n",
        "            print(f\"{resource_type}: {count}\")\n",
        "\n",
        "        print(\"\\nPerformance Metrics:\")\n",
        "        print(f\"Makespan: {metrics['makespan']:.2f} seconds\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Simulation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d18cf40d967244298ec27fa88194191f",
            "3f9c1b89a3e04f80a800678c1f30c694"
          ]
        },
        "id": "X9ar_Wc5VSh9",
        "outputId": "b02f4fa7-6ff5-4daa-d143-ae2b92acd745"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m             Task Distribution              \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mResource         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTasks\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFailed Tasks\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_Raspberry_Pi\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m253  \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m247         \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mEdge_Smartphone  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m265  \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m235         \u001b[0m\u001b[31m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mCloud_Host       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m500  \u001b[0m\u001b[35m \u001b[0m│\u001b[31m \u001b[0m\u001b[31m0           \u001b[0m\u001b[31m \u001b[0m│\n",
              "└───────────────────┴───────┴──────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">             Task Distribution              </span>\n",
              "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Resource          </span>┃<span style=\"font-weight: bold\"> Tasks </span>┃<span style=\"font-weight: bold\"> Failed Tasks </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_Raspberry_Pi </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 253   </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 247          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Edge_Smartphone   </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 265   </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 235          </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cloud_Host        </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> 500   </span>│<span style=\"color: #800000; text-decoration-color: #800000\"> 0            </span>│\n",
              "└───────────────────┴───────┴──────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d18cf40d967244298ec27fa88194191f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e1640cb32286>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-e1640cb32286>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# Run simulation for 1500 tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_tasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Print final metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-e1640cb32286>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, total_tasks, max_iterations)\u001b[0m\n\u001b[1;32m    464\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Calculate final metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With CPU and Utilization output included"
      ],
      "metadata": {
        "id": "FTKFBZBto2q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Detailed task representation with advanced tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "        # Queuing attributes\n",
        "        self.wait_time = 0\n",
        "        self.queue_position = None\n",
        "\n",
        "        # Additional metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "        self.task_class = self.details.get('task_class', 'generic')\n",
        "        self.cpu_intensity = self.details.get('cpu_intensity', 'medium')\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with comprehensive tracking and utilization metrics\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Task management\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Utilization tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Additional tracking for more nuanced CPU utilization\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in the queue with detailed tracking and utilization update\n",
        "        \"\"\"\n",
        "        # Reset current usage and task tracking\n",
        "        self.current_cpu_usage = 0\n",
        "        self.task_cpu_demands = []\n",
        "        self.detailed_task_tracking = []\n",
        "\n",
        "        # Calculate available CPU for this time step\n",
        "        available_cpu = self.cpu_rating\n",
        "\n",
        "        # Process current tasks first\n",
        "        for task in self.current_tasks[:]:\n",
        "            # Determine how much CPU can be used for this task\n",
        "            task_cpu = min(available_cpu, task.remaining_cpu)\n",
        "\n",
        "            processing_result = task.process(task_cpu)\n",
        "\n",
        "            # Update CPU usage and available CPU\n",
        "            processed_amount = processing_result['processed']\n",
        "            self.current_cpu_usage += processed_amount\n",
        "            available_cpu -= processed_amount\n",
        "\n",
        "            # Track detailed task information\n",
        "            task_info = {\n",
        "                'id': task.id,\n",
        "                'name': task.task_name,\n",
        "                'processed': processed_amount,\n",
        "                'total_required': task.total_cpu_required,\n",
        "                'completion_percentage': processing_result['completion_percentage']\n",
        "            }\n",
        "            self.detailed_task_tracking.append(task_info)\n",
        "\n",
        "            # Calculate task CPU demand\n",
        "            task_demand = processed_amount / self.cpu_rating\n",
        "            self.task_cpu_demands.append(task_demand)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "            # Stop processing if no CPU left\n",
        "            if available_cpu <= 0:\n",
        "                break\n",
        "\n",
        "        # Calculate CPU utilization\n",
        "        # Use sum of task CPU demands to get a more dynamic representation\n",
        "        if self.task_cpu_demands:\n",
        "            cpu_utilization = min(sum(self.task_cpu_demands) * 100, 100)\n",
        "        else:\n",
        "            cpu_utilization = 0\n",
        "\n",
        "        # Estimate memory usage (simple model: each current task uses some memory)\n",
        "        self.current_memory_usage = len(self.current_tasks) * (self.total_memory / 10)\n",
        "        memory_utilization = min((self.current_memory_usage / self.total_memory) * 100, 100)\n",
        "\n",
        "        # If resource has available capacity, move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:  # Limit concurrent tasks\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "            next_task.wait_time = current_time - next_task.arrival_time\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        # Return detailed resource state with utilization\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'cpu_utilization': cpu_utilization,\n",
        "            'memory_utilization': memory_utilization,\n",
        "            'raw_cpu_usage': self.current_cpu_usage,\n",
        "            'task_demands': self.task_cpu_demands,\n",
        "            'detailed_tasks': self.detailed_task_tracking\n",
        "        }\n",
        "\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        self.console = Console()\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "            'resource_status': {}\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks from JSON\n",
        "        \"\"\"\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),\n",
        "                cpu_required=task_dict.get('instructions', 50000),\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            task.arrival_time = self.current_time\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources\n",
        "        \"\"\"\n",
        "        # Load tasks\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin distribution\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            resource = self.resources[resource_index]\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        # Print distribution table\n",
        "        distribution_table = Table(title=\"Task Distribution\")\n",
        "        distribution_table.add_column(\"Resource\", style=\"cyan\")\n",
        "        distribution_table.add_column(\"Tasks\", style=\"magenta\")\n",
        "\n",
        "        for resource_type, count in task_distribution.items():\n",
        "            distribution_table.add_row(resource_type, str(count))\n",
        "\n",
        "        self.console.print(distribution_table)\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 10000):\n",
        "        \"\"\"\n",
        "        Run simulation with a stopping criterion similar to the provided code\n",
        "        \"\"\"\n",
        "        # Distribute tasks\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Total number of tasks\n",
        "        total_tasks = self.metrics['total_tasks']\n",
        "\n",
        "        # Prepare layout for live visualization\n",
        "        layout = Layout()\n",
        "        layout.split_row(\n",
        "            Layout(name=\"resource1\"),\n",
        "            Layout(name=\"resource2\"),\n",
        "            Layout(name=\"resource3\")\n",
        "        )\n",
        "\n",
        "        # Live visualization\n",
        "        with Live(layout, console=self.console, refresh_per_second=10) as live:\n",
        "            for iteration in range(max_iterations):\n",
        "                self.current_time += 1\n",
        "\n",
        "                # Process tasks on each resource\n",
        "                for i, resource in enumerate(self.resources, 1):\n",
        "                    # Process resource queue\n",
        "                    resource_status = resource.process_queue(self.current_time)\n",
        "\n",
        "                    # Update layout with resource-specific panel\n",
        "                    layout[f\"resource{i}\"].update(\n",
        "                        self._create_resource_panel(resource, resource_status)\n",
        "                    )\n",
        "\n",
        "                # Update live display\n",
        "                live.update(layout)\n",
        "\n",
        "                # Custom stopping criterion similar to the provided code\n",
        "                provisioned_tasks = sum(\n",
        "                    len(resource.completed_tasks) for resource in self.resources\n",
        "                )\n",
        "\n",
        "                # Stop when all tasks are provisioned (completed)\n",
        "                if provisioned_tasks == total_tasks:\n",
        "                    logger.info(f\"Simulation completed in {iteration} iterations\")\n",
        "                    break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "        return self.metrics\n",
        "\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with utilization metrics\n",
        "        \"\"\"\n",
        "        # Create table for resource details\n",
        "        table = Table(show_header=False)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['raw_cpu_usage']:.2f}/{resource.cpu_rating} MI/s)\"\n",
        "        )\n",
        "\n",
        "        # Show individual task demands for more insight\n",
        "        if status['task_demands']:\n",
        "            demands_str = \", \".join([f\"{d*100:.2f}%\" for d in status['task_demands']])\n",
        "            table.add_row(f\"[yellow]Task Demands:[/yellow] {demands_str}\")\n",
        "\n",
        "        # Detailed task tracking\n",
        "        if status['detailed_tasks']:\n",
        "            table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "            for task in status['detailed_tasks']:\n",
        "                table.add_row(\n",
        "                    f\"[blue]Task {task['id']} ({task['name']}):[/blue] \"\n",
        "                    f\"{task['processed']:.2f}/{task['total_required']} MI \"\n",
        "                    f\"({task['completion_percentage']:.2f}%)\"\n",
        "                )\n",
        "\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['memory_utilization']:.2f}% \"\n",
        "            f\"({resource.current_memory_usage:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "\n",
        "        # Task processing status\n",
        "        table.add_row(\"\\n[bold]Task Processing[/bold]\")\n",
        "        table.add_row(f\"[green]Completed Tasks:[/green] {status['completed_tasks']}\")\n",
        "        table.add_row(f\"[yellow]Current Tasks:[/yellow] {status['current_tasks']}\")\n",
        "        table.add_row(f\"[red]Queue Length:[/red] {status['queue_length']}\")\n",
        "\n",
        "        # Create panel with resource-specific styling\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Create resources\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    metrics = scheduler.run_simulation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8055e298b5e943efaecc5a10c8cdc4b4",
            "954db004304d487d8c8fd886c3b31990"
          ]
        },
        "id": "HmJFZgwjo8uc",
        "outputId": "04b4375b-87da-46f4-fa11-79b269d0e516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "📂 Available log files in EdgeSimPy/logs:\n",
            "simulation.log\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8055e298b5e943efaecc5a10c8cdc4b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8e1122721995>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-8e1122721995>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;31m# Run simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;31m# Print final metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-8e1122721995>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(self, total_tasks)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0;31m# Update live feed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mlive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_live_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Calculate comprehensive task metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/rich/live.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, renderable, refresh)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mrenderable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Round Robin Algorithm\n"
      ],
      "metadata": {
        "id": "qlju10qbKZWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional, Tuple  # Added Tuple\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.layout import Layout\n",
        "from rich.live import Live\n",
        "from rich.text import Text\n",
        "import logging\n",
        "import threading\n",
        "from google.colab import drive\n",
        "import os\n",
        "from rich import box  # This is the import we need\n",
        "from datetime import datetime, timedelta\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import multiprocessing\n",
        "import functools\n",
        "import copy\n",
        "import itertools\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the log directory in Google Drive\n",
        "log_dir = \"/content/drive/My Drive/EdgeSimPy/logs\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Generate a log filename with current date and time\n",
        "log_filename = datetime.now().strftime(\"simulation_%Y-%m-%d_%H-%M-%S.log\")\n",
        "full_log_path = os.path.join(log_dir, log_filename)\n",
        "\n",
        "# List existing log files in the directory (optional)\n",
        "try:\n",
        "    print(\"\\n📂 Available log files in EdgeSimPy/logs:\")\n",
        "    for filename in os.listdir(log_dir):\n",
        "        print(filename)\n",
        "except Exception as e:\n",
        "    print(f\"Error listing log files: {e}\")\n",
        "\n",
        "# Configure logging to write to both console and file\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,  # Change to DEBUG to capture more detailed logs\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout),  # Output to console\n",
        "        logging.FileHandler(full_log_path)  # Save logs to dated file in Google Drive\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a logger instance\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class Task:\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 task_type: str,\n",
        "                 input_size: float,    # Input data size in GB\n",
        "                 output_size: float,   # Output data size in GB\n",
        "                 cpu_required: float): # Total MI required\n",
        "        # Basic identification\n",
        "        self.id = task_id\n",
        "        self.type = task_type\n",
        "        # Resource requirements\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Timing metrics (CloudSim-style)\n",
        "        self.arrival_time = datetime.now().timestamp()  # Set arrival time immediately\n",
        "        self.start_time = None    # Will be set when actual processing begins\n",
        "        self.completion_time = None\n",
        "        self.exec_start_time = None\n",
        "        self.actual_exec_time = 0.0     # Initialize as float\n",
        "        self.turnaround_time = 0.0      # Initialize as float\n",
        "        self.waiting_time = 0.0         # Initialize as float\n",
        "\n",
        "        # Status tracking\n",
        "        self.status = 'CREATED'\n",
        "        self.completion_percentage = 0.0\n",
        "        self.assigned_resource = None\n",
        "\n",
        "        # Progress tracking\n",
        "        self.transferred_input = 0.0\n",
        "        self.transferred_output = 0.0\n",
        "        self.processed_mi = 0.0\n",
        "\n",
        "        # Tracking flags\n",
        "        self._time_initialized = False\n",
        "        self.last_update_time = None\n",
        "    def calculate_timing_metrics(self):\n",
        "        \"\"\"Calculate final timing metrics when task completes\"\"\"\n",
        "        if self.completion_time and self.arrival_time:\n",
        "            # Total time from arrival to completion\n",
        "            self.turnaround_time = self.completion_time - self.arrival_time\n",
        "\n",
        "            # Time spent in actual processing (excluding transfers)\n",
        "            if self.exec_start_time:\n",
        "                self.actual_exec_time = self.completion_time - self.exec_start_time\n",
        "            else:\n",
        "                self.actual_exec_time = self.completion_time - self.start_time\n",
        "\n",
        "            # Waiting time is turnaround time minus execution time\n",
        "            self.waiting_time = self.turnaround_time - self.actual_exec_time\n",
        "\n",
        "            # Ensure we don't have negative times\n",
        "            self.turnaround_time = max(0, self.turnaround_time)\n",
        "            self.actual_exec_time = max(0, self.actual_exec_time)\n",
        "            self.waiting_time = max(0, self.waiting_time)\n",
        "    def estimate_execution_time(self, resource) -> float:\n",
        "        \"\"\"\n",
        "        Calculate execution time considering separate input and output transfers\n",
        "        \"\"\"\n",
        "        # Input transfer time (for read tasks)\n",
        "        input_mb = self.input_size * 1024\n",
        "        input_transfer_time = input_mb / resource.total_bandwidth if input_mb > 0 else 0\n",
        "\n",
        "        # Processing time\n",
        "        processing_time = self.total_cpu_required / resource.total_cpu_rating\n",
        "\n",
        "        # Output transfer time (for write tasks)\n",
        "        output_mb = self.output_size * 1024\n",
        "        output_transfer_time = output_mb / resource.total_bandwidth if output_mb > 0 else 0\n",
        "\n",
        "        total_time = input_transfer_time + processing_time + output_transfer_time\n",
        "        return total_time\n",
        "\n",
        "    def update_progress(self, resource, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Update task progress with fixed time step calculations and enhanced timing metrics\n",
        "\n",
        "        This method handles the complete lifecycle of a task, including:\n",
        "        - Input data transfer\n",
        "        - Processing\n",
        "        - Output data transfer\n",
        "        - Timing metrics calculation\n",
        "        \"\"\"\n",
        "        # Log initial state for debugging\n",
        "        logger.info(f\"Task {self.id} UPDATE: Current state={self.status}, Time={current_time:.2f}\")\n",
        "\n",
        "        # SECTION 1: Initialize timing tracking\n",
        "        if not self._time_initialized:\n",
        "            logger.info(f\"Task {self.id} INIT: First update at time {current_time:.2f}\")\n",
        "            self._time_initialized = True\n",
        "            self.last_update_time = current_time\n",
        "\n",
        "        # SECTION 2: Calculate time steps for this update\n",
        "        elapsed = current_time - self.last_update_time  # Time since last update\n",
        "        steps = max(1, int(elapsed / 1.0))  # Divide into 1-second steps\n",
        "        time_per_step = elapsed / steps     # Actual time per step\n",
        "\n",
        "        logger.info(f\"Task {self.id} STEP: Time since last update={elapsed:.3f}s, Steps={steps}\")\n",
        "\n",
        "        # Calculate bandwidth in GB/s (convert from Mb/s)\n",
        "        step_bandwidth = (resource.total_bandwidth / 8.0) / 1024.0\n",
        "\n",
        "        # SECTION 3: State Machine - Handle different task states\n",
        "        old_status = self.status  # Track state transitions\n",
        "\n",
        "        if self.status == 'CREATED':\n",
        "            # Initial state: Set up task for processing\n",
        "            self.status = 'READY'\n",
        "            self.transferred_input = 0.0\n",
        "            self.transferred_output = 0.0\n",
        "            self.processed_mi = 0.0\n",
        "            if not self.start_time:  # Only set start_time if not already set\n",
        "                self.start_time = current_time  # Record when task starts\n",
        "                logger.info(f\"Task {self.id} TRANSITION: CREATED → READY at {current_time:.2f}\")\n",
        "\n",
        "        elif self.status == 'READY':\n",
        "            # Determine next phase based on input requirements\n",
        "            if self.input_size > 0:\n",
        "                self.status = 'TRANSFERRING_INPUT'\n",
        "                logger.info(f\"Task {self.id} TRANSITION: READY → TRANSFERRING_INPUT (input_size={self.input_size}GB)\")\n",
        "            else:\n",
        "                self.status = 'PROCESSING'\n",
        "                self.exec_start_time = current_time  # Record processing start\n",
        "                logger.info(f\"Task {self.id} TRANSITION: READY → PROCESSING (no input transfer needed)\")\n",
        "            self.completion_percentage = 0\n",
        "\n",
        "        elif self.status == 'TRANSFERRING_INPUT':\n",
        "            # Calculate input data transfer for this time step\n",
        "            step_transfer = step_bandwidth * time_per_step * steps\n",
        "            old_transfer = self.transferred_input\n",
        "            self.transferred_input = min(self.input_size, self.transferred_input + step_transfer)\n",
        "\n",
        "            logger.info(f\"Task {self.id} TRANSFER: Input {old_transfer:.3f}GB → {self.transferred_input:.3f}GB of {self.input_size:.3f}GB\")\n",
        "\n",
        "            if self.transferred_input >= self.input_size:\n",
        "                # Input transfer complete, start processing\n",
        "                self.status = 'PROCESSING'\n",
        "                self.exec_start_time = current_time  # Record actual processing start time\n",
        "                self.completion_percentage = 0\n",
        "                logger.info(f\"Task {self.id} TRANSITION: TRANSFERRING_INPUT → PROCESSING at {current_time:.2f}\")\n",
        "            else:\n",
        "                self.completion_percentage = (self.transferred_input / self.input_size) * 100\n",
        "\n",
        "        elif self.status == 'PROCESSING':\n",
        "            # Calculate processing progress\n",
        "            step_processing = resource.total_cpu_rating * time_per_step * steps\n",
        "            old_processed = self.processed_mi\n",
        "            self.processed_mi = min(self.total_cpu_required, self.processed_mi + step_processing)\n",
        "            self.remaining_cpu = self.total_cpu_required - self.processed_mi\n",
        "\n",
        "            logger.info(f\"Task {self.id} PROCESSING: {old_processed:.0f}MI → {self.processed_mi:.0f}MI of {self.total_cpu_required:.0f}MI\")\n",
        "\n",
        "            if self.processed_mi >= self.total_cpu_required:\n",
        "                # Processing complete, check if output transfer needed\n",
        "                if self.output_size > 0:\n",
        "                    self.status = 'TRANSFERRING_OUTPUT'\n",
        "                    self.completion_percentage = 0\n",
        "                    logger.info(f\"Task {self.id} TRANSITION: PROCESSING → TRANSFERRING_OUTPUT (output_size={self.output_size}GB)\")\n",
        "                else:\n",
        "                    # No output transfer needed, task is complete\n",
        "                    self.status = 'COMPLETED'\n",
        "                    self.completion_time = current_time\n",
        "                    self.calculate_timing_metrics()\n",
        "                    self.completion_percentage = 100\n",
        "                    logger.info(f\"Task {self.id} TRANSITION: PROCESSING → COMPLETED at {current_time:.2f}\")\n",
        "            else:\n",
        "                self.completion_percentage = (self.processed_mi / self.total_cpu_required) * 100\n",
        "\n",
        "        elif self.status == 'TRANSFERRING_OUTPUT':\n",
        "            # Calculate output data transfer for this time step\n",
        "            step_transfer = step_bandwidth * time_per_step * steps\n",
        "            old_transfer = self.transferred_output\n",
        "            self.transferred_output = min(self.output_size, self.transferred_output + step_transfer)\n",
        "\n",
        "            logger.info(f\"Task {self.id} TRANSFER: Output {old_transfer:.3f}GB → {self.transferred_output:.3f}GB of {self.output_size:.3f}GB\")\n",
        "\n",
        "            if self.transferred_output >= self.output_size:\n",
        "                # Output transfer complete, task is finished\n",
        "                self.status = 'COMPLETED'\n",
        "                self.completion_time = current_time\n",
        "                self.calculate_timing_metrics()\n",
        "                self.completion_percentage = 100\n",
        "                logger.info(f\"Task {self.id} TRANSITION: TRANSFERRING_OUTPUT → COMPLETED at {current_time:.2f}\")\n",
        "            else:\n",
        "                self.completion_percentage = (self.transferred_output / self.output_size) * 100\n",
        "\n",
        "        # Log state transition if it occurred\n",
        "        if old_status != self.status:\n",
        "            logger.info(f\"Task {self.id} STATE CHANGE: {old_status} → {self.status}\")\n",
        "\n",
        "        # SECTION 4: Update timing and return status\n",
        "        self.last_update_time = current_time\n",
        "\n",
        "        # Calculate current execution time\n",
        "        current_exec_time = current_time - (self.start_time or current_time)\n",
        "\n",
        "        # Final progress report for this update\n",
        "        logger.info(f\"Task {self.id} PROGRESS: Status={self.status}, Completion={self.completion_percentage:.1f}%, ExecTime={current_exec_time:.2f}s\")\n",
        "\n",
        "        return {\n",
        "            'status': self.status,\n",
        "            'progress': self.completion_percentage,\n",
        "            'exec_time': current_exec_time\n",
        "        }\n",
        "    def calculate_final_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate final timing metrics when task completes\n",
        "        \"\"\"\n",
        "        if self.completion_time and self.arrival_time and self.exec_start_time:\n",
        "            # Turnaround time: time from arrival to completion\n",
        "            self.turnaround_time = self.completion_time - self.arrival_time\n",
        "\n",
        "            # Actual execution time: time spent processing (excluding transfers)\n",
        "            self.actual_exec_time = self.completion_time - self.exec_start_time\n",
        "\n",
        "            # Waiting time: turnaround time minus actual execution time\n",
        "            self.waiting_time = self.turnaround_time - self.actual_exec_time\n",
        "    def update_execution(self, resource, time_step: float) -> bool:\n",
        "            \"\"\"\n",
        "            Process task as a single unit, tracking overall progress.\n",
        "            Returns True if task is completed.\n",
        "            \"\"\"\n",
        "            if self.status == 'CREATED':\n",
        "                self.status = 'RUNNING'\n",
        "                self.start_time = datetime.now().timestamp()\n",
        "\n",
        "            elif self.status == 'RUNNING':\n",
        "                # Calculate progress including both transfer and processing\n",
        "                progress = (time_step * resource.total_cpu_rating)\n",
        "                self.remaining_cpu -= progress\n",
        "\n",
        "                if self.remaining_cpu <= 0:\n",
        "                    self.status = 'COMPLETED'\n",
        "                    self.completion_time = datetime.now().timestamp()\n",
        "                    self.execution_time = self.completion_time - self.start_time\n",
        "                    return True\n",
        "\n",
        "            return False\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Log task processing details\n",
        "        logger.info(f\"Processing task {self.id} on resource. Remaining CPU: {self.remaining_cpu}\")\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = datetime.now().timestamp()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "class Resource:\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # MIPS\n",
        "                 memory: int,        # GB\n",
        "                 bandwidth: int):    # Mb/s\n",
        "        # Resource identification\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "\n",
        "        # Resource capabilities\n",
        "        self.total_cpu_rating = cpu_rating\n",
        "        self.total_memory = memory\n",
        "        self.total_bandwidth = bandwidth\n",
        "\n",
        "        # Task tracking\n",
        "        self.task_queue = []\n",
        "        self.current_task = None\n",
        "        self.completed_tasks = []\n",
        "        self.failed_tasks = []\n",
        "        self.failed_tasks_count = 0\n",
        "\n",
        "        # Resource utilization tracking\n",
        "        self.used_cpu = 0\n",
        "        self.used_memory = 0\n",
        "        self.current_load = 0.0\n",
        "        # Add reliability attribute\n",
        "        # You can assign different reliability values based on resource type\n",
        "        if resource_type.startswith(\"Cloud_\"):\n",
        "            self.reliability = 0.95  # High reliability for cloud resources\n",
        "        elif resource_type.startswith(\"Smartphone_\"):\n",
        "            self.reliability = 0.8   # Moderate reliability for smartphones\n",
        "        elif resource_type.startswith(\"Raspberry_\"):\n",
        "            self.reliability = 0.4   # Lower reliability for Raspberry Pi\n",
        "        else:\n",
        "            self.reliability = 0.5   # Default reliability\n",
        "    def calculate_resource_utilization(self):\n",
        "        \"\"\"\n",
        "        Debug resource utilization\n",
        "        \"\"\"\n",
        "        # First, log the current state\n",
        "        task_info = \"No task\"\n",
        "        if self.current_task:\n",
        "            task_info = f\"Task {self.current_task.id} ({self.current_task.type}) in state {self.current_task.status}\"\n",
        "            # Add extensive task state logging\n",
        "            logger.info(f\"\"\"\n",
        "            CURRENT TASK STATE:\n",
        "            Task ID: {self.current_task.id}\n",
        "            Type: {self.current_task.type}\n",
        "            Status: {self.current_task.status}\n",
        "            Progress: {self.current_task.completion_percentage}%\n",
        "            Input Size: {self.current_task.input_size} GB\n",
        "            Output Size: {self.current_task.output_size} GB\n",
        "            Processed MI: {self.current_task.processed_mi} / {self.current_task.total_cpu_required}\n",
        "            Input Transfer: {self.current_task.transferred_input} / {self.current_task.input_size} GB\n",
        "            Output Transfer: {self.current_task.transferred_output} / {self.current_task.output_size} GB\n",
        "            \"\"\")\n",
        "\n",
        "        logger.info(f\"Resource {self.id} ({self.type}) - {task_info}\")\n",
        "\n",
        "        # Default values\n",
        "        cpu_util = 0\n",
        "        mem_util = 0\n",
        "        bw_util = 0\n",
        "\n",
        "        # Super simple utilization based purely on state\n",
        "        if self.current_task:\n",
        "            status = self.current_task.status\n",
        "\n",
        "            # Debug status transitions\n",
        "            logger.info(f\"Current status: {status}\")\n",
        "\n",
        "            if status == 'PROCESSING':\n",
        "                cpu_util = 100  # Full CPU during processing\n",
        "                logger.info(f\"Setting CPU utilization to 100% for PROCESSING state\")\n",
        "\n",
        "            if status in ['TRANSFERRING_INPUT', 'TRANSFERRING_OUTPUT']:\n",
        "                bw_util = 100  # Full bandwidth during transfers\n",
        "                logger.info(f\"Setting bandwidth utilization to 100% for {status}\")\n",
        "\n",
        "            # Set memory utilization based on data presence\n",
        "            if self.current_task.input_size > 0 or self.current_task.output_size > 0:\n",
        "                mem_util = 50  # Using 50% as a simple indicator\n",
        "                logger.info(f\"Setting memory utilization to 50% due to data presence\")\n",
        "\n",
        "        # Log final values\n",
        "       # logger.info(f\"\"\"\n",
        "       # FINAL UTILIZATION VALUES:\n",
        "       #CPU: {cpu_util}%\n",
        "       # Memory: {mem_util}%\n",
        "       # Bandwidth: {bw_util}%\n",
        "       # \"\"\")\n",
        "\n",
        "        return {\n",
        "            'cpu_utilization': cpu_util,\n",
        "            'memory_utilization': mem_util,\n",
        "            'bandwidth_utilization': bw_util,\n",
        "            'overall_utilization': (cpu_util + mem_util + bw_util) / 3,\n",
        "            'raw_cpu_usage': (cpu_util / 100.0) * self.total_cpu_rating,\n",
        "            'raw_memory_usage': (mem_util / 100.0) * self.total_memory * 1024,\n",
        "            'raw_bandwidth_usage': (bw_util / 100.0) * self.total_bandwidth,\n",
        "            'active_tasks': 1 if self.current_task else 0,\n",
        "            'transfer_phase': self.current_task.status if self.current_task else 'NONE'\n",
        "        }\n",
        "    def _get_zero_utilization(self):\n",
        "        \"\"\"Helper method to return zero utilization state\"\"\"\n",
        "        return {\n",
        "            'cpu_utilization': 0,\n",
        "            'memory_utilization': 0,\n",
        "            'bandwidth_utilization': 0,\n",
        "            'overall_utilization': 0,\n",
        "            'raw_cpu_usage': 0,\n",
        "            'raw_memory_usage': 0,\n",
        "            'raw_bandwidth_usage': 0,\n",
        "            'active_tasks': 0,\n",
        "            'transfer_phase': 'NONE'\n",
        "        }\n",
        "    def can_process_task(self, task: Task) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Check if resource can process a given task based on task type and resource type.\n",
        "        Only RT1 and RT3 tasks are restricted from Smartphone and Raspberry Pi resources.\n",
        "        \"\"\"\n",
        "        # Cloud resources can process all tasks\n",
        "        if self.type.startswith(\"Cloud_\"):\n",
        "            return True, \"\"\n",
        "\n",
        "        # For Smartphone and Raspberry Pi resources\n",
        "        if self.type.startswith((\"Smartphone_\", \"Raspberry_\")):\n",
        "            return True, \"\"\n",
        "\n",
        "        # All other combinations are valid\n",
        "        return True, \"\"\n",
        "\n",
        "    def process_task(self, resource, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process task as a single unit, ensuring proper completion.\n",
        "        \"\"\"\n",
        "        status = {\n",
        "            'processed': False,\n",
        "            'completed': False,\n",
        "            'task_id': self.id,\n",
        "            'progress': self.completion_percentage\n",
        "        }\n",
        "\n",
        "        if self.status == 'CREATED':\n",
        "            self.status = 'RUNNING'\n",
        "            self.start_time = current_time\n",
        "            status['processed'] = True\n",
        "\n",
        "        elif self.status == 'RUNNING':\n",
        "            # Calculate progress including both transfer and processing\n",
        "            time_step = current_time - self.start_time\n",
        "            progress = (time_step * resource.total_cpu_rating)\n",
        "            self.remaining_cpu = max(0, self.remaining_cpu - progress)\n",
        "\n",
        "            # Update completion percentage\n",
        "            self.completion_percentage = min(100, ((self.total_cpu_required - self.remaining_cpu) /\n",
        "                                                self.total_cpu_required * 100))\n",
        "\n",
        "            if self.remaining_cpu <= 0:\n",
        "                self.status = 'COMPLETED'\n",
        "                self.completion_time = current_time\n",
        "                self.actual_exec_time = self.completion_time - self.start_time\n",
        "                status['completed'] = True\n",
        "\n",
        "            status['processed'] = True\n",
        "            status['progress'] = self.completion_percentage\n",
        "\n",
        "        return status\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"Add task to queue and update resource utilization\"\"\"\n",
        "        can_process, failure_reason = self.can_process_task(task)\n",
        "\n",
        "        if can_process:\n",
        "            task.status = 'READY'\n",
        "            self.task_queue.append(task)\n",
        "            logger.info(f\"Task {task.id} queued on {self.type}. Queue length: {len(self.task_queue)}\")\n",
        "        else:\n",
        "            task.status = 'FAILED'\n",
        "            task.failure_reason = failure_reason\n",
        "            self.failed_tasks.append(task)\n",
        "            self.failed_tasks_count += 1\n",
        "            logger.warning(f\"Task {task.id} ({task.type}) failed on {self.type}: {failure_reason}\")\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks in queue with fixed progress tracking\n",
        "        \"\"\"\n",
        "        status = {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_task': None,\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'resource_utilization': self.calculate_resource_utilization()\n",
        "        }\n",
        "\n",
        "        if self.current_task:\n",
        "            # Update task progress\n",
        "            progress = self.current_task.update_progress(self, current_time)\n",
        "\n",
        "            # Update status dictionary\n",
        "            status['current_task'] = {\n",
        "                'id': self.current_task.id,\n",
        "                'type': self.current_task.type,\n",
        "                'phase': self.current_task.status,\n",
        "                'progress': progress['progress'],\n",
        "                'input_size': self.current_task.input_size,\n",
        "                'output_size': self.current_task.output_size\n",
        "            }\n",
        "\n",
        "            # Handle task completion\n",
        "            if self.current_task.status == 'COMPLETED':\n",
        "                self.completed_tasks.append(self.current_task)\n",
        "                logger.info(f\"Task {self.current_task.id} completed on {self.type}\")\n",
        "                self.current_task = None\n",
        "\n",
        "        # Start new task if available\n",
        "        if not self.current_task and self.task_queue:\n",
        "            self.current_task = self.task_queue.pop(0)\n",
        "            # Make sure tasks are in CREATED state before processing\n",
        "            logger.info(f\"Starting Task {self.current_task.id} (status: {self.current_task.status}) - forcing to CREATED\")\n",
        "            self.current_task.status = 'CREATED'\n",
        "\n",
        "            self.current_task.exec_start_time = current_time\n",
        "            self.current_task._time_initialized = False  # Reset this flag to trigger initialization\n",
        "\n",
        "        return status\n",
        "class ResourceFocusedScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with resource-focused real-time visualization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.current_time = 0\n",
        "        #self.arrival_rate = 1.0  # Default task arrival rate\n",
        "        self.console = Console()\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'completed_tasks': 0,\n",
        "            'failed_tasks': 0,\n",
        "            'globally_failed_tasks': [],  # Store globally unassigned failed tasks\n",
        "            'makespan': 0,\n",
        "            'throughput': 0\n",
        "        }\n",
        "    def calculate_turnaround_time(self, task, simulation_start_time):\n",
        "        \"\"\"\n",
        "        Calculate turnaround time relative to simulation start time\n",
        "        \"\"\"\n",
        "        if (task.arrival_time is not None and\n",
        "            task.completion_time is not None):\n",
        "            # Adjust times relative to simulation start\n",
        "            arrival_relative = task.arrival_time - simulation_start_time\n",
        "            completion_relative = task.completion_time - simulation_start_time\n",
        "\n",
        "            turnaround_time = max(completion_relative - arrival_relative, 0)\n",
        "            return turnaround_time\n",
        "        return 0.0\n",
        "\n",
        "    def calculate_waiting_time(self, task):\n",
        "        \"\"\"\n",
        "        Calculate waiting time\n",
        "        \"\"\"\n",
        "        if (task.turnaround_time is not None and\n",
        "            task.actual_exec_time is not None):\n",
        "            waiting_time = max(task.turnaround_time - task.actual_exec_time, 0)\n",
        "            return waiting_time\n",
        "        return 0.0\n",
        "\n",
        "    def calculate_timing_metrics(self, completed_tasks: List[Task], simulation_start_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate timing metrics with guaranteed dictionary return\n",
        "        \"\"\"\n",
        "        # Initialize metrics with default values\n",
        "        metrics = {\n",
        "            'average_turnaround_time': 0.0,\n",
        "            'average_waiting_time': 0.0,\n",
        "            'average_execution_time': 0.0,\n",
        "            'total_tasks_processed': 0,\n",
        "            'total_turnaround_time': 0.0,\n",
        "            'total_waiting_time': 0.0,\n",
        "            'total_execution_time': 0.0\n",
        "        }\n",
        "\n",
        "        if not completed_tasks:\n",
        "            logger.warning(\"No completed tasks to process\")\n",
        "            return metrics\n",
        "\n",
        "        total_turnaround = 0.0\n",
        "        total_waiting = 0.0\n",
        "        total_execution = 0.0\n",
        "        valid_tasks = 0\n",
        "\n",
        "        logger.info(f\"\\nProcessing timing metrics for {len(completed_tasks)} completed tasks\")\n",
        "\n",
        "        for task in completed_tasks:\n",
        "            if task.status == 'COMPLETED':\n",
        "                # Log timing values for debugging\n",
        "                logger.debug(f\"\"\"\n",
        "                Task {task.id} timing values:\n",
        "                - Arrival: {task.arrival_time}\n",
        "                - Start: {task.start_time}\n",
        "                - Exec Start: {task.exec_start_time}\n",
        "                - Completion: {task.completion_time}\n",
        "                \"\"\")\n",
        "\n",
        "                # Ensure timing values are valid\n",
        "                if all(x is not None for x in [task.arrival_time, task.start_time,\n",
        "                                            task.completion_time, task.exec_start_time]):\n",
        "                    # Recalculate metrics to ensure consistency\n",
        "                    task.turnaround_time = max(0, task.completion_time - task.arrival_time)\n",
        "                    task.actual_exec_time = max(0, task.completion_time - task.exec_start_time)\n",
        "                    task.waiting_time = max(0, task.turnaround_time - task.actual_exec_time)\n",
        "\n",
        "                    if task.turnaround_time > 0 and task.actual_exec_time > 0:\n",
        "                        total_turnaround += task.turnaround_time\n",
        "                        total_waiting += task.waiting_time\n",
        "                        total_execution += task.actual_exec_time\n",
        "                        valid_tasks += 1\n",
        "                        logger.info(f\"Task {task.id} metrics valid - turnaround: {task.turnaround_time:.2f}s\")\n",
        "                    else:\n",
        "                        logger.warning(f\"Task {task.id} has zero or negative timing values\")\n",
        "                else:\n",
        "                    logger.warning(f\"Task {task.id} has missing timing values\")\n",
        "\n",
        "        # Update metrics if we have valid tasks\n",
        "        if valid_tasks > 0:\n",
        "            metrics.update({\n",
        "                'average_turnaround_time': total_turnaround / valid_tasks,\n",
        "                'average_waiting_time': total_waiting / valid_tasks,\n",
        "                'average_execution_time': total_execution / valid_tasks,\n",
        "                'total_tasks_processed': valid_tasks,\n",
        "                'total_turnaround_time': total_turnaround,\n",
        "                'total_waiting_time': total_waiting,\n",
        "                'total_execution_time': total_execution\n",
        "            })\n",
        "\n",
        "        # Log final summary\n",
        "        logger.info(f\"\"\"\n",
        "        Timing Metrics Summary:\n",
        "        - Total Tasks: {len(completed_tasks)}\n",
        "        - Valid Tasks: {valid_tasks}\n",
        "        - Average Turnaround: {metrics['average_turnaround_time']:.2f}s\n",
        "        - Average Waiting: {metrics['average_waiting_time']:.2f}s\n",
        "        - Average Execution: {metrics['average_execution_time']:.2f}s\n",
        "        \"\"\")\n",
        "\n",
        "        return metrics\n",
        "    def calculate_datacenter_utilization(self, start_time: float, end_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate utilization for different datacenter types following the paper's integral approach\n",
        "        \"\"\"\n",
        "        # Separate resources by datacenter type\n",
        "        smartphone_resources = [r for r in self.resources if r.type.startswith('Smartphone_')]\n",
        "        raspberry_pi_resources = [r for r in self.resources if r.type.startswith('Raspberry_')]\n",
        "        cloud_resources = [r for r in self.resources if r.type.startswith('Cloud_')]\n",
        "\n",
        "        def calculate_datacenter_ru(resources: List[Resource]) -> Dict:\n",
        "            \"\"\"\n",
        "            Calculate resource utilization for a specific datacenter type\n",
        "            \"\"\"\n",
        "            # Collect individual resource utilizations\n",
        "            resource_utilizations = [r.calculate_resource_utilization() for r in resources]\n",
        "\n",
        "            # Calculate datacenter-wide metrics\n",
        "            return {\n",
        "                'total_resources': len(resources),\n",
        "                'avg_cpu_utilization': np.mean([ru['cpu_utilization'] for ru in resource_utilizations]),\n",
        "                'avg_memory_utilization': np.mean([ru['memory_utilization'] for ru in resource_utilizations]),\n",
        "                'avg_bandwidth_utilization': np.mean([ru['bandwidth_utilization'] for ru in resource_utilizations]),\n",
        "                'overall_utilization': np.mean([ru['overall_utilization'] for ru in resource_utilizations]),\n",
        "                'active_tasks': sum(ru['active_tasks'] for ru in resource_utilizations),\n",
        "                'raw_metrics': resource_utilizations\n",
        "            }\n",
        "\n",
        "        # Calculate utilization for each datacenter type\n",
        "        datacenter_utilization = {\n",
        "            'smartphone_edge': calculate_datacenter_ru(smartphone_resources),\n",
        "            'raspberry_pi_edge': calculate_datacenter_ru(raspberry_pi_resources),\n",
        "            'cloud': calculate_datacenter_ru(cloud_resources)\n",
        "        }\n",
        "\n",
        "        # Calculate overall datacenter utilization\n",
        "        datacenter_utilization['overall'] = {\n",
        "            'total_resources': len(self.resources),\n",
        "            'total_simulation_time': end_time - start_time,\n",
        "            'avg_cpu_utilization': np.mean([\n",
        "                datacenter_utilization['smartphone_edge']['avg_cpu_utilization'],\n",
        "                datacenter_utilization['raspberry_pi_edge']['avg_cpu_utilization'],\n",
        "                datacenter_utilization['cloud']['avg_cpu_utilization']\n",
        "            ]),\n",
        "            'avg_memory_utilization': np.mean([\n",
        "                datacenter_utilization['smartphone_edge']['avg_memory_utilization'],\n",
        "                datacenter_utilization['raspberry_pi_edge']['avg_memory_utilization'],\n",
        "                datacenter_utilization['cloud']['avg_memory_utilization']\n",
        "            ]),\n",
        "            'avg_bandwidth_utilization': np.mean([\n",
        "                datacenter_utilization['smartphone_edge']['avg_bandwidth_utilization'],\n",
        "                datacenter_utilization['raspberry_pi_edge']['avg_bandwidth_utilization'],\n",
        "                datacenter_utilization['cloud']['avg_bandwidth_utilization']\n",
        "            ]),\n",
        "            'total_active_tasks': sum(\n",
        "                datacenter_utilization[dc_type]['active_tasks']\n",
        "                for dc_type in ['smartphone_edge', 'raspberry_pi_edge', 'cloud']\n",
        "            )\n",
        "        }\n",
        "\n",
        "        return datacenter_utilization\n",
        "\n",
        "    def generate_tasks(self, total_tasks: int) -> Tuple[List[Task], List[float], List[float]]:\n",
        "            \"\"\"\n",
        "            Generate tasks with Poisson-distributed arrival times and return raw inter-arrival times.\n",
        "\n",
        "            Args:\n",
        "                total_tasks (int): The total number of tasks to generate.\n",
        "\n",
        "            Returns:\n",
        "                Tuple[List[Task], List[float], List[float]]: A tuple containing:\n",
        "                    - List of generated Task objects\n",
        "                    - List of cumulative arrival times\n",
        "                    - List of raw inter-arrival times\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "            simulation_duration = 100\n",
        "            lambda_rate = total_tasks / simulation_duration\n",
        "            inter_arrival_times = []\n",
        "            cumulative_times = [0]  # Start with 0 as the first arrival time\n",
        "\n",
        "            while len(inter_arrival_times) < total_tasks - 1:  # We need one less inter-arrival time than total tasks\n",
        "                interval = np.random.exponential(1.0 / lambda_rate)\n",
        "                inter_arrival_times.append(interval)\n",
        "                cumulative_times.append(cumulative_times[-1] + interval)\n",
        "            # Use a base time to ensure consistent and positive arrival times\n",
        "            base_time = datetime.now().timestamp()\n",
        "\n",
        "            tasks = []\n",
        "            for i in range(total_tasks):\n",
        "                task = Task(\n",
        "                    task_id=i + 1,\n",
        "                    task_type=\"placeholder\",\n",
        "                    input_size=0.0,    # Changed from data_size to input_size\n",
        "                    output_size=0.0,   # Added output_size\n",
        "                    cpu_required=0.0\n",
        "                )\n",
        "                task.arrival_time = base_time + cumulative_times[i]\n",
        "                tasks.append(task)\n",
        "\n",
        "            # Write inter-arrival times to a CSV file\n",
        "            with open('inter_arrival_times.csv', 'w', newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(['Inter-arrival Time'])\n",
        "                for time in inter_arrival_times:\n",
        "                    writer.writerow([time])\n",
        "\n",
        "            return tasks, cumulative_times, inter_arrival_times\n",
        "\n",
        "    def _create_resource_panel(self, resource: Resource, status: Dict) -> Panel:\n",
        "        \"\"\"\n",
        "        Create a detailed panel for a specific resource with comprehensive task information.\n",
        "        \"\"\"\n",
        "        table = Table(show_header=False, show_lines=True)\n",
        "\n",
        "        # Resource basic information\n",
        "        table.add_row(\"[bold]Resource Details[/bold]\")\n",
        "        table.add_row(f\"[cyan]Type:[/cyan] {resource.type}\")\n",
        "        table.add_row(f\"[green]CPU Rating:[/green] {resource.total_cpu_rating} MI/s\")\n",
        "        table.add_row(f\"[blue]Memory:[/blue] {resource.total_memory} GB\")\n",
        "        table.add_row(f\"[yellow]Bandwidth:[/yellow] {resource.total_bandwidth} MB/s\")\n",
        "\n",
        "        # Utilization information\n",
        "        table.add_row(\"\\n[bold]Utilization Metrics[/bold]\")\n",
        "        table.add_row(\n",
        "            f\"[green]CPU Usage:[/green] {status['resource_utilization']['cpu_utilization']:.2f}% \"\n",
        "            f\"({status['resource_utilization']['raw_cpu_usage']:.2f}/{resource.total_cpu_rating} MI/s)\"\n",
        "        )\n",
        "        table.add_row(\n",
        "            f\"[blue]Memory Usage:[/blue] {status['resource_utilization']['memory_utilization']:.2f}% \"\n",
        "            f\"({status['resource_utilization']['raw_memory_usage']:.2f}/{resource.total_memory} GB)\"\n",
        "        )\n",
        "        table.add_row(\n",
        "            f\"[yellow]Bandwidth Usage:[/yellow] {status['resource_utilization']['bandwidth_utilization']:.2f}% \"\n",
        "            f\"({status['resource_utilization']['raw_bandwidth_usage']:.2f}/{resource.total_bandwidth} MB/s)\"\n",
        "        )\n",
        "\n",
        "        # Task Queue Information\n",
        "        table.add_row(\"\\n[bold]Task Queue[/bold]\")\n",
        "        table.add_row(f\"[yellow]Queued Tasks:[/yellow] {status['queue_length']}\")\n",
        "\n",
        "        # Current Tasks\n",
        "        table.add_row(\"\\n[bold]Current Tasks[/bold]\")\n",
        "        if status['current_task']:\n",
        "            current_task = status['current_task']\n",
        "            table.add_row(\n",
        "                f\"[blue]Task {current_task['id']} ({current_task['type']}):[/blue] \"\n",
        "                f\"Phase: {current_task['phase']} Progress: {current_task['progress']}\"\n",
        "            )\n",
        "        else:\n",
        "            table.add_row(\"[dim]No tasks currently processing[/dim]\")\n",
        "\n",
        "        # Failed Tasks\n",
        "        table.add_row(\"\\n[bold]Failed Tasks[/bold]\")\n",
        "        if resource.failed_tasks:\n",
        "            for task in resource.failed_tasks:\n",
        "                table.add_row(\n",
        "                    f\"[red]Task {task.id} ({task.type}):[/red] \"\n",
        "                    f\"Reason: {task.failure_reason}\"\n",
        "                )\n",
        "        else:\n",
        "            table.add_row(\"[dim]No failed tasks[/dim]\")\n",
        "\n",
        "        return Panel(\n",
        "            table,\n",
        "            title=f\"Resource {resource.id}: {resource.type}\",\n",
        "            border_style=\"green\"\n",
        "        )\n",
        "    def verify_and_fix_task_distribution(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Emergency fix to directly ensure tasks are properly queued to resources\n",
        "        regardless of distribution algorithm issues.\n",
        "        \"\"\"\n",
        "        logger.info(\"🚨 EMERGENCY FIX: Verifying task distribution...\")\n",
        "\n",
        "        # Check current queue status\n",
        "        total_queued = sum(len(resource.task_queue) for resource in self.resources)\n",
        "        logger.info(f\"Current queued tasks: {total_queued} of {total_tasks}\")\n",
        "\n",
        "        # If we have tasks queued, no action needed\n",
        "        if total_queued >= total_tasks:\n",
        "            logger.info(\"✅ Task distribution verified: All tasks are properly queued\")\n",
        "\n",
        "            # Collect all tasks to return\n",
        "            all_tasks = []\n",
        "            for resource in self.resources:\n",
        "                all_tasks.extend(resource.task_queue)\n",
        "                all_tasks.extend(resource.failed_tasks)\n",
        "\n",
        "            return all_tasks\n",
        "\n",
        "        # If we have zero or insufficient tasks queued, perform emergency distribution\n",
        "        logger.warning(f\"⚠️ Task distribution problem detected: Only {total_queued} of {total_tasks} tasks queued\")\n",
        "\n",
        "        # Clear all existing resource queues\n",
        "        for resource in self.resources:\n",
        "            resource.task_queue = []\n",
        "            resource.failed_tasks = []\n",
        "\n",
        "        # Generate fresh tasks\n",
        "        logger.info(\"Generating emergency replacement tasks...\")\n",
        "        tasks, _, _ = self.generate_tasks(total_tasks)\n",
        "\n",
        "        # Define task types with fixed requirements\n",
        "        task_types = [\n",
        "            # Read Tasks\n",
        "            {\"type\": \"RT1\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"RT2\", \"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "            {\"type\": \"RT3\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "            {\"type\": \"RT4\", \"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "            # Write Tasks\n",
        "            {\"type\": \"WT1\", \"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"WT2\", \"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "            {\"type\": \"WT3\", \"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "            {\"type\": \"WT4\", \"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "        ]\n",
        "\n",
        "        # Distribute tasks using simple round-robin\n",
        "        distributed_tasks = []\n",
        "        resource_index = 0\n",
        "\n",
        "        for i, task_record in enumerate(tasks):\n",
        "            # Select task type based on index\n",
        "            task_type = task_types[i % len(task_types)]\n",
        "\n",
        "            # Create task with proper properties\n",
        "            task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "            task.arrival_time = task_record.arrival_time\n",
        "            task.status = 'CREATED'  # Ensure correct initial status\n",
        "\n",
        "            # Assign to resource using round-robin\n",
        "            resource = self.resources[resource_index]\n",
        "            resource.task_queue.append(task)\n",
        "\n",
        "            # Log the assignment\n",
        "            logger.info(f\"Emergency assigned Task {task.id} ({task.type}) to {resource.type}\")\n",
        "\n",
        "            # Advance resource index for round-robin\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "            # Add to distributed tasks list\n",
        "            distributed_tasks.append(task)\n",
        "\n",
        "        # Verify fix worked\n",
        "        total_queued = sum(len(resource.task_queue) for resource in self.resources)\n",
        "        logger.info(f\"Emergency fix completed: {total_queued} of {total_tasks} tasks now queued\")\n",
        "\n",
        "        # Double check each resource has tasks\n",
        "        for resource in self.resources:\n",
        "            logger.info(f\"Resource {resource.type} now has {len(resource.task_queue)} tasks queued\")\n",
        "\n",
        "        return distributed_tasks\n",
        "\n",
        "    def calculate_load_balancing_metrics(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Calculate load balancing metrics based on resource utilization formula:\n",
        "        1. U(Ri) = L(Ri) / Makespan - Utilization of each resource\n",
        "        2. Uav = (Σ U(Ri)) / n - Average utilization across all resources\n",
        "\n",
        "        Returns:\n",
        "            Dict: Load balancing metrics\n",
        "        \"\"\"\n",
        "        # Start debug logging\n",
        "        logger.info(\"===== LOAD BALANCING METRICS CALCULATION STARTED =====\")\n",
        "\n",
        "        # Get makespan from metrics (correct order - define before using)\n",
        "        # Calculate makespan dynamically\n",
        "        makespan = max(\n",
        "            max(\n",
        "                (task.completion_time or 0)\n",
        "                for resource in self.resources\n",
        "                for task in resource.completed_tasks\n",
        "            ),\n",
        "            0.001  # Ensure a minimum makespan to avoid division by zero\n",
        "        )\n",
        "\n",
        "        # Debug output\n",
        "        logger.info(f\"DEBUG - Makespan value: {makespan}\")\n",
        "        logger.info(f\"DEBUG - self.metrics contents: {self.metrics}\")\n",
        "\n",
        "        # Check for valid makespan\n",
        "        if makespan <= 0:\n",
        "            logger.warning(\"Makespan is zero or negative, returning empty metrics\")\n",
        "            return {\n",
        "                'resource_utilizations': {},\n",
        "                'average_utilization': 0,\n",
        "                'load_balance_score': 0,\n",
        "                'utilization_std_dev': 0,\n",
        "                'resource_type_metrics': {}\n",
        "            }\n",
        "\n",
        "        # Calculate load on each resource\n",
        "        # L(Ri) = total processing time of all tasks assigned to Ri\n",
        "        resource_loads = {}\n",
        "        resource_utilizations = {}\n",
        "\n",
        "        # Group resources by type\n",
        "        smartphone_resources = []\n",
        "        raspberry_pi_resources = []\n",
        "        cloud_resources = []\n",
        "\n",
        "        # Check and fix task timing issues\n",
        "        task_timing_issues = 0\n",
        "        fixed_task_count = 0\n",
        "\n",
        "        # Process each resource\n",
        "        logger.info(\"Processing individual resource metrics:\")\n",
        "\n",
        "        for resource in self.resources:\n",
        "            # Group resource by type\n",
        "            if resource.type.startswith('Smartphone_'):\n",
        "                smartphone_resources.append(resource)\n",
        "            elif resource.type.startswith('Raspberry_'):\n",
        "                raspberry_pi_resources.append(resource)\n",
        "            elif resource.type.startswith('Cloud_'):\n",
        "                cloud_resources.append(resource)\n",
        "\n",
        "            # Fix any task timing issues\n",
        "            for task in resource.completed_tasks:\n",
        "                if not hasattr(task, 'actual_exec_time') or task.actual_exec_time is None:\n",
        "                    task_timing_issues += 1\n",
        "                    # Try to calculate from raw timestamps\n",
        "                    if hasattr(task, 'completion_time') and hasattr(task, 'exec_start_time'):\n",
        "                        if task.completion_time and task.exec_start_time:\n",
        "                            task.actual_exec_time = max(0.001, task.completion_time - task.exec_start_time)\n",
        "                            fixed_task_count += 1\n",
        "                            logger.info(f\"Fixed task {task.id} exec_time to {task.actual_exec_time:.4f}s\")\n",
        "                elif task.actual_exec_time <= 0:\n",
        "                    task_timing_issues += 1\n",
        "                    # Force a minimum value\n",
        "                    task.actual_exec_time = 0.001  # 1 millisecond minimum\n",
        "                    fixed_task_count += 1\n",
        "                    logger.info(f\"Corrected zero/negative exec_time for task {task.id}\")\n",
        "\n",
        "            # Debug task information\n",
        "            completed_task_count = len(resource.completed_tasks)\n",
        "            valid_task_count = sum(\n",
        "                1 for task in resource.completed_tasks\n",
        "                if hasattr(task, 'actual_exec_time') and task.actual_exec_time is not None and task.actual_exec_time > 0\n",
        "            )\n",
        "\n",
        "            logger.info(f\"Resource {resource.id} ({resource.type}):\")\n",
        "            logger.info(f\"  - Completed tasks: {completed_task_count}\")\n",
        "            logger.info(f\"  - Tasks with valid execution time: {valid_task_count}\")\n",
        "\n",
        "            # Log individual task execution times\n",
        "            task_times_summary = []\n",
        "            for i, task in enumerate(resource.completed_tasks[:5]):  # Log first 5 tasks for brevity\n",
        "                task_exec_time = getattr(task, 'actual_exec_time', None)\n",
        "                task_times_summary.append(f\"Task {task.id}: {task_exec_time:.4f}s\" if task_exec_time else f\"Task {task.id}: None\")\n",
        "\n",
        "            logger.info(f\"  - Task times: {', '.join(task_times_summary)}\")\n",
        "\n",
        "            if completed_task_count > 5:\n",
        "                logger.info(f\"  - ... and {completed_task_count - 5} more tasks\")\n",
        "\n",
        "            # Calculate total processing time for all completed tasks\n",
        "            total_processing_time = sum(\n",
        "                task.actual_exec_time\n",
        "                for task in resource.completed_tasks\n",
        "                if hasattr(task, 'actual_exec_time') and task.actual_exec_time is not None and task.actual_exec_time > 0\n",
        "            )\n",
        "\n",
        "            logger.info(f\"  - Total processing time: {total_processing_time:.4f} seconds\")\n",
        "\n",
        "            # Calculate utilization: U(Ri) = L(Ri) / Makespan\n",
        "            utilization = total_processing_time / makespan if makespan > 0 else 0\n",
        "            logger.info(f\"  - Utilization (U(Ri) = L(Ri) / Makespan): {utilization:.4f}\")\n",
        "\n",
        "            resource_loads[resource.id] = total_processing_time\n",
        "            resource_utilizations[resource.id] = utilization\n",
        "\n",
        "        # Log task timing fixes\n",
        "        logger.info(f\"Found {task_timing_issues} tasks with timing issues, fixed {fixed_task_count}\")\n",
        "\n",
        "        # Check if we have any valid utilization data\n",
        "        if not resource_utilizations or all(util == 0 for util in resource_utilizations.values()):\n",
        "            logger.warning(\"All resources have zero utilization, metrics will be zero\")\n",
        "\n",
        "        # Calculate average utilization overall: Uav = (Σ U(Ri)) / n\n",
        "        average_utilization = sum(resource_utilizations.values()) / len(self.resources) if self.resources else 0\n",
        "        logger.info(f\"Average utilization across all resources (Uav): {average_utilization:.4f}\")\n",
        "\n",
        "        # Calculate standard deviation of utilizations (measure of balance)\n",
        "        utilization_values = list(resource_utilizations.values())\n",
        "        logger.info(f\"All utilization values: {utilization_values}\")\n",
        "\n",
        "        utilization_std_dev = np.std(utilization_values) if utilization_values else 0\n",
        "        logger.info(f\"Standard deviation of utilizations: {utilization_std_dev:.4f}\")\n",
        "\n",
        "        # Load balance score (lower is better - 0 is perfect balance)\n",
        "        # Using coefficient of variation to normalize\n",
        "        if average_utilization <= 0.0001:  # Very small threshold\n",
        "            logger.warning(\"Average utilization near zero, setting load balance score to 0\")\n",
        "            load_balance_score = 0\n",
        "        else:\n",
        "            load_balance_score = utilization_std_dev / average_utilization\n",
        "\n",
        "        logger.info(f\"Load balance score (CV = std_dev / avg): {load_balance_score:.4f}\")\n",
        "\n",
        "        # Calculate metrics per resource type\n",
        "        def calculate_resource_type_metrics(resources, type_name):\n",
        "            logger.info(f\"\\nCalculating metrics for {type_name} resources:\")\n",
        "\n",
        "            if not resources:\n",
        "                logger.info(f\"  No {type_name} resources found\")\n",
        "                return {\n",
        "                    'average_utilization': 0,\n",
        "                    'utilization_std_dev': 0,\n",
        "                    'load_balance_score': 0,\n",
        "                    'resource_count': 0\n",
        "                }\n",
        "\n",
        "            logger.info(f\"  Found {len(resources)} {type_name} resources\")\n",
        "            type_utilizations = [resource_utilizations[r.id] for r in resources]\n",
        "            logger.info(f\"  Utilization values: {type_utilizations}\")\n",
        "\n",
        "            type_avg_util = sum(type_utilizations) / len(resources)\n",
        "            logger.info(f\"  Average utilization: {type_avg_util:.4f}\")\n",
        "\n",
        "            type_std_dev = np.std(type_utilizations) if len(type_utilizations) > 1 else 0\n",
        "            logger.info(f\"  Standard deviation: {type_std_dev:.4f}\")\n",
        "\n",
        "            type_balance_score = type_std_dev / type_avg_util if type_avg_util > 0 else 0\n",
        "            logger.info(f\"  Balance score: {type_balance_score:.4f}\")\n",
        "\n",
        "            return {\n",
        "                'average_utilization': type_avg_util,\n",
        "                'utilization_std_dev': type_std_dev,\n",
        "                'load_balance_score': type_balance_score,\n",
        "                'resource_count': len(resources)\n",
        "            }\n",
        "\n",
        "        # Get metrics for each resource type\n",
        "        logger.info(\"\\nCalculating metrics by resource type:\")\n",
        "        resource_type_metrics = {\n",
        "            'smartphone': calculate_resource_type_metrics(smartphone_resources, \"smartphone\"),\n",
        "            'raspberry_pi': calculate_resource_type_metrics(raspberry_pi_resources, \"raspberry_pi\"),\n",
        "            'cloud': calculate_resource_type_metrics(cloud_resources, \"cloud\")\n",
        "        }\n",
        "\n",
        "        # Calculate inter-type balance\n",
        "        logger.info(\"\\nCalculating inter-type balance metrics:\")\n",
        "        type_avg_utils = [\n",
        "            resource_type_metrics['smartphone']['average_utilization'],\n",
        "            resource_type_metrics['raspberry_pi']['average_utilization'],\n",
        "            resource_type_metrics['cloud']['average_utilization']\n",
        "        ]\n",
        "        logger.info(f\"  Resource type average utilizations: {type_avg_utils}\")\n",
        "\n",
        "        inter_type_std_dev = np.std(type_avg_utils)\n",
        "        logger.info(f\"  Inter-type standard deviation: {inter_type_std_dev:.4f}\")\n",
        "\n",
        "        inter_type_avg = sum(type_avg_utils) / 3 if sum(type_avg_utils) > 0 else 0\n",
        "        logger.info(f\"  Inter-type average: {inter_type_avg:.4f}\")\n",
        "\n",
        "        inter_type_balance = inter_type_std_dev / inter_type_avg if inter_type_avg > 0 else 0\n",
        "        logger.info(f\"  Inter-type balance score: {inter_type_balance:.4f}\")\n",
        "\n",
        "        resource_type_metrics['inter_type_balance'] = {\n",
        "            'standard_deviation': inter_type_std_dev,\n",
        "            'balance_score': inter_type_balance\n",
        "        }\n",
        "\n",
        "        logger.info(\"===== LOAD BALANCING METRICS CALCULATION COMPLETED =====\")\n",
        "\n",
        "        # Force log flush\n",
        "        for handler in logger.handlers:\n",
        "            if isinstance(handler, logging.FileHandler):\n",
        "                handler.flush()\n",
        "\n",
        "        return {\n",
        "            'resource_utilizations': resource_utilizations,\n",
        "            'average_utilization': average_utilization,\n",
        "            'load_balance_score': load_balance_score,\n",
        "            'utilization_std_dev': utilization_std_dev,\n",
        "            'resource_type_metrics': resource_type_metrics\n",
        "        }\n",
        "    def _optimized_hybrid_algorithm(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Optimized hybrid Tabu-Genetic algorithm for smaller task sets (2000-5000 tasks).\n",
        "        This version is significantly faster while maintaining solution quality.\n",
        "\n",
        "        Key optimizations:\n",
        "        1. Faster initialization with smaller population\n",
        "        2. Reduced generations with early convergence detection\n",
        "        3. Streamlined Tabu Search focused on high-impact tasks\n",
        "        4. Simplified fitness function with multi-objective cost calculation\n",
        "        5. Better progress tracking throughout execution\n",
        "\n",
        "        Args:\n",
        "            total_tasks (int): Total number of tasks to distribute\n",
        "\n",
        "        Returns:\n",
        "            List[Task]: Distributed tasks with optimized resource assignments\n",
        "        \"\"\"\n",
        "        # Log start time and show progress indicator\n",
        "        start_time = time.time()\n",
        "        logger.info(f\"\\n⏳ Starting Optimized Hybrid Algorithm for {total_tasks} tasks...\")\n",
        "        logger.info(\"Phase 1/5: Task generation and initialization...\")\n",
        "\n",
        "        try:\n",
        "            # === STEP 1: Generate tasks with batch processing for efficiency ===\n",
        "            tasks, cumulative_times, inter_arrival_times = self.generate_tasks(total_tasks)\n",
        "\n",
        "            # Define task types with cached requirements\n",
        "            TASK_TYPES = {\n",
        "                \"RT1\": {\"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "                \"RT2\": {\"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "                \"RT3\": {\"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "                \"RT4\": {\"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "                \"WT1\": {\"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "                \"WT2\": {\"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "                \"WT3\": {\"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "                \"WT4\": {\"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "            }\n",
        "\n",
        "            # Pre-compute resource capabilities for faster lookup\n",
        "            RESOURCE_CAPABILITIES = {\n",
        "                resource.id: {\n",
        "                    'type': resource.type,\n",
        "                    'cpu_rating': resource.total_cpu_rating,\n",
        "                    'bandwidth': resource.total_bandwidth,\n",
        "                    'is_cloud': resource.type.startswith(\"Cloud_\"),\n",
        "                    'memory': resource.total_memory,\n",
        "                    'reliability': resource.reliability\n",
        "                } for resource in self.resources\n",
        "            }\n",
        "\n",
        "            # Faster task creation with larger batch size\n",
        "            batch_size = 500\n",
        "            initial_tasks = []\n",
        "            resource_loads = {r.id: 0 for r in self.resources}\n",
        "\n",
        "            # Show progress for task creation\n",
        "            logger.info(f\"Creating {total_tasks} tasks in batches of {batch_size}...\")\n",
        "\n",
        "            for i in range(0, total_tasks, batch_size):\n",
        "                batch_end = min(i + batch_size, total_tasks)\n",
        "                batch_tasks = []\n",
        "\n",
        "                for j in range(i, batch_end):\n",
        "                    task_record = tasks[j]\n",
        "                    task_type = list(TASK_TYPES.keys())[j % len(TASK_TYPES)]\n",
        "                    specs = TASK_TYPES[task_type]\n",
        "\n",
        "                    task = Task(\n",
        "                        task_id=task_record.id,\n",
        "                        task_type=task_type,\n",
        "                        input_size=specs[\"input_size\"],\n",
        "                        output_size=specs[\"output_size\"],\n",
        "                        cpu_required=specs[\"cpu_required\"]\n",
        "                    )\n",
        "                    task.arrival_time = task_record.arrival_time\n",
        "                    batch_tasks.append(task)\n",
        "\n",
        "                initial_tasks.extend(batch_tasks)\n",
        "                logger.info(f\"Created {min(batch_end, total_tasks)}/{total_tasks} tasks ({(min(batch_end, total_tasks)/total_tasks)*100:.1f}%)\")\n",
        "\n",
        "            # Special handling for very small task counts (like 5)\n",
        "            if total_tasks <= 10:\n",
        "                logger.info(f\"Small task count ({total_tasks}) detected - using specialized optimization parameters\")\n",
        "                # Smaller population, fewer generations for tiny problems\n",
        "                population_size = max(5, min(10, total_tasks))\n",
        "                generations = 3\n",
        "                tabu_iterations = max(5, min(10, total_tasks))\n",
        "                tabu_tenure = max(3, min(5, total_tasks))\n",
        "                max_stagnation = 2\n",
        "            else:\n",
        "            # === STEP 2: Adjusted optimization parameters for larger task counts ===\n",
        "                population_size = min(50, int(total_tasks * 0.1))  # Proportional to total tasks\n",
        "                generations = min(20, int(total_tasks * 0.05))     # More generations for larger problems\n",
        "                tabu_iterations = min(100, int(total_tasks * 0.05))  # Increased iterations\n",
        "                tabu_tenure = min(50, int(total_tasks * 0.02))     # Slightly larger tabu tenure\n",
        "                max_stagnation = 10    # Increased early stopping patience\n",
        "\n",
        "            mutation_rate = 0.15\n",
        "            crossover_rate = 0.8\n",
        "            elite_count = 2\n",
        "\n",
        "            tabu_list = collections.deque(maxlen=tabu_tenure)\n",
        "\n",
        "            # === STEP 3: Define optimized utility functions ===\n",
        "            def fast_exec_time_estimate(task, resource_id):\n",
        "                \"\"\"Simplified execution time estimation for speed\"\"\"\n",
        "                resource = RESOURCE_CAPABILITIES[resource_id]\n",
        "\n",
        "                # Basic estimate combining transfer and processing time\n",
        "                transfer_time = ((task.input_size + task.output_size) * 1024) / resource['bandwidth']\n",
        "                process_time = task.total_cpu_required / resource['cpu_rating']\n",
        "\n",
        "                # Simple reliability factor\n",
        "                reliability_factor = 1.0 + (1.0 - resource['reliability']) * 0.5\n",
        "\n",
        "                # Simplified total time calculation\n",
        "                return (transfer_time + process_time) * reliability_factor\n",
        "\n",
        "            def simplified_fitness(solution):\n",
        "                \"\"\"\n",
        "                Multi-objective cost function focusing on:\n",
        "                1. Task distribution efficiency\n",
        "                2. Load balancing\n",
        "                3. Resource type compatibility\n",
        "                4. Task execution characteristics\n",
        "                \"\"\"\n",
        "                # Calculate total task execution times with penalties\n",
        "                total_execution_cost = 0\n",
        "                task_counts = {}\n",
        "                resource_loads = {}\n",
        "\n",
        "                # Specific task type and resource compatibility coefficients\n",
        "                type_resource_penalties = {\n",
        "                    'WT3': {\n",
        "                        'Raspberry_': 3.0,  # Heavy penalty for WT3 on Raspberry Pi\n",
        "                        'Cloud_': 0.5,      # Slight bonus for WT3 on cloud\n",
        "                        'Smartphone_': 1.5  # Moderate penalty on smartphones\n",
        "                    },\n",
        "                    'RT1': {\n",
        "                        'Cloud_': 0.1,      # Preferred placement\n",
        "                        'Smartphone_': 2.0, # Less preferred\n",
        "                        'Raspberry_': 3.0   # Least preferred\n",
        "                    },\n",
        "                    'RT3': {\n",
        "                        'Cloud_': 0.1,      # Preferred placement\n",
        "                        'Smartphone_': 2.0, # Less preferred\n",
        "                        'Raspberry_': 3.0   # Least preferred\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # Process each task in the solution\n",
        "                for task, resource in solution.items():\n",
        "                    if not resource:\n",
        "                        # Heavy penalty for unassigned tasks\n",
        "                        total_execution_cost += 100000\n",
        "                        continue\n",
        "\n",
        "                    # Basic execution time estimation\n",
        "                    exec_time = (task.input_size + task.output_size + task.total_cpu_required / resource.total_cpu_rating)\n",
        "\n",
        "                    # Adjust cost based on task-resource compatibility\n",
        "                    penalty_multiplier = type_resource_penalties.get(task.type, {}).get(resource.type.split('_')[0] + '_', 1.0)\n",
        "                    exec_time *= penalty_multiplier\n",
        "\n",
        "                    # Track task counts per resource\n",
        "                    task_counts[resource.id] = task_counts.get(resource.id, 0) + 1\n",
        "                    resource_loads[resource.id] = resource_loads.get(resource.id, 0) + exec_time\n",
        "\n",
        "                    total_execution_cost += exec_time\n",
        "\n",
        "                # Load balancing penalty\n",
        "                if task_counts:\n",
        "                    # Standard deviation of task counts\n",
        "                    count_std = np.std(list(task_counts.values())) * 500\n",
        "                    # Standard deviation of resource loads\n",
        "                    load_std = np.std(list(resource_loads.values())) * 1000\n",
        "\n",
        "                    total_execution_cost += count_std + load_std\n",
        "\n",
        "                # Scale down the total cost for manageable values\n",
        "                total_execution_cost *= 0.5\n",
        "\n",
        "                return total_execution_cost\n",
        "\n",
        "            # === STEP 4: Create smart initial solution ===\n",
        "            logger.info(\"Phase 2/5: Creating initial population...\")\n",
        "\n",
        "            def create_bandwidth_aware_solution():\n",
        "                \"\"\"Generate initial solution with data size awareness\"\"\"\n",
        "                solution = {}\n",
        "                high_bw_resources = [r for r in self.resources if r.total_bandwidth >= 800]\n",
        "                med_bw_resources = [r for r in self.resources if 400 <= r.total_bandwidth < 800]\n",
        "                low_bw_resources = [r for r in self.resources if r.total_bandwidth < 400]\n",
        "\n",
        "                # Track loads for balancing\n",
        "                local_loads = {r.id: 0 for r in self.resources}\n",
        "\n",
        "                # Sort tasks by arrival time\n",
        "                for task in sorted(initial_tasks, key=lambda t: t.arrival_time):\n",
        "                    # Assign based on data size needs\n",
        "                    if task.input_size > 2.0 or task.output_size > 2.0:\n",
        "                        candidates = high_bw_resources if high_bw_resources else self.resources\n",
        "                    elif task.input_size > 0.5 or task.output_size > 0.5:\n",
        "                        candidates = med_bw_resources + high_bw_resources if med_bw_resources or high_bw_resources else self.resources\n",
        "                    else:\n",
        "                        candidates = self.resources\n",
        "\n",
        "                    # Select least loaded resource\n",
        "                    resource = min(candidates, key=lambda r: local_loads[r.id])\n",
        "                    solution[task] = resource\n",
        "                    local_loads[resource.id] += 1\n",
        "\n",
        "                return solution\n",
        "\n",
        "            # Create initial population\n",
        "            population = []\n",
        "            smart_solution = create_bandwidth_aware_solution()\n",
        "            # Log the smart solution to verify it contains valid assignments\n",
        "            logger.info(f\"Created smart solution with {len(smart_solution)} assignments\")\n",
        "            population.append(smart_solution)\n",
        "\n",
        "            # Generate diverse initial population\n",
        "            for i in range(1, population_size):\n",
        "                # Create variation of smart solution\n",
        "                solution = copy.deepcopy(smart_solution)\n",
        "\n",
        "                # Mutate a percentage of assignments\n",
        "                mutation_pct = 0.1 + (0.2 * i / population_size)  # More mutation for later solutions\n",
        "                tasks_to_mutate = random.sample(\n",
        "                    list(solution.keys()),\n",
        "                    k=max(1, int(len(solution) * mutation_pct))\n",
        "                )\n",
        "\n",
        "                for task in tasks_to_mutate:\n",
        "                    solution[task] = random.choice(self.resources)\n",
        "\n",
        "                population.append(solution)\n",
        "\n",
        "            # === STEP 5: Run Optimized Genetic Algorithm ===\n",
        "            logger.info(\"Phase 3/5: Running genetic algorithm optimization...\")\n",
        "\n",
        "            # Evaluate initial population\n",
        "            fitnesses = [simplified_fitness(sol) for sol in population]\n",
        "\n",
        "            # Track best solution\n",
        "            best_idx = fitnesses.index(min(fitnesses))\n",
        "            best_solution = copy.deepcopy(population[best_idx])\n",
        "            best_fitness = fitnesses[best_idx]\n",
        "            best_cost = simplified_fitness(best_solution)\n",
        "\n",
        "\n",
        "            # Run genetic algorithm with progress updates\n",
        "            stagnation_counter = 0\n",
        "\n",
        "            for gen in range(generations):\n",
        "                # Progress indicator\n",
        "                current_cost = simplified_fitness(best_solution)\n",
        "                logger.info(f\"Generation {gen+1}/{generations} - Current best cost: {current_cost}\")\n",
        "\n",
        "                # Sort by fitness and retain elites\n",
        "                sorted_indices = sorted(range(len(fitnesses)), key=lambda i: fitnesses[i])\n",
        "                new_population = [copy.deepcopy(population[i]) for i in sorted_indices[:elite_count]]\n",
        "\n",
        "                # Fill remaining population with crossover and mutation\n",
        "                while len(new_population) < population_size:\n",
        "                    # Tournament selection\n",
        "                    tournament_size = min(3, len(population))\n",
        "                    parent1_idx = min(random.sample(range(len(population)), tournament_size),\n",
        "                                    key=lambda i: fitnesses[i])\n",
        "                    parent2_idx = min(random.sample(range(len(population)), tournament_size),\n",
        "                                    key=lambda i: fitnesses[i])\n",
        "\n",
        "                    parent1 = population[parent1_idx]\n",
        "                    parent2 = population[parent2_idx]\n",
        "\n",
        "                    # Simplified crossover\n",
        "                    if random.random() < crossover_rate:\n",
        "                        child = {}\n",
        "\n",
        "                        # Create a random crossover point\n",
        "                        tasks_ordered = sorted(parent1.keys(), key=lambda t: t.arrival_time)\n",
        "                        crossover_point = random.randint(1, len(tasks_ordered) - 1)\n",
        "\n",
        "                        # Take first part from parent1, second from parent2\n",
        "                        for i, task in enumerate(tasks_ordered):\n",
        "                            if i < crossover_point:\n",
        "                                child[task] = parent1[task]\n",
        "                            else:\n",
        "                                # Make sure task exists in parent2\n",
        "                                if task in parent2:\n",
        "                                    child[task] = parent2[task]\n",
        "                                else:\n",
        "                                    child[task] = parent1[task]\n",
        "                    else:\n",
        "                        # No crossover, just clone parent1\n",
        "                        child = copy.deepcopy(parent1)\n",
        "\n",
        "                    # Simple mutation\n",
        "                    if random.random() < mutation_rate:\n",
        "                        mutation_count = max(1, int(len(child) * 0.1))  # Mutate about 10%\n",
        "                        tasks_to_mutate = random.sample(list(child.keys()), k=mutation_count)\n",
        "\n",
        "                        for task in tasks_to_mutate:\n",
        "                            child[task] = random.choice(self.resources)\n",
        "\n",
        "                    new_population.append(child)\n",
        "\n",
        "                # Update population\n",
        "                population = new_population\n",
        "\n",
        "                # Calculate fitness - evaluate each solution\n",
        "                fitnesses = [simplified_fitness(sol) for sol in population]\n",
        "\n",
        "                # Check for improvement\n",
        "                current_best_idx = fitnesses.index(min(fitnesses))\n",
        "                current_best_fitness = fitnesses[current_best_idx]\n",
        "\n",
        "                if current_best_fitness < best_fitness:\n",
        "                    best_solution = copy.deepcopy(population[current_best_idx])\n",
        "                    best_fitness = current_best_fitness\n",
        "                    best_cost = simplified_fitness(best_solution)\n",
        "                    logger.info(f\"✓ New best solution found! Fitness: {best_fitness}, Cost: {best_cost}\")\n",
        "                    stagnation_counter = 0\n",
        "                else:\n",
        "                    stagnation_counter += 1\n",
        "\n",
        "                # Early stopping\n",
        "                if stagnation_counter >= max_stagnation:\n",
        "                    logger.info(f\"Early stopping at generation {gen+1} (no improvement for {max_stagnation} generations)\")\n",
        "                    break\n",
        "\n",
        "            # === STEP 6: Apply focused Tabu Search to best solution ===\n",
        "            logger.info(\"Phase 4/5: Applying focused Tabu Search...\")\n",
        "\n",
        "            # Create a copy of the best solution\n",
        "            current_solution = copy.deepcopy(best_solution)\n",
        "            current_fitness = simplified_fitness(current_solution)\n",
        "            tabu_best_solution = copy.deepcopy(current_solution)\n",
        "            tabu_best_fitness = current_fitness\n",
        "\n",
        "            # Function to identify high-impact tasks (focuses on tasks with largest execution times)\n",
        "            def identify_high_impact_tasks(solution, limit=20):\n",
        "                # Calculate execution times for each task\n",
        "                task_times = []\n",
        "                for task, resource in solution.items():\n",
        "                    if resource:\n",
        "                        exec_time = fast_exec_time_estimate(task, resource.id)\n",
        "                        task_times.append((task, exec_time))\n",
        "\n",
        "                # Sort by execution time and return top tasks\n",
        "                return [task for task, _ in sorted(task_times, key=lambda x: x[1], reverse=True)[:limit]]\n",
        "\n",
        "            # Run efficient Tabu Search\n",
        "            stagnation_counter = 0\n",
        "\n",
        "            for iteration in range(tabu_iterations):\n",
        "                # Progress indicator every few iterations\n",
        "                if iteration % 5 == 0 or iteration == tabu_iterations-1:\n",
        "                    current_cost = simplified_fitness(tabu_best_solution)\n",
        "                    logger.info(f\"Tabu iteration {iteration+1}/{tabu_iterations} - Current best cost: {current_cost}\")\n",
        "\n",
        "                # Focus on most impactful tasks - consider more tasks for larger problems\n",
        "                task_limit = max(20, int(len(current_solution) * 0.2))  # At least 20 tasks or 20% of total\n",
        "                high_impact_tasks = identify_high_impact_tasks(current_solution, limit=task_limit)\n",
        "\n",
        "                # Generate and evaluate a limited set of moves\n",
        "                best_move = None\n",
        "                best_move_fitness = float('inf')\n",
        "\n",
        "                # For each high-impact task, try a few resources\n",
        "                for task in high_impact_tasks:\n",
        "                    current_resource = current_solution[task]\n",
        "\n",
        "                    # Sample a small set of resources to try\n",
        "                    sampled_resources = random.sample(self.resources, min(5, len(self.resources)))\n",
        "\n",
        "                    for resource in sampled_resources:\n",
        "                        # Skip current assignment and tabu moves\n",
        "                        if resource == current_resource or (task.id, resource.id) in tabu_list:\n",
        "                            continue\n",
        "\n",
        "                        # Evaluate the move\n",
        "                        current_solution[task] = resource\n",
        "                        move_fitness = simplified_fitness(current_solution)\n",
        "\n",
        "                        # Update best move if better\n",
        "                        if move_fitness < best_move_fitness:\n",
        "                            best_move = (task, resource)\n",
        "                            best_move_fitness = move_fitness\n",
        "\n",
        "                        # Restore current solution\n",
        "                        current_solution[task] = current_resource\n",
        "\n",
        "                # Apply best move if found\n",
        "                if best_move:\n",
        "                    task, resource = best_move\n",
        "                    current_solution[task] = resource\n",
        "                    current_fitness = best_move_fitness\n",
        "\n",
        "                    # Add to tabu list\n",
        "                    tabu_list.append((task.id, resource.id))\n",
        "\n",
        "                    # Update best solution if improved\n",
        "                    if current_fitness < tabu_best_fitness:\n",
        "                        tabu_best_solution = copy.deepcopy(current_solution)\n",
        "                        tabu_best_fitness = current_fitness\n",
        "                        stagnation_counter = 0\n",
        "                    else:\n",
        "                        stagnation_counter += 1\n",
        "                else:\n",
        "                    stagnation_counter += 1\n",
        "\n",
        "                # Early stopping\n",
        "                if stagnation_counter >= 5:\n",
        "                    logger.info(f\"Early stopping Tabu Search at iteration {iteration+1} (no improvement for 5 iterations)\")\n",
        "                    break\n",
        "\n",
        "            # === STEP 7: Select final solution and apply to resources ===\n",
        "            logger.info(\"Phase 5/5: Finalizing solution and distributing tasks...\")\n",
        "\n",
        "            # Validate solution before proceeding\n",
        "            valid_assignments = 0\n",
        "            for task, resource in tabu_best_solution.items():\n",
        "                if resource is not None:\n",
        "                    valid_assignments += 1\n",
        "\n",
        "            logger.info(f\"Validating tabu solution: {valid_assignments} valid assignments out of {len(tabu_best_solution)} tasks\")\n",
        "\n",
        "            # Check GA solution as well\n",
        "            ga_valid_assignments = 0\n",
        "            for task, resource in best_solution.items():\n",
        "                if resource is not None:\n",
        "                    ga_valid_assignments += 1\n",
        "\n",
        "            logger.info(f\"Validating GA solution: {ga_valid_assignments} valid assignments out of {len(best_solution)} tasks\")\n",
        "            tabu_cost = simplified_fitness(tabu_best_solution)\n",
        "\n",
        "            final_solution = tabu_best_solution\n",
        "            logger.info(f\"Using Tabu-improved solution (cost: {tabu_cost}, valid assignments: {valid_assignments})\")\n",
        "\n",
        "            # Calculate execution time\n",
        "            execution_time = time.time() - start_time\n",
        "\n",
        "            # Reset resources - explicitly clear queues\n",
        "            for resource in self.resources:\n",
        "                resource.task_queue = []\n",
        "                resource.failed_tasks = []\n",
        "                logger.info(f\"Reset {resource.type} queue to 0 tasks\")\n",
        "\n",
        "            # Apply solution to resources\n",
        "            distributed_tasks = []\n",
        "            assignment_data = []\n",
        "            base_time = datetime.now()\n",
        "\n",
        "            # Task distribution counts\n",
        "            resource_assignment_counts = {r.type: 0 for r in self.resources}\n",
        "            # Temporary task assignment tracking\n",
        "            temp_resource_task_queues = {resource.id: [] for resource in self.resources}\n",
        "            # Process and apply all assignments, logging each step\n",
        "            logger.info(f\"Processing {len(final_solution)} task assignments...\")\n",
        "            assignment_count = 0\n",
        "\n",
        "            # CRITICALLY IMPORTANT: Set reference to task's assigned resource\n",
        "            # This helps maintain the connection between tasks and resources\n",
        "            for task, resource in final_solution.items():\n",
        "                # Verify task is valid\n",
        "                if task is None:\n",
        "                    logger.error(\"Found None task in solution!\")\n",
        "                    continue\n",
        "\n",
        "                # Handle case where resource is None by assigning to least loaded resource\n",
        "                if resource is None:\n",
        "                    logger.warning(f\"Task {task.id} has no resource assignment, assigning to least loaded resource\")\n",
        "                    continue\n",
        "\n",
        "                # Set task status and add to queue\n",
        "                task.status = 'CREATED'  # Ensure correct initial status\n",
        "                task.assigned_resource = resource  # CRITICAL: Maintain reference to resource\n",
        "                temp_resource_task_queues[resource.id].append(task)\n",
        "                resource_assignment_counts[resource.type] += 1\n",
        "                assignment_count += 1\n",
        "\n",
        "                # Debug log for each assignment\n",
        "                logger.info(f\"Assigned Task {task.id} ({task.type}) to {resource.type}, queue now has {len(resource.task_queue)} tasks\")\n",
        "\n",
        "                # Record assignment\n",
        "                arrival_time = base_time + timedelta(seconds=task.arrival_time)\n",
        "                record = {\n",
        "                    'Task ID': task.id,\n",
        "                    'Type': task.type,\n",
        "                    'Input Size (GB)': task.input_size,\n",
        "                    'Output Size (GB)': task.output_size,\n",
        "                    'Time of Arrival': arrival_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                    'Status': task.status,\n",
        "                    'Assigned Node': resource.type if resource else 'None',\n",
        "                    'Estimated Time': fast_exec_time_estimate(task, resource.id) if resource else 'N/A'\n",
        "                }\n",
        "                assignment_data.append(record)\n",
        "                distributed_tasks.append(task)\n",
        "\n",
        "            logger.info(f\"Completed {assignment_count} task assignments\")\n",
        "\n",
        "            # Write to CSV\n",
        "            csv_folder = \"/content/drive/My Drive/CSV_dump\"\n",
        "            os.makedirs(csv_folder, exist_ok=True)\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            csv_filepath = os.path.join(csv_folder, f'optimized_hybrid_{timestamp}.csv')\n",
        "\n",
        "            with open(csv_filepath, mode='w', newline='') as csv_file:\n",
        "                fieldnames = [\n",
        "                    'Task ID', 'Type', 'Input Size (GB)', 'Output Size (GB)',\n",
        "                    'Time of Arrival', 'Status', 'Assigned Node',\n",
        "                    'Estimated Time'\n",
        "                ]\n",
        "                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "                writer.writeheader()\n",
        "                writer.writerows(assignment_data)\n",
        "\n",
        "            # Print summary\n",
        "            logger.info(\"\\n=== Optimization Complete ===\")\n",
        "            logger.info(f\"Total execution time: {execution_time:.2f} seconds\")\n",
        "            logger.info(f\"Final solution cost: {simplified_fitness(final_solution)}\")\n",
        "            logger.info(f\"Task distribution:\")\n",
        "            for resource_type, count in resource_assignment_counts.items():\n",
        "                if count > 0:\n",
        "                    logger.info(f\"  {resource_type}: {count} tasks\")\n",
        "            logger.info(f\"Results saved to: {csv_filepath}\")\n",
        "\n",
        "            # Add detailed debug information to verify task distribution\n",
        "            total_queued = 0\n",
        "            for resource in self.resources:\n",
        "                resource.task_queue = temp_resource_task_queues[resource.id]\n",
        "                logger.info(f\"Copied {len(resource.task_queue)} tasks to {resource.type} queue\")\n",
        "                queued = len(resource.task_queue)\n",
        "                total_queued += queued\n",
        "                logger.info(f\"After distribution: {resource.type} has {queued} tasks in queue\")\n",
        "\n",
        "            logger.info(f\"Total tasks queued: {total_queued} of {total_tasks} requested\")\n",
        "\n",
        "            # Ensure we always have the right number of tasks\n",
        "            # If we don't have enough tasks, apply Tabu-based logic for additional tasks\n",
        "            if total_queued < total_tasks:\n",
        "                logger.warning(f\"Distribution incomplete: only {total_queued} of {total_tasks} tasks distributed\")\n",
        "\n",
        "                # Calculate how many more tasks we need\n",
        "                tasks_needed = total_tasks - total_queued\n",
        "                logger.info(f\"Adding {tasks_needed} additional tasks using Tabu optimization logic\")\n",
        "\n",
        "                # Create additional tasks\n",
        "                additional_tasks = []\n",
        "                for i in range(tasks_needed):\n",
        "                    # Get task type\n",
        "                    task_type = list(TASK_TYPES.keys())[i % len(TASK_TYPES)]\n",
        "                    specs = TASK_TYPES[task_type]\n",
        "\n",
        "                    # Create task\n",
        "                    new_task_id = total_queued + i + 1\n",
        "                    task = Task(\n",
        "                        task_id=new_task_id,\n",
        "                        task_type=task_type,\n",
        "                        input_size=specs[\"input_size\"],\n",
        "                        output_size=specs[\"output_size\"],\n",
        "                        cpu_required=specs[\"cpu_required\"]\n",
        "                    )\n",
        "\n",
        "                    # Set arrival time\n",
        "                    task.arrival_time = datetime.now().timestamp()\n",
        "                    task.status = 'CREATED'\n",
        "                    additional_tasks.append(task)\n",
        "\n",
        "                # Apply Tabu-based assignment logic for the additional tasks\n",
        "                # First calculate current resource loads from existing assignments\n",
        "                current_loads = {r.id: len(r.task_queue) for r in self.resources}\n",
        "\n",
        "                # For each additional task, assign based on the same criteria used in Tabu Search\n",
        "                for task in additional_tasks:\n",
        "                    # Find best resource based on type compatibility and load\n",
        "                    best_resource = None\n",
        "                    best_cost = float('inf')\n",
        "\n",
        "                    for resource in self.resources:\n",
        "                        # Calculate cost based on the same logic used in Tabu Search\n",
        "                        exec_time = fast_exec_time_estimate(task, resource.id)\n",
        "\n",
        "                        # Apply the same penalties from the original solution\n",
        "                        if task.type == \"WT3\" and resource.type.startswith(\"Raspberry_\"):\n",
        "                            exec_time *= 3.0\n",
        "                        elif task.type in [\"RT1\", \"RT3\"] and resource.type.startswith(\"Cloud_\"):\n",
        "                            exec_time *= 0.1\n",
        "\n",
        "                        # Add load balancing factor\n",
        "                        load_factor = current_loads[resource.id] * 500\n",
        "                        total_cost = exec_time + load_factor\n",
        "\n",
        "                        if total_cost < best_cost:\n",
        "                            best_cost = total_cost\n",
        "                            best_resource = resource\n",
        "\n",
        "                    # Assign to the best resource\n",
        "                    if best_resource:\n",
        "                        task.assigned_resource = best_resource\n",
        "                        best_resource.task_queue.append(task)\n",
        "                        current_loads[best_resource.id] += 1\n",
        "                        distributed_tasks.append(task)\n",
        "                        logger.info(f\"Added task {task.id} ({task.type}) to {best_resource.type} using Tabu logic\")\n",
        "\n",
        "                # Verify final count\n",
        "                final_count = sum(len(r.task_queue) for r in self.resources)\n",
        "                logger.info(f\"Final distribution check: {final_count} of {total_tasks} tasks distributed\")\n",
        "\n",
        "            logger.info(f\"Returning {len(distributed_tasks)} distributed tasks\")\n",
        "            return distributed_tasks\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in Optimized Hybrid algorithm: {e}\")\n",
        "            import traceback\n",
        "            logger.error(traceback.format_exc())\n",
        "\n",
        "            # Just raise the exception instead of falling back to round-robin\n",
        "            logger.error(\"Hybrid algorithm failed without fallback mechanism enabled\")\n",
        "            raise\n",
        "    def _tabu_search_distribution(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Optimized Tabu Search for large task sets (up to 8000 tasks) - Sequential Version\n",
        "        \"\"\"\n",
        "        # Step 1: Generate tasks with optimized batch processing\n",
        "        tasks, cumulative_times, inter_arrival_times = self.generate_tasks(total_tasks)\n",
        "\n",
        "        # Define task types with cached requirements\n",
        "        TASK_TYPES = {\n",
        "            \"RT1\": {\"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "            \"RT2\": {\"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "            \"RT3\": {\"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "            \"RT4\": {\"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "            \"WT1\": {\"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "            \"WT2\": {\"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "            \"WT3\": {\"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "            \"WT4\": {\"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "        }\n",
        "\n",
        "        # Pre-compute resource capabilities with additional metrics\n",
        "        RESOURCE_CAPABILITIES = {\n",
        "            resource.id: {\n",
        "                'type': resource.type,\n",
        "                'cpu_rating': resource.total_cpu_rating,\n",
        "                'bandwidth': resource.total_bandwidth,\n",
        "                'is_cloud': resource.type.startswith(\"Cloud_\"),\n",
        "                'memory': resource.total_memory,\n",
        "                'efficiency_score': resource.total_cpu_rating / resource.total_bandwidth\n",
        "            } for resource in self.resources\n",
        "        }\n",
        "        def calculate_adaptive_tabu_tenure(current_solution, recent_improvements):\n",
        "            \"\"\"\n",
        "            Calculate adaptive tabu tenure based on recent improvement rates\n",
        "\n",
        "            Args:\n",
        "                current_solution: Current task-to-resource assignments\n",
        "                recent_improvements: Rate of improvement over recent iterations\n",
        "\n",
        "            Returns:\n",
        "                int: Adjusted tabu tenure value\n",
        "            \"\"\"\n",
        "            base_tenure = min(int(len(current_solution) * 0.025), 800)\n",
        "            if recent_improvements < 0.001:  # Stuck in local optimum\n",
        "                return int(base_tenure * 1.5)  # Increase tenure to force exploration\n",
        "            return base_tenure\n",
        "        # Optimize task object creation with batch processing\n",
        "        initial_tasks = []\n",
        "        task_lookup = {}\n",
        "        batch_size = 500  # Process tasks in larger batches\n",
        "\n",
        "        for i in range(0, total_tasks, batch_size):\n",
        "            batch_end = min(i + batch_size, total_tasks)\n",
        "            batch_tasks = []\n",
        "\n",
        "            for j in range(i, batch_end):\n",
        "                task_record = tasks[j]\n",
        "                task_type = list(TASK_TYPES.keys())[j % len(TASK_TYPES)]\n",
        "                specs = TASK_TYPES[task_type]\n",
        "\n",
        "                task = Task(\n",
        "                    task_id=task_record.id,\n",
        "                    task_type=task_type,\n",
        "                    input_size=specs[\"input_size\"],\n",
        "                    output_size=specs[\"output_size\"],\n",
        "                    cpu_required=specs[\"cpu_required\"]\n",
        "                )\n",
        "                task.arrival_time = task_record.arrival_time\n",
        "                batch_tasks.append(task)\n",
        "                task_lookup[task.id] = task\n",
        "\n",
        "            initial_tasks.extend(batch_tasks)\n",
        "\n",
        "        # Adjust parameters for large-scale optimization\n",
        "        tabu_tenure = min(int(total_tasks * 0.025), 800)  # Dynamic scaling\n",
        "\n",
        "        # With this adaptive implementation:\n",
        "        improvement_history = []  # Track improvement rates\n",
        "        current_tenure = min(int(total_tasks * 0.025), 800)  # Initial tenure\n",
        "        max_iterations = min(int(total_tasks * 0.0125), 800)\n",
        "        max_stagnation = 60\n",
        "        convergence_window = 100\n",
        "        convergence_threshold = 0.0005\n",
        "\n",
        "        tabu_list = collections.deque(maxlen=current_tenure)\n",
        "        resource_loads = {r.id: 0 for r in self.resources}\n",
        "        cost_history = []\n",
        "\n",
        "        def quick_exec_time_estimate(task, resource_id):\n",
        "            \"\"\"Enhanced execution time estimation\"\"\"\n",
        "            resource = RESOURCE_CAPABILITIES[resource_id]\n",
        "\n",
        "            # Fast path for cloud resources\n",
        "            if resource['is_cloud'] and task.type in ['RT1', 'RT3']:\n",
        "                return task.total_cpu_required / resource['cpu_rating']\n",
        "\n",
        "            # Basic estimate combining transfer and processing time\n",
        "            transfer_time = ((task.input_size + task.output_size) * 1024) / resource['bandwidth']\n",
        "            process_time = task.total_cpu_required / resource['cpu_rating']\n",
        "\n",
        "            return transfer_time + process_time\n",
        "\n",
        "        def calculate_batch_cost(assignments):\n",
        "            \"\"\"Sequential batch cost calculation\"\"\"\n",
        "            total_cost = 0\n",
        "            resource_times = {r.id: 0 for r in self.resources}\n",
        "\n",
        "\n",
        "            # Process assignments sequentially\n",
        "            for task, resource in assignments.items():\n",
        "                if not resource:\n",
        "                    total_cost += 1000000  # Penalty for unassigned tasks\n",
        "                    continue\n",
        "\n",
        "                exec_time = quick_exec_time_estimate(task, resource.id)\n",
        "                current_time = resource_times[resource.id]\n",
        "                completion_time = max(current_time, task.arrival_time) + exec_time\n",
        "                resource_times[resource.id] = completion_time\n",
        "                total_cost += exec_time\n",
        "\n",
        "                # Added Specific penalty so that WT3 will be discouraged to be assigned to Raspberry nodes\n",
        "                if task.type == \"WT3\" and resource.type.startswith(\"Raspberry_\"):\n",
        "                    total_cost += exec_time * 3 # 5x penalty makes Raspberry Pi cost higher than other alternatives\n",
        "                # Cloud penalty\n",
        "                elif resource.type.startswith(\"Cloud_\") and task.type not in ['RT1', 'RT3']:\n",
        "                    total_cost += exec_time * 0.5\n",
        "\n",
        "            # Load balancing penalty\n",
        "            loads = {r.id: 0 for r in self.resources}\n",
        "            for _, resource in assignments.items():\n",
        "                if resource:\n",
        "                    loads[resource.id] += 1\n",
        "\n",
        "            std_dev = np.std(list(loads.values()))\n",
        "            balance_penalty = std_dev * 1000\n",
        "\n",
        "            return total_cost + balance_penalty\n",
        "\n",
        "        def calculate_dynamic_moves(total_tasks):\n",
        "            base_moves = 100\n",
        "            # Scale with task count but cap at reasonable maximum\n",
        "            additional_moves = min(int(total_tasks * 0.05), 900)\n",
        "            return base_moves + additional_moves\n",
        "\n",
        "        def generate_efficient_moves(current_solution):\n",
        "            \"\"\"\n",
        "            Generate selective neighborhood moves based on task execution times and resource loads.\n",
        "\n",
        "            This version implements dynamic move scaling based on problem size while\n",
        "            maintaining efficient memory usage and move diversity.\n",
        "\n",
        "            Args:\n",
        "                current_solution: Dictionary mapping tasks to their currently assigned resources\n",
        "\n",
        "            Returns:\n",
        "                List of (task, new_resource) tuples representing possible moves\n",
        "            \"\"\"\n",
        "            # Calculate dynamic move limit\n",
        "            total_moves = calculate_dynamic_moves(len(current_solution))\n",
        "            moves = []\n",
        "\n",
        "            # Select tasks with highest execution times\n",
        "            task_times = [\n",
        "                (task, quick_exec_time_estimate(task, current_solution[task].id))\n",
        "                for task in current_solution\n",
        "                if current_solution[task]\n",
        "            ]\n",
        "\n",
        "            # Calculate 40% of total tasks for consideration\n",
        "            num_candidates = max(int(len(task_times) * 0.40), 1)\n",
        "            candidate_tasks = [\n",
        "                task for task, _ in sorted(task_times,\n",
        "                key=lambda x: x[1], reverse=True)[:num_candidates]\n",
        "            ]\n",
        "\n",
        "            logger.info(f\"Selected {len(candidate_tasks)} candidate tasks (40% of {len(task_times)} total tasks)\")\n",
        "\n",
        "            # Generate moves up to the dynamic limit\n",
        "            while len(moves) < total_moves:\n",
        "                # Randomly select a candidate task\n",
        "                task = random.choice(candidate_tasks)\n",
        "                current_resource = current_solution[task]\n",
        "\n",
        "                # Select a potential resource\n",
        "                potential_resources = [\n",
        "                    r for r in sorted(self.resources, key=lambda r: resource_loads[r.id])\n",
        "                    if r != current_resource and (task, r) not in tabu_list\n",
        "                ]\n",
        "\n",
        "                if potential_resources:\n",
        "                    new_resource = random.choice(potential_resources)\n",
        "                    move = (task, new_resource)\n",
        "                    if move not in moves:  # Avoid duplicate moves\n",
        "                        moves.append(move)\n",
        "\n",
        "            return moves\n",
        "        def generate_smart_initial_solution():\n",
        "            \"\"\"Generate initial solution with improved distribution\"\"\"\n",
        "            solution = {}\n",
        "            cloud_resources = [r for r in self.resources if r.type.startswith(\"Cloud_\")]\n",
        "            edge_resources = [r for r in self.resources if not r.type.startswith(\"Cloud_\")]\n",
        "\n",
        "            # Sort tasks by requirements\n",
        "            sorted_tasks = sorted(\n",
        "                initial_tasks,\n",
        "                key=lambda t: (t.total_cpu_required + (t.input_size + t.output_size) * 1024),\n",
        "                reverse=True\n",
        "            )\n",
        "\n",
        "            for task in sorted_tasks:\n",
        "                if task.type in ['RT1', 'RT3']:\n",
        "                    resource = min(cloud_resources, key=lambda r: resource_loads[r.id])\n",
        "                else:\n",
        "                    candidates = edge_resources if edge_resources else cloud_resources\n",
        "                    resource = min(candidates, key=lambda r: resource_loads[r.id])\n",
        "\n",
        "                solution[task] = resource\n",
        "                resource_loads[resource.id] += 1\n",
        "\n",
        "            return solution\n",
        "\n",
        "        # Main optimization loop\n",
        "        logger.info(f\"Starting Tabu Search with {total_tasks} tasks\")\n",
        "        current_solution = generate_smart_initial_solution()\n",
        "        best_solution = current_solution.copy()\n",
        "        best_cost = calculate_batch_cost(current_solution)\n",
        "\n",
        "        stagnation_counter = 0\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "    # Calculate recent improvement rate\n",
        "            if len(cost_history) >= convergence_window:\n",
        "                recent_improvements = (cost_history[-convergence_window] - cost_history[-1]) / cost_history[-convergence_window]\n",
        "                improvement_history.append(recent_improvements)\n",
        "\n",
        "                # Update tabu tenure adaptively\n",
        "                current_tenure = calculate_adaptive_tabu_tenure(\n",
        "                    current_solution,\n",
        "                    sum(improvement_history[-10:]) / min(10, len(improvement_history))  # Average recent improvements\n",
        "                )\n",
        "                tabu_list = collections.deque(list(tabu_list), maxlen=current_tenure)\n",
        "\n",
        "            moves = generate_efficient_moves(current_solution)\n",
        "            if not moves:\n",
        "                break\n",
        "\n",
        "            # Sequential move evaluation\n",
        "            best_move = None\n",
        "            best_move_cost = float('inf')\n",
        "\n",
        "            for move in moves:\n",
        "                task, new_resource = move\n",
        "                temp_solution = current_solution.copy()\n",
        "                temp_solution[task] = new_resource\n",
        "                move_cost = calculate_batch_cost(temp_solution)\n",
        "\n",
        "                if move_cost < best_move_cost:\n",
        "                    best_move = move\n",
        "                    best_move_cost = move_cost\n",
        "\n",
        "            # Apply best move\n",
        "            if best_move:\n",
        "                task, new_resource = best_move\n",
        "                current_solution[task] = new_resource\n",
        "                tabu_list.append(best_move)\n",
        "\n",
        "                if best_move_cost < best_cost:\n",
        "                    best_solution = current_solution.copy()\n",
        "                    best_cost = best_move_cost\n",
        "                    stagnation_counter = 0\n",
        "                else:\n",
        "                    stagnation_counter += 1\n",
        "\n",
        "            # Check convergence\n",
        "            cost_history.append(best_cost)\n",
        "            if len(cost_history) >= convergence_window:\n",
        "                improvement = (cost_history[-convergence_window] - cost_history[-1]) / cost_history[-convergence_window]\n",
        "                if improvement < convergence_threshold:\n",
        "                    logger.info(f\"Convergence reached at iteration {iteration}\")\n",
        "                    break\n",
        "\n",
        "            # Early stopping check\n",
        "            if stagnation_counter >= max_stagnation:\n",
        "                logger.info(f\"Early stopping at iteration {iteration} due to stagnation\")\n",
        "                break\n",
        "\n",
        "            if iteration % 10 == 0:\n",
        "                logger.info(f\"Iteration {iteration}: Current best cost = {best_cost}\")\n",
        "\n",
        "        # Convert solution to task assignments\n",
        "        distributed_tasks = []\n",
        "        assignment_data = []\n",
        "        base_time = datetime.now()\n",
        "\n",
        "        # Reset resources\n",
        "        for resource in self.resources:\n",
        "            resource.task_queue = []\n",
        "            resource.failed_tasks = []\n",
        "\n",
        "        # Apply final solution\n",
        "        for task, resource in best_solution.items():\n",
        "            if resource:\n",
        "                task.status = 'READY'\n",
        "                resource.task_queue.append(task)\n",
        "            else:\n",
        "                task.status = 'FAILED'\n",
        "                task.failure_reason = \"No compatible resource found\"\n",
        "                least_loaded = min(self.resources, key=lambda r: len(r.task_queue))\n",
        "                least_loaded.failed_tasks.append(task)\n",
        "\n",
        "            arrival_time = base_time + timedelta(seconds=task.arrival_time)\n",
        "            record = {\n",
        "                'Task ID': task.id,\n",
        "                'Type': task.type,\n",
        "                'Input Size (GB)': task.input_size,\n",
        "                'Output Size (GB)': task.output_size,\n",
        "                'Time of Arrival': arrival_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                'Status': task.status,\n",
        "                'Assigned Node': resource.type if resource else 'None',\n",
        "                'Estimated Time': quick_exec_time_estimate(task, resource.id) if resource else 'N/A'\n",
        "            }\n",
        "            assignment_data.append(record)\n",
        "            distributed_tasks.append(task)\n",
        "\n",
        "        # Write final assignments to CSV\n",
        "        self._write_tabu_assignments_to_csv(assignment_data)\n",
        "\n",
        "        logger.info(f\"Tabu Search completed. Distributed {len(distributed_tasks)} tasks\")\n",
        "        return distributed_tasks\n",
        "    def _shortest_job_first_distribution(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Distribute tasks using Shortest Job First approach. Tasks are sorted by estimated\n",
        "        execution time before distribution, while maintaining original task validation logic.\n",
        "        \"\"\"\n",
        "        # Step 1: Generate tasks and arrival times\n",
        "        tasks, cumulative_times, inter_arrival_times = self.generate_tasks(total_tasks)\n",
        "\n",
        "        # Define task types with input/output sizes\n",
        "        task_types = [\n",
        "            # Read Tasks: input_size > 0, output_size = 0\n",
        "            {\"type\": \"RT1\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"RT2\", \"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "            {\"type\": \"RT3\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "            {\"type\": \"RT4\", \"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "            # Write Tasks: input_size = 0, output_size > 0\n",
        "            {\"type\": \"WT1\", \"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"WT2\", \"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "            {\"type\": \"WT3\", \"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "            {\"type\": \"WT4\", \"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "        ]\n",
        "\n",
        "        # Step 2: Create temporary tasks with execution time estimates\n",
        "        task_estimates = []\n",
        "        for task_record in tasks:\n",
        "            task_type = task_types[task_record.id % len(task_types)]\n",
        "\n",
        "            # Create temporary task for estimation\n",
        "            temp_task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "\n",
        "            # Find minimum execution time across all compatible resources\n",
        "            min_execution_time = float('inf')\n",
        "            for resource in self.resources:\n",
        "                can_process, _ = resource.can_process_task(temp_task)\n",
        "                if can_process:\n",
        "                    estimated_time = temp_task.estimate_execution_time(resource)\n",
        "                    min_execution_time = min(min_execution_time, estimated_time)\n",
        "\n",
        "            task_estimates.append({\n",
        "                'task_record': task_record,\n",
        "                'task_type': task_type,\n",
        "                'estimated_time': min_execution_time\n",
        "            })\n",
        "\n",
        "        # Step 3: Sort tasks by estimated execution time\n",
        "        sorted_tasks = sorted(task_estimates, key=lambda x: x['estimated_time'])\n",
        "\n",
        "        # Step 4: Create resource task map\n",
        "        resource_task_map = {resource.id: {'can_process': [], 'cannot_process': []}\n",
        "                            for resource in self.resources}\n",
        "\n",
        "        # Step 5: Pre-validate tasks (keeping original validation logic)\n",
        "        for task_info in sorted_tasks:\n",
        "            task_type = task_info['task_type']\n",
        "            task_record = task_info['task_record']\n",
        "\n",
        "            temp_task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "\n",
        "            for resource in self.resources:\n",
        "                can_process, reason = resource.can_process_task(temp_task)\n",
        "                if can_process:\n",
        "                    resource_task_map[resource.id]['can_process'].append(task_record)\n",
        "                else:\n",
        "                    resource_task_map[resource.id]['cannot_process'].append(task_record)\n",
        "\n",
        "        # Step 6: Reset resources\n",
        "        for resource in self.resources:\n",
        "            resource.task_queue = []\n",
        "            resource.failed_tasks = []\n",
        "\n",
        "        # Step 7: Distribute sorted tasks\n",
        "        distributed_tasks = []\n",
        "        resource_index = 0\n",
        "        csv_data = []\n",
        "        base_time = datetime.now()\n",
        "\n",
        "        for task_info in sorted_tasks:\n",
        "            task_record = task_info['task_record']\n",
        "            task_type = task_info['task_type']\n",
        "            resource = self.resources[resource_index]\n",
        "\n",
        "            # Create the actual task\n",
        "            task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "            task.arrival_time = task_record.arrival_time\n",
        "\n",
        "            arrival_time = base_time + timedelta(seconds=task_record.arrival_time)\n",
        "            assigned_node = resource.type\n",
        "\n",
        "            # Check if resource can process this task\n",
        "            if task_record in resource_task_map[resource.id]['can_process']:\n",
        "                task.status = 'READY'\n",
        "                resource.task_queue.append(task)\n",
        "            else:\n",
        "                task.status = 'FAILED'\n",
        "                task.failure_reason = f\"Cannot process on {resource.type}\"\n",
        "                resource.failed_tasks.append(task)\n",
        "\n",
        "            # Record task assignment\n",
        "            csv_data.append({\n",
        "                'Task ID': task.id,\n",
        "                'Type': task.type,\n",
        "                'Input Size': task_type[\"input_size\"],\n",
        "                'Output Size': task_type[\"output_size\"],\n",
        "                'Time of Arrival': arrival_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                'Status': task.status,\n",
        "                'Assigned Node': assigned_node,\n",
        "                'Estimated Time': task_info['estimated_time']\n",
        "            })\n",
        "\n",
        "            distributed_tasks.append(task)\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        # Logging and verification steps\n",
        "        logger.info(\"\\n=== Task Distribution Summary (SJF) ===\")\n",
        "        logger.info(f\"Total tasks requested: {total_tasks}\")\n",
        "\n",
        "        # Resource breakdown\n",
        "        for resource in self.resources:\n",
        "            queued = len(resource.task_queue)\n",
        "            failed = len(resource.failed_tasks)\n",
        "            logger.info(\n",
        "                f\"{resource.type}: \"\n",
        "                f\"Queue={queued}, Failed={failed}, \"\n",
        "                f\"Total={queued + failed}\"\n",
        "            )\n",
        "\n",
        "        # Verify counts\n",
        "        distributed_count = len(distributed_tasks)\n",
        "        queued_count = sum(len(r.task_queue) for r in self.resources)\n",
        "        failed_count = sum(len(r.failed_tasks) for r in self.resources)\n",
        "        total_count = queued_count + failed_count\n",
        "\n",
        "        logger.info(f\"Tasks distributed: {distributed_count}\")\n",
        "        logger.info(f\"Tasks queued: {queued_count}\")\n",
        "        logger.info(f\"Tasks failed: {failed_count}\")\n",
        "        logger.info(f\"Total count: {total_count}\")\n",
        "\n",
        "        assert distributed_count == total_tasks, \\\n",
        "            f\"Distribution count mismatch: {distributed_count} != {total_tasks}\"\n",
        "        assert total_count == total_tasks, \\\n",
        "            f\"Total count mismatch: {total_count} != {total_tasks}\"\n",
        "        assert len(set(t.id for t in distributed_tasks)) == total_tasks, \\\n",
        "            f\"Task ID uniqueness violation\"\n",
        "\n",
        "        # Write data to CSV\n",
        "        self.write_tasks_to_sjf_csv(csv_data)\n",
        "\n",
        "        return distributed_tasks\n",
        "    def _round_robin_distribution(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Distribute tasks using Round Robin approach\n",
        "        \"\"\"\n",
        "        # Step 1: Generate tasks and arrival times\n",
        "        tasks, cumulative_times, inter_arrival_times = self.generate_tasks(total_tasks)\n",
        "\n",
        "        # Step 1: Define task types with input/output sizes\n",
        "        task_types = [\n",
        "            # Read Tasks: input_size > 0, output_size = 0\n",
        "            {\"type\": \"RT1\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"RT2\", \"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "            {\"type\": \"RT3\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "            {\"type\": \"RT4\", \"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "            # Write Tasks: input_size = 0, output_size > 0\n",
        "            {\"type\": \"WT1\", \"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"WT2\", \"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "            {\"type\": \"WT3\", \"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "            {\"type\": \"WT4\", \"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "        ]\n",
        "\n",
        "        # Step 2: Create resource task map\n",
        "        resource_task_map = {resource.id: {'can_process': [], 'cannot_process': []}\n",
        "                            for resource in self.resources}\n",
        "\n",
        "        # Step 3: Pre-validate tasks\n",
        "        for task_record in tasks:\n",
        "            task_type = task_types[task_record.id % len(task_types)]\n",
        "\n",
        "            temp_task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "\n",
        "            for resource in self.resources:\n",
        "                can_process, reason = resource.can_process_task(temp_task)\n",
        "                if can_process:\n",
        "                    resource_task_map[resource.id]['can_process'].append(task_record)\n",
        "                else:\n",
        "                    resource_task_map[resource.id]['cannot_process'].append(task_record)\n",
        "\n",
        "        # Step 4: Reset resources\n",
        "        for resource in self.resources:\n",
        "            resource.task_queue = []\n",
        "            resource.failed_tasks = []\n",
        "\n",
        "        # Step 5: Distribute tasks\n",
        "        distributed_tasks = []\n",
        "        resource_index = 0\n",
        "        csv_data = []\n",
        "        base_time = datetime.now()\n",
        "\n",
        "        for task_record in tasks:\n",
        "            resource = self.resources[resource_index]\n",
        "\n",
        "            # Determine task type\n",
        "            task_type = task_types[task_record.id % len(task_types)]\n",
        "\n",
        "            task = Task(\n",
        "                task_id=task_record.id,\n",
        "                task_type=task_type[\"type\"],\n",
        "                input_size=task_type[\"input_size\"],\n",
        "                output_size=task_type[\"output_size\"],\n",
        "                cpu_required=task_type[\"cpu_required\"]\n",
        "            )\n",
        "            task.arrival_time = task_record.arrival_time\n",
        "\n",
        "            arrival_time = base_time + timedelta(seconds=task_record.arrival_time)\n",
        "            assigned_node = resource.type\n",
        "\n",
        "            if task_record in resource_task_map[resource.id]['can_process']:\n",
        "                task.status = 'READY'\n",
        "                resource.task_queue.append(task)\n",
        "            else:\n",
        "                task.status = 'FAILED'\n",
        "                task.failure_reason = f\"Cannot process on {resource.type}\"\n",
        "                resource.failed_tasks.append(task)\n",
        "\n",
        "            csv_data.append({\n",
        "                'Task ID': task.id,\n",
        "                'Type': task.type,\n",
        "                'Input Size': task_type[\"input_size\"],\n",
        "                'Output Size': task_type[\"output_size\"],\n",
        "                'Time of Arrival': arrival_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                'Status': task.status,\n",
        "                'Assigned Node': assigned_node\n",
        "            })\n",
        "\n",
        "            distributed_tasks.append(task)\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        # Logging and verification steps\n",
        "        logger.info(\"\\n=== Task Distribution Summary ===\")\n",
        "        logger.info(f\"Total tasks requested: {total_tasks}\")\n",
        "\n",
        "        # Resource breakdown\n",
        "        for resource in self.resources:\n",
        "            queued = len(resource.task_queue)\n",
        "            failed = len(resource.failed_tasks)\n",
        "            logger.info(\n",
        "                f\"{resource.type}: \"\n",
        "                f\"Queue={queued}, Failed={failed}, \"\n",
        "                f\"Total={queued + failed}\"\n",
        "            )\n",
        "\n",
        "        # Verify counts\n",
        "        distributed_count = len(distributed_tasks)\n",
        "        queued_count = sum(len(r.task_queue) for r in self.resources)\n",
        "        failed_count = sum(len(r.failed_tasks) for r in self.resources)\n",
        "        total_count = queued_count + failed_count\n",
        "\n",
        "        logger.info(f\"Tasks distributed: {distributed_count}\")\n",
        "        logger.info(f\"Tasks queued: {queued_count}\")\n",
        "        logger.info(f\"Tasks failed: {failed_count}\")\n",
        "        logger.info(f\"Total count: {total_count}\")\n",
        "\n",
        "        assert distributed_count == total_tasks, \\\n",
        "            f\"Distribution count mismatch: {distributed_count} != {total_tasks}\"\n",
        "        assert total_count == total_tasks, \\\n",
        "            f\"Total count mismatch: {total_count} != {total_tasks}\"\n",
        "        assert len(set(t.id for t in distributed_tasks)) == total_tasks, \\\n",
        "            f\"Task ID uniqueness violation\"\n",
        "\n",
        "        # Write data to CSV\n",
        "        self.write_tasks_to_csv(csv_data)\n",
        "\n",
        "        return distributed_tasks\n",
        "    def _Default_distribute_tasks(self, total_tasks: int) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Guaranteed distribution of exactly total_tasks tasks.\n",
        "        Uses pre-validation, strict counting, and saves distribution data to CSV.\n",
        "        \"\"\"\n",
        "        tasks, cumulative_times, inter_arrival_times = self.generate_tasks(total_tasks)\n",
        "\n",
        "        # Step 1: Define task types with input/output sizes\n",
        "        task_types = [\n",
        "            # Read Tasks: input_size > 0, output_size = 0\n",
        "            {\"type\": \"RT1\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"RT2\", \"input_size\": 0.2, \"output_size\": 0, \"cpu_required\": 4_000_000},\n",
        "            {\"type\": \"RT3\", \"input_size\": 5.0, \"output_size\": 0, \"cpu_required\": 200_000},\n",
        "            {\"type\": \"RT4\", \"input_size\": 0.5, \"output_size\": 0, \"cpu_required\": 500_000},\n",
        "            # Write Tasks: input_size = 0, output_size > 0\n",
        "            {\"type\": \"WT1\", \"input_size\": 0, \"output_size\": 2.0, \"cpu_required\": 2_000_000},\n",
        "            {\"type\": \"WT2\", \"input_size\": 0, \"output_size\": 0.5, \"cpu_required\": 1_000_000},\n",
        "            {\"type\": \"WT3\", \"input_size\": 0, \"output_size\": 5.0, \"cpu_required\": 500_000},\n",
        "            {\"type\": \"WT4\", \"input_size\": 0, \"output_size\": 0.2, \"cpu_required\": 200_000}\n",
        "        ]\n",
        "\n",
        "        # Step 2: Generate task records\n",
        "        task_records = []\n",
        "        for i, arrival_time in enumerate(cumulative_times):\n",
        "            task_type = task_types[i % len(task_types)]\n",
        "            task_records.append({\n",
        "                'id': i + 1,\n",
        "                'type': task_type[\"type\"],\n",
        "                'input_size': task_type[\"input_size\"],\n",
        "                'output_size': task_type[\"output_size\"],\n",
        "                'cpu_required': task_type[\"cpu_required\"],\n",
        "                'arrival_time': arrival_time\n",
        "            })\n",
        "\n",
        "        # Step 3: Create resource task map\n",
        "        resource_task_map = {resource.id: {'can_process': [], 'cannot_process': []}\n",
        "                            for resource in self.resources}\n",
        "\n",
        "        # Step 4: Pre-validate tasks\n",
        "        for task_record in task_records:\n",
        "            temp_task = Task(\n",
        "                task_id=task_record['id'],\n",
        "                task_type=task_record['type'],\n",
        "                input_size=task_record['input_size'],\n",
        "                output_size=task_record['output_size'],\n",
        "                cpu_required=task_record['cpu_required']\n",
        "            )\n",
        "\n",
        "            for resource in self.resources:\n",
        "                can_process, reason = resource.can_process_task(temp_task)\n",
        "                if can_process:\n",
        "                    resource_task_map[resource.id]['can_process'].append(task_record)\n",
        "                else:\n",
        "                    resource_task_map[resource.id]['cannot_process'].append(task_record)\n",
        "\n",
        "        # Step 5: Reset resources\n",
        "        for resource in self.resources:\n",
        "            resource.task_queue = []\n",
        "            resource.failed_tasks = []\n",
        "\n",
        "        # Step 6: Distribute tasks\n",
        "        distributed_tasks = []\n",
        "        resource_index = 0\n",
        "        csv_data = []\n",
        "        base_time = datetime.now()\n",
        "\n",
        "        for task_record in task_records:\n",
        "            resource = self.resources[resource_index]\n",
        "\n",
        "            task = Task(\n",
        "                task_id=task_record['id'],\n",
        "                task_type=task_record['type'],\n",
        "                input_size=task_record['input_size'],\n",
        "                output_size=task_record['output_size'],\n",
        "                cpu_required=task_record['cpu_required']\n",
        "            )\n",
        "            task.arrival_time = task_record['arrival_time']\n",
        "\n",
        "            arrival_time = base_time + timedelta(seconds=task_record['arrival_time'])\n",
        "            assigned_node = resource.type\n",
        "\n",
        "            if task_record in resource_task_map[resource.id]['can_process']:\n",
        "                task.status = 'READY'  # Changed from 'queued' to match Task class states\n",
        "                resource.task_queue.append(task)\n",
        "            else:\n",
        "                task.status = 'FAILED'  # Changed from 'failed' to match Task class states\n",
        "                task.failure_reason = f\"Cannot process on {resource.type}\"\n",
        "                resource.failed_tasks.append(task)\n",
        "\n",
        "            csv_data.append({\n",
        "                'Task ID': task.id,\n",
        "                'Type': task.type,\n",
        "                'Input Size': task_record['input_size'],\n",
        "                'Output Size': task_record['output_size'],\n",
        "                'Time of Arrival': arrival_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                'Status': task.status,\n",
        "                'Assigned Node': assigned_node\n",
        "            })\n",
        "\n",
        "            distributed_tasks.append(task)\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        # Step 7: Verify counts\n",
        "        distributed_count = len(distributed_tasks)\n",
        "        queued_count = sum(len(r.task_queue) for r in self.resources)\n",
        "        failed_count = sum(len(r.failed_tasks) for r in self.resources)\n",
        "        total_count = queued_count + failed_count\n",
        "\n",
        "        # Log summary\n",
        "        logger.info(\"\\n=== Task Distribution Summary ===\")\n",
        "        logger.info(f\"Total tasks requested: {total_tasks}\")\n",
        "        logger.info(f\"Tasks distributed: {distributed_count}\")\n",
        "        logger.info(f\"Tasks queued: {queued_count}\")\n",
        "        logger.info(f\"Tasks failed: {failed_count}\")\n",
        "        logger.info(f\"Total count: {total_count}\")\n",
        "\n",
        "        # Resource breakdown\n",
        "        for resource in self.resources:\n",
        "            queued = len(resource.task_queue)\n",
        "            failed = len(resource.failed_tasks)\n",
        "            logger.info(\n",
        "                f\"{resource.type}: \"\n",
        "                f\"Queue={queued}, Failed={failed}, \"\n",
        "                f\"Total={queued + failed}\"\n",
        "            )\n",
        "\n",
        "        # Verify counts\n",
        "        assert distributed_count == total_tasks, \\\n",
        "            f\"Distribution count mismatch: {distributed_count} != {total_tasks}\"\n",
        "        assert total_count == total_tasks, \\\n",
        "            f\"Total count mismatch: {total_count} != {total_tasks}\"\n",
        "        assert len(set(t.id for t in distributed_tasks)) == total_tasks, \\\n",
        "            f\"Task ID uniqueness violation\"\n",
        "\n",
        "        # Write data to CSV\n",
        "        self.write_tasks_to_csv(csv_data)\n",
        "\n",
        "        return distributed_tasks\n",
        "\n",
        "    def write_tasks_to_sjf_csv(self, task_data):\n",
        "        \"\"\"\n",
        "        Write task distribution data to CSV with updated filename for SJF algorithm\n",
        "        \"\"\"\n",
        "        # Create CSV folder if it doesn't exist\n",
        "        csv_folder = \"/content/drive/My Drive/CSV_dump\"\n",
        "        if not os.path.exists(csv_folder):\n",
        "            os.makedirs(csv_folder)\n",
        "\n",
        "        # Generate filename with timestamp and 'sjf' identifier\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        csv_filepath = os.path.join(csv_folder, f'sjf_task_distribution_{timestamp}.csv')\n",
        "\n",
        "        # Define CSV fields\n",
        "        fieldnames = [\n",
        "            'Task ID', 'Type', 'Input Size (GB)', 'Output Size (GB)',\n",
        "            'Time of Arrival', 'Start Time', 'Input Transfer Time',\n",
        "            'Processing Time', 'Output Transfer Time', 'Total Time',\n",
        "            'Status', 'Assigned Node', 'Estimated Time'\n",
        "        ]\n",
        "\n",
        "        # Write data to CSV\n",
        "        with open(csv_filepath, mode='w', newline='') as csv_file:\n",
        "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            for task in task_data:\n",
        "                writer.writerow({\n",
        "                    'Task ID': task['Task ID'],\n",
        "                    'Type': task['Type'],\n",
        "                    'Input Size (GB)': task.get('Input Size', 0),\n",
        "                    'Output Size (GB)': task.get('Output Size', 0),\n",
        "                    'Time of Arrival': task['Time of Arrival'],\n",
        "                    'Start Time': task.get('Start Time', ''),\n",
        "                    'Input Transfer Time': task.get('Input Transfer Time', ''),\n",
        "                    'Processing Time': task.get('Processing Time', ''),\n",
        "                    'Output Transfer Time': task.get('Output Transfer Time', ''),\n",
        "                    'Total Time': task.get('Total Time', ''),\n",
        "                    'Status': task['Status'],\n",
        "                    'Assigned Node': task['Assigned Node'],\n",
        "                    'Estimated Time': task.get('Estimated Time', 'N/A')\n",
        "                })\n",
        "\n",
        "        logger.info(f\"Task distribution data written to {csv_filepath}\")\n",
        "        return csv_filepath\n",
        "\n",
        "    def write_tasks_to_csv(self, task_data):\n",
        "        \"\"\"\n",
        "        Updated CSV output to include transfer phases and data sizes\n",
        "        \"\"\"\n",
        "        csv_folder = \"/content/drive/My Drive/CSV_dump\"\n",
        "        if not os.path.exists(csv_folder):\n",
        "            os.makedirs(csv_folder)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        csv_filepath = os.path.join(csv_folder, f'round_robin_distribution_{timestamp}.csv')\n",
        "\n",
        "        # Updated fieldnames to include transfer information\n",
        "        fieldnames = [\n",
        "            'Task ID', 'Type', 'Input Size (GB)', 'Output Size (GB)',\n",
        "            'Time of Arrival', 'Start Time', 'Input Transfer Time',\n",
        "            'Processing Time', 'Output Transfer Time', 'Total Time',\n",
        "            'Status', 'Assigned Node'\n",
        "        ]\n",
        "\n",
        "        with open(csv_filepath, mode='w', newline='') as csv_file:\n",
        "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            for task in task_data:\n",
        "                writer.writerow({\n",
        "                    'Task ID': task['Task ID'],\n",
        "                    'Type': task['Type'],\n",
        "                    'Input Size (GB)': task.get('input_size', 0),\n",
        "                    'Output Size (GB)': task.get('output_size', 0),\n",
        "                    'Time of Arrival': task['Time of Arrival'],\n",
        "                    'Start Time': task.get('start_time', ''),\n",
        "                    'Input Transfer Time': task.get('input_transfer_time', ''),\n",
        "                    'Processing Time': task.get('processing_time', ''),\n",
        "                    'Output Transfer Time': task.get('output_transfer_time', ''),\n",
        "                    'Total Time': task.get('total_time', ''),\n",
        "                    'Status': task['Status'],\n",
        "                    'Assigned Node': task['Assigned Node']\n",
        "                })\n",
        "\n",
        "        logger.info(f\"Task distribution data written to {csv_filepath}\")\n",
        "\n",
        "        # Flush and sync to ensure all data is written to the drive\n",
        "        logger.info(\"Google Drive has been unmounted. You can now access the CSV file in your Google Drive.\")\n",
        "    def distribute_tasks(self, total_tasks: int, distribution_type: str = 'default') -> List[Task]:\n",
        "        \"\"\"\n",
        "        Enhanced distribution method with verification and emergency fallback\n",
        "        \"\"\"\n",
        "        # Mapping of distribution strategies\n",
        "        distribution_strategies = {\n",
        "            'default': self._Default_distribute_tasks,\n",
        "            'round_robin': self._round_robin_distribution,\n",
        "            'shortest_job_first': self._shortest_job_first_distribution,\n",
        "            'tabu_search': self._tabu_search_distribution,\n",
        "            'hybrid': self._optimized_hybrid_algorithm\n",
        "        }\n",
        "\n",
        "        # Select and execute the appropriate distribution strategy\n",
        "        if distribution_type in distribution_strategies:\n",
        "            try:\n",
        "                logger.info(f\"Using {distribution_type} distribution strategy for {total_tasks} tasks\")\n",
        "\n",
        "                # First attempt with selected algorithm\n",
        "                distributed_tasks = distribution_strategies[distribution_type](total_tasks)\n",
        "\n",
        "                # Verify tasks were actually queued and fix if needed\n",
        "                total_queued = sum(len(resource.task_queue) for resource in self.resources)\n",
        "                if total_queued < total_tasks:\n",
        "                    logger.warning(f\"Verification failed: Only {total_queued} of {total_tasks} queued after {distribution_type}\")\n",
        "                    distributed_tasks = self.verify_and_fix_task_distribution(total_tasks)\n",
        "\n",
        "                return distributed_tasks\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in {distribution_type} distribution: {e}\")\n",
        "                logger.info(\"Falling back to emergency distribution due to error\")\n",
        "                return self.verify_and_fix_task_distribution(total_tasks)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distribution type: {distribution_type}. \"\n",
        "                            f\"Supported types are: {list(distribution_strategies.keys())}\")\n",
        "\n",
        "    def _write_tabu_assignments_to_csv(self, assignment_data):\n",
        "        \"\"\"Helper method to write Tabu Search assignments to CSV with total cost.\"\"\"\n",
        "        csv_folder = \"/content/drive/My Drive/CSV_dump\"\n",
        "        os.makedirs(csv_folder, exist_ok=True)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        csv_filepath = os.path.join(csv_folder, f'tabu_task_distribution_{timestamp}.csv')\n",
        "\n",
        "        # Calculate total cost for each task when written\n",
        "        for task_record in assignment_data:\n",
        "            # Skip if no resource assigned\n",
        "            if task_record['Assigned Node'] == 'None':\n",
        "                task_record['Total Cost'] = 'N/A'\n",
        "                continue\n",
        "\n",
        "            # Base execution time\n",
        "            base_cost = float(task_record['Estimated Time'])\n",
        "            total_cost = base_cost\n",
        "\n",
        "            # Add WT3-Raspberry penalty if applicable\n",
        "            if task_record['Type'] == 'WT3' and task_record['Assigned Node'].startswith('Raspberry_'):\n",
        "                total_cost += base_cost * 3  # 5x penalty\n",
        "\n",
        "            # Add cloud penalty if applicable\n",
        "            elif task_record['Assigned Node'].startswith('Cloud_') and task_record['Type'] not in ['RT1', 'RT3']:\n",
        "                total_cost += base_cost * 0.5\n",
        "\n",
        "            task_record['Total Cost'] = f\"{total_cost:.2f}\"\n",
        "\n",
        "        fieldnames = [\n",
        "            'Task ID', 'Type', 'Input Size (GB)', 'Output Size (GB)',\n",
        "            'Time of Arrival', 'Status', 'Assigned Node', 'Estimated Time',\n",
        "            'Total Cost'  # Added Total Cost field\n",
        "        ]\n",
        "\n",
        "        with open(csv_filepath, mode='w', newline='') as csv_file:\n",
        "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(assignment_data)\n",
        "\n",
        "        logger.info(f\"Task assignments with costs written to {csv_filepath}\")\n",
        "        return csv_filepath\n",
        "\n",
        "    def generate_live_feed(self):\n",
        "        \"\"\"\n",
        "        Updated live visualization to show transfer phases\n",
        "        \"\"\"\n",
        "        table = Table(\n",
        "            title=\"Live Resource Processing Status\",\n",
        "            box=box.MINIMAL_DOUBLE_HEAD,\n",
        "            show_header=True,\n",
        "            header_style=\"bold magenta\",\n",
        "            border_style=\"bold green\",\n",
        "            show_lines=True,\n",
        "            padding=(0, 1)\n",
        "        )\n",
        "\n",
        "        # Updated columns to show transfer phases\n",
        "        table.add_column(\"Resource\", style=\"bold blue\", width=15)\n",
        "        table.add_column(\"Type\", style=\"bold cyan\", width=20)\n",
        "        table.add_column(\"Current Task\", style=\"bold yellow\", width=15)\n",
        "        table.add_column(\"Phase\", style=\"bold green\", width=26)\n",
        "        table.add_column(\"Progress\", style=\"bold red\", width=18)\n",
        "        table.add_column(\"Data Size\", style=\"bold yellow\", width=18)\n",
        "        table.add_column(\"Queue\", style=\"bold green\", width=15)\n",
        "        table.add_column(\"Completed\", style=\"bold magenta\", width=15)\n",
        "        table.add_column(\"Failed\", style=\"bold red\", width=15)\n",
        "\n",
        "        for resource in self.resources:\n",
        "            current_task = \"None\"\n",
        "            phase = \"Idle\"\n",
        "            progress = \"N/A\"\n",
        "            data_size = \"N/A\"\n",
        "\n",
        "            if resource.current_task:\n",
        "                task = resource.current_task\n",
        "                current_task = f\"{task.id} ({task.type})\"\n",
        "\n",
        "                # Phase and progress based on task status\n",
        "                phase_colors = {\n",
        "                    'TRANSFERRING_INPUT': \"yellow\",\n",
        "                    'PROCESSING': \"blue\",\n",
        "                    'TRANSFERRING_OUTPUT': \"cyan\",\n",
        "                    'COMPLETED': \"green\"\n",
        "                }\n",
        "\n",
        "                phase = task.status\n",
        "                progress = f\"{task.completion_percentage:.1f}%\"\n",
        "\n",
        "                # Show relevant data size based on phase\n",
        "                if task.status == 'TRANSFERRING_INPUT':\n",
        "                    data_size = f\"↑{task.input_size:.1f}GB\"\n",
        "                elif task.status == 'TRANSFERRING_OUTPUT':\n",
        "                    data_size = f\"↓{task.output_size:.1f}GB\"\n",
        "                else:\n",
        "                    data_size = f\"↕{max(task.input_size, task.output_size):.1f}GB\"\n",
        "\n",
        "            # Add row with updated information\n",
        "            table.add_row(\n",
        "                f\"{resource.id:<8}\",\n",
        "                f\"{resource.type:<11}\",\n",
        "                current_task,\n",
        "                phase,\n",
        "                progress,\n",
        "                data_size,\n",
        "                f\"{len(resource.task_queue):<5}\",\n",
        "                f\"{len(resource.completed_tasks):<9}\",\n",
        "                str(len(resource.failed_tasks))\n",
        "            )\n",
        "\n",
        "        return table\n",
        "    def write_simulation_results(self, metrics, start_time, distribution_type):\n",
        "        \"\"\"\n",
        "        Write simulation results to CSV file\n",
        "\n",
        "        Args:\n",
        "            metrics (dict): Simulation metrics\n",
        "            start_time (float): Simulation start timestamp\n",
        "            distribution_type (str): Type of distribution algorithm used\n",
        "        \"\"\"\n",
        "        csv_folder = \"/content/drive/My Drive/EdgeSimPy/results\"\n",
        "        if not os.path.exists(csv_folder):\n",
        "            os.makedirs(csv_folder)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        csv_filepath = os.path.join(csv_folder, f'run_simulation_results_{distribution_type}_{timestamp}.csv')\n",
        "\n",
        "        # Prepare simulation results\n",
        "        results = {\n",
        "            'Distribution_Algorithm': distribution_type,\n",
        "            'Simulation_Start_Time': datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'Simulation_End_Time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'Total_Tasks': metrics['total_tasks'],\n",
        "            'Completed_Tasks': metrics['completed_tasks'],\n",
        "            'Failed_Tasks': metrics['failed_tasks'],\n",
        "            'Makespan': f\"{metrics['makespan']:.2f}s\",\n",
        "            'Throughput': f\"{metrics['throughput']:.2f} tasks/s\",\n",
        "        }\n",
        "\n",
        "        # Add load balancing metrics if available\n",
        "        # Add utilization variability metrics if available\n",
        "        if 'load_balancing_metrics' in metrics:\n",
        "            # Map to the expected 'load_balancing' key format in the output\n",
        "            lb_metrics = metrics['load_balancing_metrics']\n",
        "            results.update({\n",
        "                'Average_Resource_Utilization': f\"{lb_metrics.get('average_utilization', 0):.4f}\",\n",
        "                'Coefficient_of_Variation': f\"{lb_metrics.get('load_balance_score', 0):.4f}\",\n",
        "                'CoV_Standard_Deviation': f\"{lb_metrics.get('utilization_std_dev', 0):.4f}\"\n",
        "            })\n",
        "\n",
        "            # Add resource type specific metrics\n",
        "            if 'resource_type_metrics' in lb_metrics:\n",
        "                for resource_type, type_metrics in lb_metrics['resource_type_metrics'].items():\n",
        "                    if resource_type != 'inter_type_balance':\n",
        "                        results.update({\n",
        "                            f'{resource_type}_avg_utilization': f\"{type_metrics.get('average_utilization', 0):.4f}\",\n",
        "                            f'{resource_type}_CoV': f\"{type_metrics.get('load_balance_score', 0):.4f}\"\n",
        "                        })\n",
        "\n",
        "                # Add inter-type balance if available\n",
        "                if 'inter_type_balance' in lb_metrics['resource_type_metrics']:\n",
        "                    inter_balance = lb_metrics['resource_type_metrics']['inter_type_balance']\n",
        "                    results.update({\n",
        "                        'Inter_Type_CoV': f\"{inter_balance.get('balance_score', 0):.4f}\"\n",
        "                    })\n",
        "\n",
        "        # Add timing metrics if available\n",
        "        if 'average_turnaround_time' in metrics:\n",
        "            results['Average_Turnaround_Time'] = f\"{metrics['average_turnaround_time']:.2f}s\"\n",
        "        if 'average_waiting_time' in metrics:\n",
        "            results['Average_Waiting_Time'] = f\"{metrics['average_waiting_time']:.2f}s\"\n",
        "        if 'average_execution_time' in metrics:\n",
        "            results['Average_Execution_Time'] = f\"{metrics['average_execution_time']:.2f}s\"\n",
        "\n",
        "        # Add failed tasks breakdown\n",
        "        for task_type, count in metrics['failed_tasks_by_type'].items():\n",
        "            results[f'Failed_{task_type}'] = count\n",
        "\n",
        "        for resource_type, count in metrics['failed_tasks_by_resource'].items():\n",
        "            results[f'Failed_On_{resource_type}'] = count\n",
        "\n",
        "        # Write to CSV\n",
        "        with open(csv_filepath, 'w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['Metric', 'Value'])\n",
        "            for key, value in results.items():\n",
        "                writer.writerow([key, value])\n",
        "\n",
        "        logger.info(f\"Simulation results written to: {csv_filepath}\")\n",
        "        return csv_filepath\n",
        "    def run_simulation(self, total_tasks: int, distribution_type: str = 'default') -> Dict:\n",
        "        \"\"\"Run the simulation with enhanced logging and timing metrics\"\"\"\n",
        "        tasks = self.distribute_tasks(total_tasks, distribution_type)\n",
        "        simulation_start_time = datetime.now().timestamp()\n",
        "\n",
        "        logger.info(f\"Starting simulation with {total_tasks} total tasks\")\n",
        "        logger.info(f\"Distributed tasks count: {len(tasks)}\")\n",
        "\n",
        "        # Start with original task distribution logging\n",
        "        logger.info(\"\\n=== Initial Task Distribution ===\")\n",
        "        for resource in self.resources:\n",
        "            logger.debug(f\"\\nProcessing Resource: {resource.type}\")\n",
        "            logger.debug(f\"  Current Task: {resource.current_task.type if resource.current_task else 'None'}\")\n",
        "            logger.debug(f\"  Queue Length: {len(resource.task_queue)}\")\n",
        "            if resource.task_queue:\n",
        "                for task in resource.task_queue[:5]:\n",
        "                    logger.info(f\"\"\"\n",
        "                    Task {task.id}:\n",
        "                    - Type: {task.type}\n",
        "                    - CPU Required: {task.total_cpu_required}\n",
        "                    - Arrival Time: {task.arrival_time}\n",
        "                    \"\"\")\n",
        "\n",
        "        resource_utilization = {}\n",
        "        datacenter_utilization_snapshots = []\n",
        "\n",
        "        # Main simulation loop\n",
        "        with Live(self.generate_live_feed(), refresh_per_second=1) as live:\n",
        "            while True:\n",
        "                self.current_time = datetime.now().timestamp() - simulation_start_time\n",
        "                all_completed = True\n",
        "\n",
        "                for resource in self.resources:\n",
        "                    logger.debug(f\"\\nProcessing Resource: {resource.type}\")\n",
        "                    logger.debug(f\"  Current Task: {resource.current_task.type if resource.current_task else 'None'}\")\n",
        "                    logger.debug(f\"  Queue Length: {len(resource.task_queue)}\")\n",
        "                    # Add a debug log right here to check task states\n",
        "                    for i, task in enumerate(resource.task_queue[:3]):  # Just check first 3 tasks\n",
        "                        logger.info(f\"Queue {i}: Task {task.id} - Status: {task.status}\")\n",
        "                    # Pause briefly before processing this resource\n",
        "                    #time.sleep(0.5)  # Half-second delay per resource\n",
        "                    queue_status = resource.process_queue(self.current_time)\n",
        "                    utilization = resource.calculate_resource_utilization()\n",
        "                    resource_utilization[resource.type] = utilization\n",
        "\n",
        "                    # Check completion status\n",
        "                    if resource.current_task:\n",
        "                        if (resource.current_task.status != 'COMPLETED' or\n",
        "                            resource.current_task.completion_percentage < 100):\n",
        "                            all_completed = False\n",
        "                    if resource.task_queue:\n",
        "                        all_completed = False\n",
        "                #time.sleep(0.5)\n",
        "                # Update datacenter utilization\n",
        "                datacenter_utilization_snapshots.append({\n",
        "                    'timestamp': self.current_time,\n",
        "                    'utilization': self.calculate_datacenter_utilization(\n",
        "                        simulation_start_time,\n",
        "                        datetime.now().timestamp() - simulation_start_time\n",
        "                    )\n",
        "                })\n",
        "\n",
        "                live.update(self.generate_live_feed())\n",
        "\n",
        "                # Check completion\n",
        "                total_completed = sum(len(r.completed_tasks) for r in self.resources)\n",
        "                total_failed = sum(len(r.failed_tasks) for r in self.resources) + len(self.metrics['globally_failed_tasks'])\n",
        "\n",
        "                if all_completed and (total_completed + total_failed >= total_tasks):\n",
        "                    all_tasks_truly_complete = True\n",
        "\n",
        "                    for resource in self.resources:\n",
        "                        for task in resource.completed_tasks:\n",
        "                            if task.completion_percentage < 100 or task.status != 'COMPLETED':\n",
        "                                all_tasks_truly_complete = False\n",
        "                                break\n",
        "                        if not all_tasks_truly_complete:\n",
        "                            break\n",
        "\n",
        "                    if all_tasks_truly_complete:\n",
        "                        break\n",
        "\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            # Calculate final metrics\n",
        "            completed_tasks = []\n",
        "            for resource in self.resources:\n",
        "                completed_tasks.extend(resource.completed_tasks)\n",
        "                logger.info(f\"\"\"\n",
        "                Resource {resource.type} Final Status:\n",
        "                - Completed Tasks: {len(resource.completed_tasks)}\n",
        "                - Failed Tasks: {len(resource.failed_tasks)}\n",
        "                \"\"\")\n",
        "\n",
        "            # Calculate timing metrics with detailed debugging\n",
        "            total_turnaround_time = 0.0\n",
        "            total_waiting_time = 0.0\n",
        "            valid_tasks = 0\n",
        "\n",
        "            logger.info(f\"\\nCalculating timing metrics for {len(completed_tasks)} tasks:\")\n",
        "\n",
        "            for task in completed_tasks:\n",
        "                # Debug log all timing values\n",
        "                logger.info(f\"\"\"\n",
        "                Task {task.id} Raw Timing Values Debug:\n",
        "                - Status: {task.status}\n",
        "                - Arrival Time Present: {task.arrival_time is not None}\n",
        "                - Arrival Time: {task.arrival_time if task.arrival_time is not None else 'None'}\n",
        "                - Start Time Present: {task.start_time is not None}\n",
        "                - Start Time: {task.start_time if task.start_time is not None else 'None'}\n",
        "                - Completion Time Present: {task.completion_time is not None}\n",
        "                - Completion Time: {task.completion_time if task.completion_time is not None else 'None'}\n",
        "                - Actual Exec Time: {task.actual_exec_time}\n",
        "                \"\"\")\n",
        "\n",
        "                # Check each condition separately for debugging\n",
        "                has_completion = task.completion_time is not None\n",
        "                has_arrival = task.arrival_time is not None\n",
        "                has_exec_time = task.actual_exec_time > 0\n",
        "                completion_after_arrival = (task.completion_time >= task.arrival_time) if (has_completion and has_arrival) else False\n",
        "\n",
        "                logger.info(f\"\"\"\n",
        "                Task {task.id} Validation Checks:\n",
        "                - Has Completion Time: {has_completion}\n",
        "                - Has Arrival Time: {has_arrival}\n",
        "                - Has Exec Time > 0: {has_exec_time}\n",
        "                - Completion After Arrival: {completion_after_arrival}\n",
        "                \"\"\")\n",
        "\n",
        "                if has_completion and has_arrival and has_exec_time and completion_after_arrival:\n",
        "                    # Calculate turnaround time\n",
        "                    task.turnaround_time = self.calculate_turnaround_time(task, simulation_start_time)\n",
        "                    task.waiting_time = self.calculate_waiting_time(task)\n",
        "\n",
        "                    # Log task timing details\n",
        "                    logger.info(f\"\"\"\n",
        "                    Task {task.id} Timing Details:\n",
        "                    - Arrival Time: {task.arrival_time}\n",
        "                    - Completion Time: {task.completion_time}\n",
        "                    - Actual Execution Time: {task.actual_exec_time}\n",
        "                    - Turnaround Time: {task.turnaround_time}\n",
        "                    - Waiting Time: {task.waiting_time}\n",
        "                    \"\"\")\n",
        "\n",
        "                    # Additional validation for calculated times\n",
        "                    if task.turnaround_time > 0:\n",
        "                        total_turnaround_time += task.turnaround_time\n",
        "                        total_waiting_time += task.waiting_time\n",
        "                        valid_tasks += 1\n",
        "\n",
        "                        logger.info(f\"Task {task.id} ACCEPTED for metrics calculation\")\n",
        "                    else:\n",
        "                        logger.warning(f\"\"\"\n",
        "                        Task {task.id} has invalid calculated times:\n",
        "                        - Turnaround Time: {task.turnaround_time:.2f}\n",
        "                        - Waiting Time: {task.waiting_time:.2f}\n",
        "                        \"\"\")\n",
        "                else:\n",
        "                    logger.warning(f\"\"\"\n",
        "                    Task {task.id} failed validation:\n",
        "                    - Missing completion time: {not has_completion}\n",
        "                    - Missing arrival time: {not has_arrival}\n",
        "                    - No execution time: {not has_exec_time}\n",
        "                    - Completion before arrival: {not completion_after_arrival}\n",
        "                    \"\"\")\n",
        "\n",
        "            # After processing all tasks, log summary\n",
        "            logger.info(f\"\"\"\n",
        "            Timing Metrics Summary:\n",
        "            Total Completed Tasks: {len(completed_tasks)}\n",
        "            Valid Tasks for Timing: {valid_tasks}\n",
        "            Total Turnaround Time: {total_turnaround_time:.2f}\n",
        "            Total Waiting Time: {total_waiting_time:.2f}\n",
        "            \"\"\")\n",
        "\n",
        "            # Calculate averages\n",
        "            if valid_tasks > 0:\n",
        "                avg_turnaround = total_turnaround_time / valid_tasks\n",
        "                avg_waiting = total_waiting_time / valid_tasks\n",
        "                logger.info(f\"\"\"\n",
        "                Final Timing Metrics:\n",
        "                - Valid Tasks: {valid_tasks}\n",
        "                - Average Turnaround Time: {avg_turnaround:.2f}s\n",
        "                - Average Waiting Time: {avg_waiting:.2f}s\n",
        "                \"\"\")\n",
        "            else:\n",
        "                logger.warning(\"No valid tasks found for timing calculation!\")\n",
        "                avg_turnaround = 0\n",
        "                avg_waiting = 0\n",
        "            # Calculate load balancing metrics\n",
        "            load_balancing_metrics = self.calculate_load_balancing_metrics()\n",
        "            # Update metrics dictionary\n",
        "            self.metrics.update({\n",
        "                'total_tasks': total_tasks,\n",
        "                'completed_tasks': total_completed,\n",
        "                'failed_tasks': total_failed,\n",
        "                'makespan': self.current_time,\n",
        "                'throughput': total_completed / self.current_time if self.current_time > 0 else 0,\n",
        "                'load_balancing_metrics': load_balancing_metrics  # Add load balancing metrics here\n",
        "\n",
        "            })\n",
        "\n",
        "\n",
        "            # Process failures\n",
        "            detailed_failed_tasks = []\n",
        "            failed_tasks_by_type = {}\n",
        "            failed_tasks_by_resource = {}\n",
        "\n",
        "            for resource in self.resources:\n",
        "                for task in resource.failed_tasks:\n",
        "                    failure_info = {\n",
        "                        'task_id': task.id,\n",
        "                        'task_type': task.type,\n",
        "                        'resource_type': resource.type,\n",
        "                        'reason': getattr(task, 'failure_reason', 'Unknown reason')\n",
        "                    }\n",
        "                    detailed_failed_tasks.append(failure_info)\n",
        "                    failed_tasks_by_type[task.type] = failed_tasks_by_type.get(task.type, 0) + 1\n",
        "                    failed_tasks_by_resource[resource.type] = failed_tasks_by_resource.get(resource.type, 0) + 1\n",
        "\n",
        "            # Add globally failed tasks\n",
        "            for task in self.metrics['globally_failed_tasks']:\n",
        "                detailed_failed_tasks.append({\n",
        "                    'task_id': task.id,\n",
        "                    'task_type': task.type,\n",
        "                    'resource_type': \"None\",\n",
        "                    'reason': getattr(task, 'failure_reason', 'Unknown reason')\n",
        "                })\n",
        "\n",
        "            # Update failure metrics\n",
        "            self.metrics.update({\n",
        "                'detailed_failed_tasks': detailed_failed_tasks,\n",
        "                'failed_tasks_by_type': failed_tasks_by_type,\n",
        "                'failed_tasks_by_resource': failed_tasks_by_resource\n",
        "            })\n",
        "\n",
        "            # Write results and finish\n",
        "            results_file = self.write_simulation_results(self.metrics, simulation_start_time, distribution_type)\n",
        "            logger.info(f\"Simulation results saved to: {results_file}\")\n",
        "\n",
        "            return self.metrics\n",
        "def create_resources():\n",
        "    \"\"\"\n",
        "    Create resources with 10 Smartphones, 5 Raspberry Pis, and 5 Cloud Hosts\n",
        "    \"\"\"\n",
        "    resources = []\n",
        "\n",
        "    # Create 10 Smartphone Nodes\n",
        "    for i in range(1, 11):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i,\n",
        "                resource_type=f\"Smartphone_{i}\",  # Changed from Edge_ to Smartphone_\n",
        "                cpu_rating=400000,   # 400,000 MI/s\n",
        "                memory=4,            # 4 GB\n",
        "                bandwidth=400         # 20 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Raspberry Pi Nodes\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+10,  # IDs 11-15\n",
        "                resource_type=f\"Raspberry_{i}\",\n",
        "                cpu_rating=80000,    # 80,000 MI/s\n",
        "                memory=1,            # 1 GB\n",
        "                bandwidth=100          # 5 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create 5 Cloud Hosts\n",
        "    for i in range(1, 6):\n",
        "        resources.append(\n",
        "            Resource(\n",
        "                resource_id=i+15,  # IDs 16-20\n",
        "                resource_type=f\"Cloud_{i}\",\n",
        "                cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "                memory=32,           # 32 GB\n",
        "                bandwidth=1200         # 80 MB/s\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Log created resources\n",
        "    logger.info(f\"Created {len(resources)} resources: {[r.type for r in resources]}\")\n",
        "\n",
        "    return resources\n",
        "def main():\n",
        "\n",
        "    # Disable all logging at the beginning\n",
        "    import logging\n",
        "    logging.disable(logging.CRITICAL)\n",
        "    # Create resources\n",
        "    resources = create_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = ResourceFocusedScheduler(resources)\n",
        "\n",
        "    try:\n",
        "        # Define the total number of tasks - use a very small number for debugging\n",
        "        total_tasks = 5  # Just 5 tasks for easier debugging\n",
        "\n",
        "        # Increase logging detail\n",
        "        #logger.setLevel(logging.DEBUG)\n",
        "\n",
        "        logger.info(\"=== STARTING SIMULATION WITH DETAILED DEBUGGING ===\")\n",
        "\n",
        "        # Run simulation\n",
        "        metrics = scheduler.run_simulation(total_tasks, distribution_type='hybrid')\n",
        "\n",
        "        logger.info(\"=== SIMULATION COMPLETED ===\")\n",
        "\n",
        "        # Print final metrics\n",
        "        print(\"\\nFinal Simulation Metrics:\")\n",
        "        for key, value in metrics.items():\n",
        "            if key not in ['resource_utilization', 'datacenter_utilization_snapshots', 'detailed_failed_tasks']:\n",
        "                print(f\"{key}: {value}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unhandled error in main: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4283648150344b50b65cdf635d28f1a6",
            "4731897c94b149858d9443630f70fe2d"
          ]
        },
        "id": "NnRDGSuPKeLC",
        "outputId": "f19c5889-403e-4e81-d05b-56f0347f5233"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "📂 Available log files in EdgeSimPy/logs:\n",
            "simulation_2025-02-11_17-58-46.log\n",
            "simulation_2025-02-11_18-25-45.log\n",
            "simulation_2025-02-11_18-26-24.log\n",
            "simulation_2025-02-11_18-56-32.log\n",
            "simulation_2025-02-11_21-50-54.log\n",
            "simulation_2025-02-11_21-52-13.log\n",
            "simulation_2025-02-11_21-54-14.log\n",
            "simulation_2025-02-11_21-57-52.log\n",
            "simulation_2025-02-11_22-00-22.log\n",
            "simulation_2025-02-11_22-02-02.log\n",
            "simulation_2025-02-11_22-06-21.log\n",
            "simulation_2025-02-11_22-06-34.log\n",
            "simulation_2025-02-11_22-19-23.log\n",
            "simulation_2025-02-11_22-27-16.log\n",
            "simulation_2025-02-11_22-38-41.log\n",
            "simulation_2025-02-11_22-46-08.log\n",
            "simulation_2025-02-11_22-53-45.log\n",
            "simulation_2025-02-11_23-01-54.log\n",
            "simulation_2025-02-11_23-02-03.log\n",
            "simulation_2025-02-11_23-02-13.log\n",
            "simulation_2025-02-11_23-02-22.log\n",
            "simulation_2025-02-11_23-04-30.log\n",
            "simulation_2025-02-11_23-08-21.log\n",
            "simulation_2025-02-11_23-11-06.log\n",
            "simulation_2025-02-11_23-15-58.log\n",
            "simulation_2025-02-11_23-17-16.log\n",
            "simulation_2025-02-11_23-17-46.log\n",
            "simulation_2025-02-11_23-21-34.log\n",
            "simulation_2025-02-11_23-24-39.log\n",
            "simulation_2025-02-11_23-27-14.log\n",
            "simulation_2025-02-11_23-29-55.log\n",
            "simulation_2025-02-11_23-30-22.log\n",
            "simulation_2025-02-11_23-35-26.log\n",
            "simulation_2025-02-11_23-36-41.log\n",
            "simulation_2025-02-11_23-37-09.log\n",
            "simulation_2025-02-11_23-39-43.log\n",
            "simulation_2025-02-11_23-42-10.log\n",
            "simulation_2025-02-11_23-43-54.log\n",
            "simulation_2025-02-11_23-44-22.log\n",
            "simulation_2025-02-11_23-45-19.log\n",
            "simulation_2025-02-11_23-50-41.log\n",
            "simulation_2025-02-11_23-54-19.log\n",
            "simulation_2025-02-11_23-57-56.log\n",
            "simulation_2025-02-11_23-59-39.log\n",
            "simulation_2025-02-12_00-01-05.log\n",
            "simulation_2025-02-12_00-02-44.log\n",
            "simulation_2025-02-12_00-04-53.log\n",
            "simulation_2025-02-12_00-10-36.log\n",
            "simulation_2025-02-12_00-14-58.log\n",
            "simulation_2025-02-12_00-18-31.log\n",
            "simulation_2025-02-12_06-51-04.log\n",
            "simulation_2025-02-12_06-56-02.log\n",
            "simulation_2025-02-12_07-04-57.log\n",
            "simulation_2025-02-12_07-10-28.log\n",
            "simulation_2025-02-12_07-17-05.log\n",
            "simulation_2025-02-12_07-19-14.log\n",
            "simulation_2025-02-12_07-46-27.log\n",
            "simulation_2025-02-12_07-56-15.log\n",
            "simulation_2025-02-12_07-56-26.log\n",
            "simulation_2025-02-12_08-00-38.log\n",
            "simulation_2025-02-12_08-06-23.log\n",
            "simulation_2025-02-12_09-32-56.log\n",
            "simulation_2025-02-12_09-40-00.log\n",
            "simulation_2025-02-12_09-46-26.log\n",
            "simulation_2025-02-12_10-18-11.log\n",
            "simulation_2025-02-12_10-20-46.log\n",
            "simulation_2025-02-12_10-20-51.log\n",
            "simulation_2025-02-12_10-23-10.log\n",
            "simulation_2025-02-12_15-24-49.log\n",
            "simulation_2025-02-12_17-18-18.log\n",
            "simulation_2025-02-12_19-58-24.log\n",
            "simulation_2025-02-13_06-32-18.log\n",
            "simulation_2025-02-13_09-15-40.log\n",
            "simulation_2025-02-15_21-21-07.log\n",
            "simulation_2025-02-16_19-59-07.log\n",
            "simulation_2025-02-18_16-47-56.log\n",
            "simulation_2025-02-18_17-17-23.log\n",
            "simulation_2025-02-18_17-20-21.log\n",
            "simulation_2025-02-18_17-20-50.log\n",
            "simulation_2025-02-18_17-25-32.log\n",
            "simulation_2025-02-18_17-25-48.log\n",
            "simulation_2025-02-18_18-46-20.log\n",
            "simulation_2025-02-18_18-46-51.log\n",
            "simulation_2025-02-18_18-57-49.log\n",
            "simulation_2025-02-18_19-13-47.log\n",
            "simulation_2025-02-18_19-39-54.log\n",
            "simulation_2025-02-18_19-40-30.log\n",
            "simulation_2025-02-18_19-50-14.log\n",
            "simulation_2025-02-18_20-00-23.log\n",
            "simulation_2025-02-18_20-02-25.log\n",
            "simulation_2025-02-18_20-17-06.log\n",
            "simulation_2025-02-18_20-35-48.log\n",
            "simulation_2025-02-18_20-40-17.log\n",
            "simulation_2025-02-18_20-47-24.log\n",
            "simulation_2025-02-18_20-53-58.log\n",
            "simulation_2025-02-18_20-56-23.log\n",
            "simulation_2025-02-18_21-02-03.log\n",
            "simulation_2025-02-18_21-08-28.log\n",
            "simulation_2025-02-18_21-14-48.log\n",
            "simulation_2025-02-18_21-20-58.log\n",
            "simulation_2025-02-18_21-30-16.log\n",
            "simulation_2025-02-18_21-31-45.log\n",
            "simulation_2025-02-18_21-34-43.log\n",
            "simulation_2025-02-19_19-34-33.log\n",
            "simulation_2025-02-19_19-37-31.log\n",
            "simulation_2025-02-19_19-46-01.log\n",
            "simulation_2025-02-19_19-51-17.log\n",
            "simulation_2025-02-19_20-01-39.log\n",
            "simulation_2025-02-19_20-11-47.log\n",
            "simulation_2025-02-19_20-17-11.log\n",
            "simulation_2025-02-19_20-31-16.log\n",
            "simulation_2025-02-19_21-18-10.log\n",
            "simulation_2025-02-19_21-39-27.log\n",
            "simulation_2025-02-19_21-43-49.log\n",
            "simulation_2025-02-19_21-44-35.log\n",
            "simulation_2025-02-19_21-49-37.log\n",
            "simulation_2025-02-19_21-59-16.log\n",
            "simulation_2025-02-19_22-06-55.log\n",
            "simulation_2025-02-19_22-10-05.log\n",
            "simulation_2025-02-19_22-14-12.log\n",
            "simulation_2025-02-19_22-17-17.log\n",
            "simulation_2025-02-19_22-20-52.log\n",
            "simulation_2025-02-19_22-22-21.log\n",
            "simulation_2025-02-19_22-25-06.log\n",
            "simulation_2025-02-19_22-28-31.log\n",
            "simulation_2025-02-19_22-32-58.log\n",
            "simulation_2025-02-20_10-43-37.log\n",
            "simulation_2025-02-20_10-59-53.log\n",
            "simulation_2025-02-20_11-05-22.log\n",
            "simulation_2025-02-20_11-09-08.log\n",
            "simulation_2025-02-20_17-36-47.log\n",
            "simulation_2025-02-20_17-44-53.log\n",
            "simulation_2025-02-20_17-57-56.log\n",
            "simulation_2025-02-20_18-08-26.log\n",
            "simulation_2025-02-20_18-21-44.log\n",
            "simulation_2025-02-20_19-41-38.log\n",
            "simulation_2025-02-20_20-09-45.log\n",
            "simulation_2025-02-20_20-12-49.log\n",
            "simulation_2025-02-20_20-13-31.log\n",
            "simulation_2025-02-20_20-13-54.log\n",
            "simulation_2025-02-20_20-17-56.log\n",
            "simulation_2025-02-20_20-20-00.log\n",
            "simulation_2025-02-20_20-20-31.log\n",
            "simulation_2025-02-20_20-21-07.log\n",
            "simulation_2025-02-20_20-36-28.log\n",
            "simulation_2025-02-20_20-42-54.log\n",
            "simulation_2025-02-20_20-46-23.log\n",
            "simulation_2025-02-20_20-47-46.log\n",
            "simulation_2025-02-20_20-55-32.log\n",
            "simulation_2025-02-20_20-59-20.log\n",
            "simulation_2025-02-20_21-00-33.log\n",
            "simulation_2025-02-20_21-58-58.log\n",
            "simulation_2025-02-20_22-08-36.log\n",
            "simulation_2025-02-20_22-08-52.log\n",
            "simulation_2025-02-20_22-09-10.log\n",
            "simulation_2025-02-20_22-09-38.log\n",
            "simulation_2025-02-20_22-14-08.log\n",
            "simulation_2025-02-20_22-25-34.log\n",
            "simulation_2025-02-20_22-33-26.log\n",
            "simulation_2025-02-20_22-34-42.log\n",
            "simulation_2025-02-20_22-41-56.log\n",
            "simulation_2025-02-20_22-50-21.log\n",
            "simulation_2025-02-20_23-05-10.log\n",
            "simulation_2025-02-20_23-10-44.log\n",
            "simulation_2025-02-20_23-16-45.log\n",
            "simulation_2025-02-20_23-22-15.log\n",
            "simulation_2025-02-20_23-30-44.log\n",
            "simulation_2025-02-20_23-31-43.log\n",
            "simulation_2025-02-20_23-32-56.log\n",
            "simulation_2025-02-20_23-34-00.log\n",
            "simulation_2025-02-20_23-34-21.log\n",
            "simulation_2025-02-20_23-34-42.log\n",
            "simulation_2025-02-20_23-38-17.log\n",
            "simulation_2025-02-21_06-38-46.log\n",
            "simulation_2025-02-21_09-20-18.log\n",
            "simulation_2025-02-21_13-29-30.log\n",
            "simulation_2025-02-21_17-20-55.log\n",
            "simulation_2025-02-21_17-29-09.log\n",
            "simulation_2025-02-21_17-30-53.log\n",
            "simulation_2025-02-21_17-32-18.log\n",
            "simulation_2025-02-21_17-33-40.log\n",
            "simulation_2025-02-21_17-50-13.log\n",
            "simulation_2025-02-21_17-56-54.log\n",
            "simulation_2025-02-21_17-58-01.log\n",
            "simulation_2025-02-21_17-59-32.log\n",
            "simulation_2025-02-21_18-02-59.log\n",
            "simulation_2025-02-21_18-04-34.log\n",
            "simulation_2025-02-21_18-06-34.log\n",
            "simulation_2025-02-22_06-32-38.log\n",
            "simulation_2025-02-22_06-36-27.log\n",
            "simulation_2025-02-22_06-36-50.log\n",
            "simulation_2025-02-22_06-41-19.log\n",
            "simulation_2025-02-22_06-42-07.log\n",
            "simulation_2025-02-22_06-44-33.log\n",
            "simulation_2025-02-22_07-18-58.log\n",
            "simulation_2025-02-22_07-21-29.log\n",
            "simulation_2025-02-22_13-20-33.log\n",
            "simulation_2025-02-22_17-46-10.log\n",
            "simulation_2025-02-22_18-14-35.log\n",
            "simulation_2025-02-22_19-12-11.log\n",
            "simulation_2025-02-22_19-14-05.log\n",
            "simulation_2025-02-22_19-16-14.log\n",
            "simulation_2025-02-22_19-18-01.log\n",
            "simulation_2025-02-22_19-22-53.log\n",
            "simulation_2025-02-22_19-25-46.log\n",
            "simulation_2025-02-22_19-28-31.log\n",
            "simulation_2025-02-22_19-42-30.log\n",
            "simulation_2025-02-22_19-46-13.log\n",
            "simulation_2025-02-23_07-56-34.log\n",
            "simulation_2025-02-23_07-59-58.log\n",
            "simulation_2025-02-23_08-04-13.log\n",
            "simulation_2025-02-23_08-05-33.log\n",
            "simulation_2025-02-23_19-47-20.log\n",
            "simulation_2025-02-23_20-52-05.log\n",
            "simulation_2025-02-23_22-27-46.log\n",
            "simulation_2025-02-23_22-30-03.log\n",
            "simulation_2025-02-23_22-49-06.log\n",
            "simulation_2025-02-24_20-14-55.log\n",
            "simulation_2025-02-24_20-17-46.log\n",
            "simulation_2025-02-24_20-21-27.log\n",
            "simulation_2025-02-24_20-44-31.log\n",
            "simulation_2025-02-24_20-46-42.log\n",
            "simulation_2025-02-24_20-52-22.log\n",
            "simulation_2025-02-24_20-54-07.log\n",
            "simulation_2025-02-24_20-57-16.log\n",
            "simulation_2025-02-25_05-20-34.log\n",
            "simulation_2025-02-25_05-25-45.log\n",
            "simulation_2025-02-25_05-26-01.log\n",
            "simulation_2025-02-25_05-34-16.log\n",
            "simulation_2025-02-25_05-38-16.log\n",
            "simulation_2025-02-25_05-43-51.log\n",
            "simulation_2025-02-25_05-48-24.log\n",
            "simulation_2025-02-25_05-55-29.log\n",
            "simulation_2025-02-25_06-40-40.log\n",
            "simulation_2025-02-25_06-43-26.log\n",
            "simulation_2025-02-25_09-10-32.log\n",
            "simulation_2025-02-25_10-31-24.log\n",
            "simulation_2025-02-25_11-31-50.log\n",
            "simulation_2025-02-25_11-36-21.log\n",
            "simulation_2025-02-25_11-42-20.log\n",
            "simulation_2025-02-25_11-51-37.log\n",
            "simulation_2025-02-25_11-53-41.log\n",
            "simulation_2025-02-25_11-59-28.log\n",
            "simulation_2025-02-25_12-00-05.log\n",
            "simulation_2025-02-25_13-39-16.log\n",
            "simulation_2025-02-25_13-40-26.log\n",
            "simulation_2025-02-25_13-43-20.log\n",
            "simulation_2025-02-25_13-47-49.log\n",
            "simulation_2025-02-25_13-54-20.log\n",
            "simulation_2025-02-25_17-03-58.log\n",
            "simulation_2025-02-25_17-08-12.log\n",
            "simulation_2025-02-25_17-14-32.log\n",
            "simulation_2025-02-25_17-23-57.log\n",
            "simulation_2025-02-25_17-25-38.log\n",
            "simulation_2025-02-25_17-32-43.log\n",
            "simulation_2025-02-25_17-42-24.log\n",
            "simulation_2025-02-25_17-53-13.log\n",
            "simulation_2025-02-25_19-39-17.log\n",
            "simulation_2025-02-25_19-41-52.log\n",
            "simulation_2025-02-25_19-42-59.log\n",
            "simulation_2025-02-25_19-53-07.log\n",
            "simulation_2025-02-25_20-05-03.log\n",
            "simulation_2025-02-25_20-20-14.log\n",
            "simulation_2025-02-25_20-22-46.log\n",
            "simulation_2025-02-25_20-31-09.log\n",
            "simulation_2025-02-25_20-34-49.log\n",
            "simulation_2025-02-25_20-41-19.log\n",
            "simulation_2025-02-25_20-44-27.log\n",
            "simulation_2025-02-25_20-46-05.log\n",
            "simulation_2025-02-25_20-51-08.log\n",
            "simulation_2025-02-25_21-03-44.log\n",
            "simulation_2025-02-25_21-05-31.log\n",
            "simulation_2025-02-25_21-06-31.log\n",
            "simulation_2025-02-25_21-13-08.log\n",
            "simulation_2025-02-25_21-13-42.log\n",
            "simulation_2025-02-25_21-17-44.log\n",
            "simulation_2025-02-25_21-18-07.log\n",
            "simulation_2025-02-25_21-22-21.log\n",
            "simulation_2025-02-25_21-23-27.log\n",
            "simulation_2025-02-25_21-23-48.log\n",
            "simulation_2025-02-25_21-25-30.log\n",
            "simulation_2025-02-25_21-26-11.log\n",
            "simulation_2025-02-25_21-27-16.log\n",
            "simulation_2025-02-25_21-28-20.log\n",
            "simulation_2025-02-25_21-30-43.log\n",
            "simulation_2025-02-25_21-40-16.log\n",
            "simulation_2025-02-25_21-40-31.log\n",
            "simulation_2025-02-25_21-41-23.log\n",
            "simulation_2025-02-25_21-52-48.log\n",
            "simulation_2025-02-25_21-56-09.log\n",
            "simulation_2025-02-25_21-56-23.log\n",
            "simulation_2025-02-25_21-57-10.log\n",
            "simulation_2025-02-25_22-01-00.log\n",
            "simulation_2025-02-25_22-01-25.log\n",
            "simulation_2025-02-25_22-03-22.log\n",
            "simulation_2025-02-25_22-04-13.log\n",
            "simulation_2025-02-25_22-04-38.log\n",
            "simulation_2025-02-25_22-05-40.log\n",
            "simulation_2025-02-26_05-54-43.log\n",
            "simulation_2025-02-26_05-55-47.log\n",
            "simulation_2025-02-26_05-58-10.log\n",
            "simulation_2025-02-26_06-06-37.log\n",
            "simulation_2025-02-26_06-07-50.log\n",
            "simulation_2025-02-26_06-14-01.log\n",
            "simulation_2025-02-26_06-32-16.log\n",
            "simulation_2025-02-26_06-32-49.log\n",
            "simulation_2025-02-26_08-16-22.log\n",
            "simulation_2025-02-26_08-18-20.log\n",
            "simulation_2025-02-26_08-29-59.log\n",
            "simulation_2025-02-26_08-37-47.log\n",
            "simulation_2025-02-26_08-57-42.log\n",
            "simulation_2025-02-26_09-01-37.log\n",
            "simulation_2025-02-26_09-03-13.log\n",
            "simulation_2025-02-26_09-13-32.log\n",
            "simulation_2025-02-26_09-14-39.log\n",
            "simulation_2025-02-26_09-18-04.log\n",
            "simulation_2025-02-26_09-30-54.log\n",
            "simulation_2025-02-27_08-30-42.log\n",
            "simulation_2025-02-27_08-36-22.log\n",
            "simulation_2025-02-27_08-36-44.log\n",
            "simulation_2025-02-27_08-40-18.log\n",
            "simulation_2025-02-27_08-46-00.log\n",
            "simulation_2025-02-27_08-46-21.log\n",
            "simulation_2025-02-27_08-54-26.log\n",
            "simulation_2025-02-27_08-54-39.log\n",
            "simulation_2025-02-27_08-56-33.log\n",
            "simulation_2025-02-27_09-01-03.log\n",
            "simulation_2025-02-27_09-53-47.log\n",
            "simulation_2025-02-27_09-55-25.log\n",
            "simulation_2025-02-27_09-56-54.log\n",
            "simulation_2025-02-27_09-58-23.log\n",
            "simulation_2025-02-27_10-13-42.log\n",
            "simulation_2025-02-27_11-27-03.log\n",
            "simulation_2025-02-27_11-28-02.log\n",
            "simulation_2025-02-27_11-39-42.log\n",
            "simulation_2025-02-27_11-47-38.log\n",
            "simulation_2025-02-27_11-55-27.log\n",
            "simulation_2025-02-27_12-05-29.log\n",
            "simulation_2025-02-27_12-12-59.log\n",
            "simulation_2025-02-27_12-15-01.log\n",
            "simulation_2025-02-27_12-16-13.log\n",
            "simulation_2025-02-27_12-16-40.log\n",
            "simulation_2025-02-27_12-16-55.log\n",
            "simulation_2025-02-27_12-18-29.log\n",
            "simulation_2025-02-27_12-19-03.log\n",
            "simulation_2025-02-27_12-19-20.log\n",
            "simulation_2025-02-27_12-19-49.log\n",
            "simulation_2025-02-27_12-23-27.log\n",
            "simulation_2025-02-27_12-24-06.log\n",
            "simulation_2025-02-27_12-31-31.log\n",
            "simulation_2025-02-27_12-32-24.log\n",
            "simulation_2025-02-28_06-25-50.log\n",
            "simulation_2025-02-28_06-26-55.log\n",
            "simulation_2025-02-28_06-33-16.log\n",
            "simulation_2025-02-28_06-42-44.log\n",
            "simulation_2025-02-28_06-53-08.log\n",
            "simulation_2025-02-28_07-00-04.log\n",
            "simulation_2025-02-28_07-01-36.log\n",
            "simulation_2025-02-28_07-01-56.log\n",
            "simulation_2025-02-28_07-03-12.log\n",
            "simulation_2025-02-28_07-11-08.log\n",
            "simulation_2025-02-28_07-11-25.log\n",
            "simulation_2025-02-28_07-11-44.log\n",
            "simulation_2025-02-28_07-12-20.log\n",
            "simulation_2025-02-28_08-51-17.log\n",
            "simulation_2025-02-28_08-54-23.log\n",
            "simulation_2025-02-28_09-06-54.log\n",
            "simulation_2025-02-28_10-08-35.log\n",
            "simulation_2025-02-28_10-16-00.log\n",
            "simulation_2025-02-28_10-17-13.log\n",
            "simulation_2025-02-28_10-18-09.log\n",
            "simulation_2025-02-28_10-24-42.log\n",
            "simulation_2025-02-28_10-27-03.log\n",
            "simulation_2025-02-28_10-27-21.log\n",
            "simulation_2025-02-28_10-36-06.log\n",
            "simulation_2025-02-28_10-48-52.log\n",
            "simulation_2025-02-28_10-52-22.log\n",
            "simulation_2025-02-28_10-52-53.log\n",
            "simulation_2025-02-28_10-53-56.log\n",
            "simulation_2025-02-28_10-59-26.log\n",
            "simulation_2025-02-28_11-00-25.log\n",
            "simulation_2025-02-28_11-05-39.log\n",
            "simulation_2025-02-28_11-06-43.log\n",
            "simulation_2025-02-28_11-09-47.log\n",
            "simulation_2025-02-28_11-11-58.log\n",
            "simulation_2025-02-28_11-17-54.log\n",
            "simulation_2025-02-28_11-21-44.log\n",
            "simulation_2025-02-28_11-24-37.log\n",
            "simulation_2025-02-28_11-26-24.log\n",
            "simulation_2025-02-28_11-29-22.log\n",
            "simulation_2025-02-28_11-32-21.log\n",
            "simulation_2025-02-28_11-35-03.log\n",
            "simulation_2025-02-28_12-01-01.log\n",
            "simulation_2025-02-28_12-02-06.log\n",
            "simulation_2025-02-28_12-02-48.log\n",
            "simulation_2025-02-28_12-03-13.log\n",
            "simulation_2025-02-28_12-05-49.log\n",
            "simulation_2025-02-28_12-06-58.log\n",
            "simulation_2025-02-28_12-08-16.log\n",
            "simulation_2025-02-28_12-12-51.log\n",
            "simulation_2025-02-28_12-16-40.log\n",
            "simulation_2025-02-28_12-52-09.log\n",
            "simulation_2025-02-28_12-56-28.log\n",
            "simulation_2025-02-28_13-00-24.log\n",
            "simulation_2025-02-28_13-07-43.log\n",
            "simulation_2025-02-28_13-08-07.log\n",
            "simulation_2025-02-28_13-09-38.log\n",
            "simulation_2025-02-28_13-18-24.log\n",
            "simulation_2025-02-28_20-00-14.log\n",
            "simulation_2025-02-28_20-01-12.log\n",
            "simulation_2025-02-28_20-02-53.log\n",
            "simulation_2025-02-28_20-04-46.log\n",
            "simulation_2025-02-28_20-05-10.log\n",
            "simulation_2025-02-28_20-06-12.log\n",
            "simulation_2025-02-28_20-09-22.log\n",
            "simulation_2025-02-28_20-18-55.log\n",
            "simulation_2025-02-28_20-20-32.log\n",
            "simulation_2025-02-28_20-22-16.log\n",
            "simulation_2025-02-28_20-23-07.log\n",
            "simulation_2025-02-28_20-32-20.log\n",
            "simulation_2025-02-28_20-46-48.log\n",
            "simulation_2025-02-28_20-57-35.log\n",
            "simulation_2025-02-28_20-58-06.log\n",
            "simulation_2025-02-28_21-00-10.log\n",
            "simulation_2025-03-01_08-02-02.log\n",
            "simulation_2025-03-01_22-15-36.log\n",
            "simulation_2025-03-01_22-21-51.log\n",
            "simulation_2025-03-01_22-30-03.log\n",
            "simulation_2025-03-01_22-31-31.log\n",
            "simulation_2025-03-01_22-34-05.log\n",
            "simulation_2025-03-01_22-37-47.log\n",
            "simulation_2025-03-01_22-44-00.log\n",
            "simulation_2025-03-01_22-48-36.log\n",
            "simulation_2025-03-01_22-49-40.log\n",
            "simulation_2025-03-01_22-50-06.log\n",
            "simulation_2025-03-01_22-50-29.log\n",
            "simulation_2025-03-01_22-52-02.log\n",
            "simulation_2025-03-01_22-54-12.log\n",
            "simulation_2025-03-01_22-55-45.log\n",
            "simulation_2025-03-01_22-57-18.log\n",
            "simulation_2025-03-01_22-57-42.log\n",
            "simulation_2025-03-01_23-09-33.log\n",
            "simulation_2025-03-01_23-09-59.log\n",
            "simulation_2025-03-01_23-11-15.log\n",
            "simulation_2025-03-01_23-12-56.log\n",
            "simulation_2025-03-01_23-13-17.log\n",
            "simulation_2025-03-01_23-13-40.log\n",
            "simulation_2025-03-01_23-19-12.log\n",
            "simulation_2025-03-01_23-24-35.log\n",
            "simulation_2025-03-01_23-29-39.log\n",
            "simulation_2025-03-02_08-12-08.log\n",
            "simulation_2025-03-02_08-27-54.log\n",
            "simulation_2025-03-02_08-34-20.log\n",
            "simulation_2025-03-02_08-34-34.log\n",
            "simulation_2025-03-02_14-49-14.log\n",
            "simulation_2025-03-02_15-45-02.log\n",
            "simulation_2025-03-02_15-45-53.log\n",
            "simulation_2025-03-02_15-57-17.log\n",
            "simulation_2025-03-02_16-06-47.log\n",
            "simulation_2025-03-02_16-34-34.log\n",
            "simulation_2025-03-02_17-27-55.log\n",
            "simulation_2025-03-02_18-03-43.log\n",
            "simulation_2025-03-02_18-38-12.log\n",
            "simulation_2025-03-02_18-57-41.log\n",
            "simulation_2025-03-02_18-58-08.log\n",
            "simulation_2025-03-02_19-01-16.log\n",
            "simulation_2025-03-02_19-08-53.log\n",
            "simulation_2025-03-02_20-33-48.log\n",
            "simulation_2025-03-02_20-33-57.log\n",
            "simulation_2025-03-02_20-34-11.log\n",
            "simulation_2025-03-02_21-29-02.log\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4283648150344b50b65cdf635d28f1a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Simulation Metrics:\n",
            "total_tasks: 200\n",
            "completed_tasks: 200\n",
            "failed_tasks: 0\n",
            "globally_failed_tasks: []\n",
            "makespan: 735.050628900528\n",
            "throughput: 0.272090101193649\n",
            "load_balancing: {'resource_utilizations': {1: 0.3846682465948477, 2: 0.048477184764182085, 3: 0.4141378725727709, 4: 0.2444910362772304, 5: 0.18913966607868726, 6: 0.1950541637910974, 7: 0.018401302100296765, 8: 0.5798321451149793, 9: 0.2593402140246058, 10: 0.05319842389005923, 11: 0.35964448092439294, 12: 0.11969740565838984, 13: 0.44067082185452217, 14: 0.8537758749785458, 15: 0.06809855385468713, 16: 0.2370536995374401, 17: 0.26743807913383877, 18: 0.1589885904013259, 19: 0.24651538813772098, 20: 0.2586591220905819}, 'average_utilization': 0.2698641135890101, 'load_balance_score': 0.7212195278187666, 'utilization_std_dev': 0.19463126857789587, 'resource_type_metrics': {'smartphone': {'average_utilization': 0.2386740255208757, 'utilization_std_dev': 0.17099828085556146, 'load_balance_score': 0.7164511533350957, 'resource_count': 10}, 'raspberry_pi': {'average_utilization': 0.36837742745410756, 'utilization_std_dev': 0.2803295943201912, 'load_balance_score': 0.7609847222659012, 'resource_count': 5}, 'cloud': {'average_utilization': 0.23373097586018154, 'utilization_std_dev': 0.03877753772374643, 'load_balance_score': 0.16590671211223304, 'resource_count': 5}, 'inter_type_balance': {'standard_deviation': 0.06234052822989146, 'balance_score': 0.22243755135175394}}}\n",
            "failed_tasks_by_type: {}\n",
            "failed_tasks_by_resource: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KJXFkoB4gFZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files Categories"
      ],
      "metadata": {
        "id": "KXe0GrhRY1QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "# Task Specifications\n",
        "TASK_SPECS = {\n",
        "    # Read Tasks\n",
        "    'RT1': {\n",
        "        'instructions': 2_000_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-intensive, memory-intensive',\n",
        "        'example': 'Financial modeling based on large historical dataset'\n",
        "    },\n",
        "    'RT2': {\n",
        "        'instructions': 4_000_000,\n",
        "        'data_size': 0.2,\n",
        "        'description': 'CPU-intensive, memory-light',\n",
        "        'example': 'Computation of NP-hard optimization problem'\n",
        "    },\n",
        "    'RT3': {\n",
        "        'instructions': 200_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-light, memory-intensive',\n",
        "        'example': 'Light database queries on large in-memory dataset'\n",
        "    },\n",
        "    'RT4': {\n",
        "        'instructions': 500_000,\n",
        "        'data_size': 0.5,\n",
        "        'description': 'CPU-light, memory-light',\n",
        "        'example': 'Light video editing'\n",
        "    },\n",
        "    # Write Tasks\n",
        "    'WT1': {\n",
        "        'instructions': 2_000_000,\n",
        "        'data_size': 2,\n",
        "        'description': 'CPU-intensive, I/O-intensive',\n",
        "        'example': 'Complex data write operations'\n",
        "    },\n",
        "    'WT2': {\n",
        "        'instructions': 1_000_000,\n",
        "        'data_size': 0.5,\n",
        "        'description': 'CPU-intensive, I/O-light',\n",
        "        'example': 'Streamlined data writing'\n",
        "    },\n",
        "    'WT3': {\n",
        "        'instructions': 500_000,\n",
        "        'data_size': 5,\n",
        "        'description': 'CPU-light, I/O-intensive',\n",
        "        'example': 'Bulk data transfer'\n",
        "    },\n",
        "    'WT4': {\n",
        "        'instructions': 200_000,\n",
        "        'data_size': 0.2,\n",
        "        'description': 'CPU-light, I/O-light',\n",
        "        'example': 'Simple data logging'\n",
        "    }\n",
        "}\n",
        "\n",
        "class Task:\n",
        "    \"\"\"\n",
        "    Enhanced Task class with precise categorization\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 task_id: int,\n",
        "                 data_size: float,     # in MB\n",
        "                 cpu_required: float,  # in MI (Million Instructions)\n",
        "                 task_details: Dict[str, Any] = None):\n",
        "        self.id = task_id\n",
        "        self.data_size = data_size\n",
        "        self.total_cpu_required = cpu_required\n",
        "        self.remaining_cpu = cpu_required\n",
        "\n",
        "        # Detailed metadata\n",
        "        self.details = task_details or {}\n",
        "        self.task_name = self.details.get('task_name', f'Task_{task_id}')\n",
        "        self.size = self.details.get('size', 'unspecified')\n",
        "        self.type = self.details.get('type', 'unknown')\n",
        "\n",
        "        # Precise task category identification\n",
        "        self.task_category = self._identify_precise_category()\n",
        "\n",
        "        # Task lifecycle tracking\n",
        "        self.arrival_time = 0\n",
        "        self.start_time = 0\n",
        "        self.completion_time = 0\n",
        "        self.status = 'pending'\n",
        "\n",
        "    def _identify_precise_category(self) -> str:\n",
        "        \"\"\"\n",
        "        Identify precise task category based on specifications\n",
        "        \"\"\"\n",
        "        for category, spec in TASK_SPECS.items():\n",
        "            if (abs(self.total_cpu_required - spec['instructions']) < 1000 and\n",
        "                abs(self.data_size - spec['data_size']) < 0.1):\n",
        "                return category\n",
        "        return 'Uncategorized'\n",
        "\n",
        "    def process(self, available_cpu: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process the task with available CPU\n",
        "        Returns processing details\n",
        "        \"\"\"\n",
        "        processed = min(available_cpu, self.remaining_cpu)\n",
        "        self.remaining_cpu -= processed\n",
        "\n",
        "        # Calculate completion percentage\n",
        "        completion_percentage = (self.total_cpu_required - self.remaining_cpu) / self.total_cpu_required * 100\n",
        "\n",
        "        # Update status\n",
        "        if self.remaining_cpu <= 0:\n",
        "            self.status = 'completed'\n",
        "            self.completion_time = time.time()\n",
        "\n",
        "        return {\n",
        "            'processed': processed,\n",
        "            'remaining': self.remaining_cpu,\n",
        "            'status': self.status,\n",
        "            'completion_percentage': completion_percentage\n",
        "        }\n",
        "\n",
        "class Resource:\n",
        "    \"\"\"\n",
        "    Resource class with advanced task tracking\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resource_id: int,\n",
        "                 resource_type: str,\n",
        "                 cpu_rating: int,    # in MI/s (Million Instructions per Second)\n",
        "                 memory: int,        # in GB\n",
        "                 bandwidth: int):    # in MB/s\n",
        "        self.id = resource_id\n",
        "        self.type = resource_type\n",
        "        self.cpu_rating = cpu_rating\n",
        "        self.memory = memory\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        # Advanced task tracking\n",
        "        self.task_queue: List[Task] = []\n",
        "        self.current_tasks: List[Task] = []\n",
        "        self.completed_tasks: List[Task] = []\n",
        "\n",
        "        # Detailed task categorization tracking\n",
        "        self.task_category_counts = defaultdict(int)\n",
        "        self.queue_category_counts = defaultdict(int)\n",
        "        self.task_details = defaultdict(lambda: {\n",
        "            'total_instr': 0,\n",
        "            'total_data_size': 0.0,\n",
        "            'description': '',\n",
        "            'example': ''\n",
        "        })\n",
        "\n",
        "    def enqueue_task(self, task: Task):\n",
        "        \"\"\"\n",
        "        Add task to resource's queue with detailed categorization\n",
        "        \"\"\"\n",
        "        task.queue_position = len(self.task_queue)\n",
        "        self.task_queue.append(task)\n",
        "        self.queue_category_counts[task.task_category] += 1\n",
        "\n",
        "        # Track task details\n",
        "        category = task.task_category\n",
        "        if category in TASK_SPECS:\n",
        "            spec = TASK_SPECS[category]\n",
        "            self.task_details[category]['total_instr'] += task.total_cpu_required\n",
        "            self.task_details[category]['total_data_size'] += task.data_size\n",
        "            self.task_details[category]['description'] = spec['description']\n",
        "            self.task_details[category]['example'] = spec['example']\n",
        "\n",
        "    def process_queue(self, current_time: float) -> Dict:\n",
        "        \"\"\"\n",
        "        Process tasks with detailed categorization\n",
        "        \"\"\"\n",
        "        # Process current tasks\n",
        "        for task in self.current_tasks[:]:\n",
        "            processing_result = task.process(self.cpu_rating)\n",
        "\n",
        "            if processing_result['status'] == 'completed':\n",
        "                self.current_tasks.remove(task)\n",
        "                self.completed_tasks.append(task)\n",
        "\n",
        "                # Track completed task category\n",
        "                self.task_category_counts[task.task_category] += 1\n",
        "\n",
        "        # Move tasks from queue to current tasks\n",
        "        while self.task_queue and len(self.current_tasks) < 5:\n",
        "            next_task = self.task_queue.pop(0)\n",
        "\n",
        "            # Update task timing\n",
        "            next_task.start_time = current_time\n",
        "\n",
        "            # Decrement queue category count\n",
        "            self.queue_category_counts[next_task.task_category] -= 1\n",
        "\n",
        "            self.current_tasks.append(next_task)\n",
        "\n",
        "        return {\n",
        "            'completed_tasks': len(self.completed_tasks),\n",
        "            'current_tasks': len(self.current_tasks),\n",
        "            'queue_length': len(self.task_queue),\n",
        "            'completed_categories': dict(self.task_category_counts),\n",
        "            'queue_categories': {k: v for k, v in self.queue_category_counts.items() if v > 0}\n",
        "        }\n",
        "\n",
        "class DetailedTaskScheduler:\n",
        "    \"\"\"\n",
        "    Scheduler with comprehensive task categorization\n",
        "    \"\"\"\n",
        "    def __init__(self, resources: List[Resource]):\n",
        "        self.resources = resources\n",
        "        self.console = Console()\n",
        "        self.metrics = {\n",
        "            'total_tasks': 0,\n",
        "            'task_distribution': {},\n",
        "        }\n",
        "\n",
        "    def load_tasks_from_json(self, json_path: str) -> List[Task]:\n",
        "        \"\"\"\n",
        "        Load tasks with comprehensive parsing\n",
        "        \"\"\"\n",
        "        with open(json_path, 'r') as f:\n",
        "            task_data = json.load(f)\n",
        "\n",
        "        tasks_list = task_data.get('tasks', [])\n",
        "\n",
        "        tasks = []\n",
        "        for task_dict in tasks_list:\n",
        "            task = Task(\n",
        "                task_id=task_dict.get('id', len(tasks) + 1),\n",
        "                data_size=task_dict.get('data_size', 10),\n",
        "                cpu_required=task_dict.get('instructions', 50000),\n",
        "                task_details=task_dict\n",
        "            )\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def distribute_tasks(self):\n",
        "        \"\"\"\n",
        "        Distribute tasks across resources with categorization\n",
        "        \"\"\"\n",
        "        # Load tasks\n",
        "        tasks = self.load_tasks_from_json(\n",
        "            '/content/drive/My Drive/FCFS_Task_Sets/fcfs_task_set_20250201_201915.json'\n",
        "        )\n",
        "        self.metrics['total_tasks'] = len(tasks)\n",
        "\n",
        "        # Track task distribution\n",
        "        task_distribution = {resource.type: 0 for resource in self.resources}\n",
        "\n",
        "        # Round-robin distribution\n",
        "        resource_index = 0\n",
        "        for task in tasks:\n",
        "            resource = self.resources[resource_index]\n",
        "            resource.enqueue_task(task)\n",
        "            task_distribution[resource.type] += 1\n",
        "            resource_index = (resource_index + 1) % len(self.resources)\n",
        "\n",
        "        self.metrics['task_distribution'] = task_distribution\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def run_simulation(self, max_iterations: int = 1000):\n",
        "        \"\"\"\n",
        "        Run simulation and track task categorization\n",
        "        \"\"\"\n",
        "        # Distribute tasks\n",
        "        self.distribute_tasks()\n",
        "\n",
        "        # Process tasks\n",
        "        for _ in range(max_iterations):\n",
        "            all_completed = True\n",
        "\n",
        "            for resource in self.resources:\n",
        "                resource.process_queue(time.time())\n",
        "\n",
        "                # Check if resource still has tasks\n",
        "                if (len(resource.task_queue) > 0 or\n",
        "                    len(resource.current_tasks) > 0):\n",
        "                    all_completed = False\n",
        "\n",
        "            if all_completed:\n",
        "                break\n",
        "\n",
        "        # Generate comprehensive report\n",
        "        self.generate_final_report()\n",
        "\n",
        "    def generate_final_report(self):\n",
        "        \"\"\"\n",
        "        Generate detailed report of task processing with comprehensive information\n",
        "        \"\"\"\n",
        "        self.console.rule(\"[bold blue]Task Processing Report[/bold blue]\")\n",
        "\n",
        "        for resource in self.resources:\n",
        "            # Create table for resource\n",
        "            resource_table = Table(title=f\"Resource {resource.id}: {resource.type}\")\n",
        "            resource_table.add_column(\"Task Category\", style=\"cyan\")\n",
        "            resource_table.add_column(\"Completed Tasks\", style=\"green\")\n",
        "            resource_table.add_column(\"Remaining in Queue\", style=\"red\")\n",
        "            resource_table.add_column(\"Total Instructions (MI)\", style=\"magenta\")\n",
        "            resource_table.add_column(\"Total Data Size (GB)\", style=\"yellow\")\n",
        "            resource_table.add_column(\"Description\", style=\"blue\")\n",
        "\n",
        "            # Combine all task categories\n",
        "            all_categories = sorted(set(list(resource.task_category_counts.keys()) +\n",
        "                                 list(resource.queue_category_counts.keys())))\n",
        "\n",
        "            # Populate table\n",
        "            for category in all_categories:\n",
        "                completed = resource.task_category_counts.get(category, 0)\n",
        "                queued = resource.queue_category_counts.get(category, 0)\n",
        "\n",
        "                # Get task details\n",
        "                details = resource.task_details.get(category, {\n",
        "                    'total_instr': 0,\n",
        "                    'total_data_size': 0.0,\n",
        "                    'description': 'N/A',\n",
        "                    'example': ''\n",
        "                })\n",
        "\n",
        "                resource_table.add_row(\n",
        "                    category,\n",
        "                    str(completed),\n",
        "                    str(queued),\n",
        "                    f\"{details['total_instr']:,}\",\n",
        "                    f\"{details['total_data_size']:.2f}\",\n",
        "                    details['description']\n",
        "                )\n",
        "\n",
        "            # Print resource-specific table\n",
        "            self.console.print(resource_table)\n",
        "            self.console.print(\"\\n\")\n",
        "\n",
        "def create_original_resources():\n",
        "    \"\"\"\n",
        "    Create resources exactly matching the original configuration table\n",
        "    \"\"\"\n",
        "    return [\n",
        "        # Raspberry Pi Edge Node\n",
        "        Resource(\n",
        "            resource_id=1,\n",
        "            resource_type=\"Edge_Raspberry_Pi\",\n",
        "            cpu_rating=80000,    # 80,000 MI/s\n",
        "            memory=1,            # 1 GB\n",
        "            bandwidth=5          # 5 MB/s\n",
        "        ),\n",
        "\n",
        "        # Smartphone Edge Node\n",
        "        Resource(\n",
        "            resource_id=2,\n",
        "            resource_type=\"Edge_Smartphone\",\n",
        "            cpu_rating=400000,   # 400,000 MI/s\n",
        "            memory=4,            # 4 GB\n",
        "            bandwidth=20         # 20 MB/s\n",
        "        ),\n",
        "\n",
        "        # Cloud Host\n",
        "        Resource(\n",
        "            resource_id=3,\n",
        "            resource_type=\"Cloud_Host\",\n",
        "            cpu_rating=1000000,  # 1,000,000 MI/s\n",
        "            memory=32,           # 32 GB\n",
        "            bandwidth=80         # 80 MB/s\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def main():\n",
        "    # Create resources\n",
        "    resources = create_original_resources()\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = DetailedTaskScheduler(resources)\n",
        "\n",
        "    # Run simulation\n",
        "    scheduler.run_simulation()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "-ffR1_EIY31s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task Generator mixed large and small files\n"
      ],
      "metadata": {
        "id": "lgMcsRNxJeIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "class TaskGenerator:\n",
        "    def __init__(self):\n",
        "        # Detailed task configurations with more specific characteristics\n",
        "        self.task_configs = {\n",
        "            # Large Read Tasks\n",
        "            'large_read_tasks': {\n",
        "                'RT1': {\n",
        "                    'instr': 2_000_000,  # Million Instructions\n",
        "                    'data': 5,           # GB\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'memory_intensity': 'high',\n",
        "                    'task_class': 'CPU-intensive, memory-intensive'\n",
        "                },\n",
        "                'RT2': {\n",
        "                    'instr': 4_000_000,\n",
        "                    'data': 0.2,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'memory_intensity': 'low',\n",
        "                    'task_class': 'CPU-intensive, memory-light'\n",
        "                }\n",
        "            },\n",
        "            # Large Write Tasks\n",
        "            'large_write_tasks': {\n",
        "                'WT1': {\n",
        "                    'instr': 2_000_000,\n",
        "                    'data': 2,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'io_intensity': 'high',\n",
        "                    'task_class': 'CPU-intensive, I/O-intensive'\n",
        "                },\n",
        "                'WT2': {\n",
        "                    'instr': 1_000_000,\n",
        "                    'data': 0.5,\n",
        "                    'cpu_intensity': 'high',\n",
        "                    'io_intensity': 'low',\n",
        "                    'task_class': 'CPU-intensive, I/O-light'\n",
        "                }\n",
        "            },\n",
        "            # Small Read Tasks\n",
        "            'small_read_tasks': {\n",
        "                'RT3': {\n",
        "                    'instr': 200_000,\n",
        "                    'data': 5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'memory_intensity': 'high',\n",
        "                    'task_class': 'CPU-light, memory-intensive'\n",
        "                },\n",
        "                'RT4': {\n",
        "                    'instr': 500_000,\n",
        "                    'data': 0.5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'memory_intensity': 'low',\n",
        "                    'task_class': 'CPU-light, memory-light'\n",
        "                }\n",
        "            },\n",
        "            # Small Write Tasks\n",
        "            'small_write_tasks': {\n",
        "                'WT3': {\n",
        "                    'instr': 500_000,\n",
        "                    'data': 5,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'io_intensity': 'high',\n",
        "                    'task_class': 'CPU-light, I/O-intensive'\n",
        "                },\n",
        "                'WT4': {\n",
        "                    'instr': 200_000,\n",
        "                    'data': 0.2,\n",
        "                    'cpu_intensity': 'low',\n",
        "                    'io_intensity': 'low',\n",
        "                    'task_class': 'CPU-light, I/O-light'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_large_task_set(self, total_tasks: int, large_task_percentage: float = 0.7) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a comprehensive set of tasks with detailed categorization\n",
        "        \"\"\"\n",
        "        # Calculate number of each type\n",
        "        num_large_tasks = int(total_tasks * large_task_percentage)\n",
        "        num_small_tasks = total_tasks - num_large_tasks\n",
        "\n",
        "        # Generate tasks\n",
        "        tasks = []\n",
        "        task_id = 1\n",
        "\n",
        "        # Generate large tasks\n",
        "        large_tasks = self._generate_tasks(num_large_tasks, \"large\", task_id)\n",
        "        tasks.extend(large_tasks)\n",
        "        task_id += num_large_tasks\n",
        "\n",
        "        # Generate small tasks\n",
        "        small_tasks = self._generate_tasks(num_small_tasks, \"small\", task_id)\n",
        "        tasks.extend(small_tasks)\n",
        "\n",
        "        # Shuffle tasks to randomize their order\n",
        "        random.shuffle(tasks)\n",
        "\n",
        "        # Categorize tasks\n",
        "        categorized_tasks = self._categorize_tasks(tasks)\n",
        "\n",
        "        # Prepare task set metadata\n",
        "        task_set_metadata = {\n",
        "            \"total_tasks\": total_tasks,\n",
        "            \"large_task_percentage\": large_task_percentage,\n",
        "            \"large_tasks\": num_large_tasks,\n",
        "            \"small_tasks\": num_small_tasks,\n",
        "            \"task_distribution\": {\n",
        "                \"read_tasks\": sum(1 for task in tasks if task.get('type') == 'read'),\n",
        "                \"write_tasks\": sum(1 for task in tasks if task.get('type') == 'write')\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"metadata\": task_set_metadata,\n",
        "            \"categorized_tasks\": categorized_tasks,\n",
        "            \"raw_tasks\": tasks\n",
        "        }\n",
        "\n",
        "    def _generate_tasks(self, num_tasks: int, size: str, start_id: int) -> List[Dict]:\n",
        "        \"\"\"Generate tasks of a specific size\"\"\"\n",
        "        tasks = []\n",
        "\n",
        "        for i in range(num_tasks):\n",
        "            # Randomly choose between read and write tasks (50-50 distribution)\n",
        "            task_type = random.choice([\"read\", \"write\"])\n",
        "\n",
        "            # Get appropriate config based on size and type\n",
        "            config_key = f\"{size}_{task_type}_tasks\"\n",
        "            possible_tasks = self.task_configs[config_key]\n",
        "\n",
        "            # Randomly select a task configuration\n",
        "            task_name = random.choice(list(possible_tasks.keys()))\n",
        "            task_config = possible_tasks[task_name]\n",
        "\n",
        "            # Create task dictionary\n",
        "            task = {\n",
        "                \"id\": start_id + i,\n",
        "                \"task_name\": task_name,\n",
        "                \"size\": size,\n",
        "                \"type\": task_type,\n",
        "                \"instructions\": task_config['instr'],\n",
        "                \"data_size\": task_config['data'],\n",
        "                \"arrival_time\": random.randint(0, 1000),  # Random arrival time\n",
        "                \"status\": \"pending\",\n",
        "                **{k: v for k, v in task_config.items() if k not in ['instr', 'data']}\n",
        "            }\n",
        "            tasks.append(task)\n",
        "\n",
        "        return tasks\n",
        "\n",
        "    def _categorize_tasks(self, tasks: List[Dict]) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"\n",
        "        Categorize tasks by their specific characteristics\n",
        "        \"\"\"\n",
        "        categorized = defaultdict(list)\n",
        "\n",
        "        # Categorize by task names (RT1, RT2, etc.)\n",
        "        for task in tasks:\n",
        "            categorized[task['task_name']].append(task)\n",
        "\n",
        "        return dict(categorized)\n",
        "\n",
        "def generate_and_save_task_set(total_tasks: int = 1500, large_task_percentage: float = 0.7):\n",
        "    \"\"\"\n",
        "    Generate task set, save to file, and print detailed categorization\n",
        "    \"\"\"\n",
        "    # Create task generator\n",
        "    generator = TaskGenerator()\n",
        "\n",
        "    # Generate tasks\n",
        "    task_set = generator.generate_large_task_set(\n",
        "        total_tasks=total_tasks,\n",
        "        large_task_percentage=large_task_percentage\n",
        "    )\n",
        "\n",
        "    # Print detailed categorization\n",
        "    print(\"\\n--- DETAILED TASK CATEGORIZATION ---\")\n",
        "    for task_category, tasks in task_set['categorized_tasks'].items():\n",
        "        print(f\"\\n{task_category} Tasks:\")\n",
        "        print(f\"Total {task_category} Tasks: {len(tasks)}\")\n",
        "        print(\"Sample Task Details:\")\n",
        "        for task in tasks[:3]:  # Print first 3 tasks of each category\n",
        "            print(\"\\nTask Details:\")\n",
        "            for key, value in task.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Print overall metadata\n",
        "    print(\"\\n--- TASK SET METADATA ---\")\n",
        "    print(json.dumps(task_set['metadata'], indent=2))\n",
        "\n",
        "    # Save to JSON\n",
        "    save_path = 'fcfs_task_set.json'\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(task_set, f, indent=2)\n",
        "\n",
        "    print(f\"\\nFull task set saved to: {save_path}\")\n",
        "\n",
        "    return task_set\n",
        "\n",
        "# Run the task generation\n",
        "if __name__ == \"__main__\":\n",
        "    generate_and_save_task_set()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyuPsyhrJjJw",
        "outputId": "b2a2fd3f-ed2a-40af-adea-7bae6552b53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DETAILED TASK CATEGORIZATION ---\n",
            "\n",
            "WT1 Tasks:\n",
            "Total WT1 Tasks: 270\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 156\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 401\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 951\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 637\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 123\n",
            "task_name: WT1\n",
            "size: large\n",
            "type: write\n",
            "instructions: 2000000\n",
            "data_size: 2\n",
            "arrival_time: 52\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: high\n",
            "task_class: CPU-intensive, I/O-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "RT2 Tasks:\n",
            "Total RT2 Tasks: 253\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 462\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 656\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 718\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 59\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1019\n",
            "task_name: RT2\n",
            "size: large\n",
            "type: read\n",
            "instructions: 4000000\n",
            "data_size: 0.2\n",
            "arrival_time: 706\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: low\n",
            "task_class: CPU-intensive, memory-light\n",
            "--------------------------------------------------\n",
            "\n",
            "WT4 Tasks:\n",
            "Total WT4 Tasks: 101\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1157\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 22\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 1470\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 883\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 1126\n",
            "task_name: WT4\n",
            "size: small\n",
            "type: write\n",
            "instructions: 200000\n",
            "data_size: 0.2\n",
            "arrival_time: 384\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: low\n",
            "task_class: CPU-light, I/O-light\n",
            "--------------------------------------------------\n",
            "\n",
            "RT3 Tasks:\n",
            "Total RT3 Tasks: 122\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1463\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 478\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1311\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 562\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1208\n",
            "task_name: RT3\n",
            "size: small\n",
            "type: read\n",
            "instructions: 200000\n",
            "data_size: 5\n",
            "arrival_time: 918\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: high\n",
            "task_class: CPU-light, memory-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "RT1 Tasks:\n",
            "Total RT1 Tasks: 258\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 999\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 216\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 219\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 64\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 338\n",
            "task_name: RT1\n",
            "size: large\n",
            "type: read\n",
            "instructions: 2000000\n",
            "data_size: 5\n",
            "arrival_time: 497\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "memory_intensity: high\n",
            "task_class: CPU-intensive, memory-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "WT2 Tasks:\n",
            "Total WT2 Tasks: 269\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 278\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 901\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 629\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 743\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "\n",
            "Task Details:\n",
            "id: 773\n",
            "task_name: WT2\n",
            "size: large\n",
            "type: write\n",
            "instructions: 1000000\n",
            "data_size: 0.5\n",
            "arrival_time: 995\n",
            "status: pending\n",
            "cpu_intensity: high\n",
            "io_intensity: low\n",
            "task_class: CPU-intensive, I/O-light\n",
            "--------------------------------------------------\n",
            "\n",
            "RT4 Tasks:\n",
            "Total RT4 Tasks: 114\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1158\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 89\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1065\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 670\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "\n",
            "Task Details:\n",
            "id: 1186\n",
            "task_name: RT4\n",
            "size: small\n",
            "type: read\n",
            "instructions: 500000\n",
            "data_size: 0.5\n",
            "arrival_time: 225\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "memory_intensity: low\n",
            "task_class: CPU-light, memory-light\n",
            "--------------------------------------------------\n",
            "\n",
            "WT3 Tasks:\n",
            "Total WT3 Tasks: 113\n",
            "Sample Task Details:\n",
            "\n",
            "Task Details:\n",
            "id: 1252\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 549\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1202\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 598\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "\n",
            "Task Details:\n",
            "id: 1062\n",
            "task_name: WT3\n",
            "size: small\n",
            "type: write\n",
            "instructions: 500000\n",
            "data_size: 5\n",
            "arrival_time: 930\n",
            "status: pending\n",
            "cpu_intensity: low\n",
            "io_intensity: high\n",
            "task_class: CPU-light, I/O-intensive\n",
            "--------------------------------------------------\n",
            "\n",
            "--- TASK SET METADATA ---\n",
            "{\n",
            "  \"total_tasks\": 1500,\n",
            "  \"large_task_percentage\": 0.7,\n",
            "  \"large_tasks\": 1050,\n",
            "  \"small_tasks\": 450,\n",
            "  \"task_distribution\": {\n",
            "    \"read_tasks\": 747,\n",
            "    \"write_tasks\": 753\n",
            "  }\n",
            "}\n",
            "\n",
            "Full task set saved to: fcfs_task_set.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1HSMks9EdDf"
      },
      "source": [
        "Once we have our stopping criterion, we can finally run our simulation by creating an instance of the `Simulator` class, loading a dataset, and calling the `run_model()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hShU1WhxEdDg",
        "outputId": "98115fcf-1658-40b5-d80d-e191cecf60d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Service_1. Host: EdgeServer_1\n",
            "Service_2. Host: EdgeServer_1\n",
            "Service_3. Host: EdgeServer_1\n",
            "Service_4. Host: EdgeServer_1\n",
            "Service_5. Host: EdgeServer_1\n",
            "Service_6. Host: EdgeServer_1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Creating a Simulator object\n",
        "simulator = Simulator(\n",
        "    tick_duration=1,\n",
        "    tick_unit=\"seconds\",\n",
        "    stopping_criterion=stopping_criterion,\n",
        "    resource_management_algorithm=my_algorithm,\n",
        ")\n",
        "\n",
        "# Loading a sample dataset from GitHub\n",
        "simulator.initialize(input_file=\"https://raw.githubusercontent.com/EdgeSimPy/edgesimpy-tutorials/master/datasets/sample_dataset2.json\")\n",
        "\n",
        "# Executing the simulation\n",
        "simulator.run_model()\n",
        "\n",
        "# Checking the placement output\n",
        "for service in Service.all():\n",
        "    print(f\"{service}. Host: {service.server}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "50cb211c4021f4a25a142368b69ce4d994f94aff73dc90314b4ffb0c06ad024a"
      }
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8055e298b5e943efaecc5a10c8cdc4b4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_954db004304d487d8c8fd886c3b31990",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[3m                         Live Resource Processing Status                         \u001b[0m\n\u001b[1;32m           ╷             ╷              ╷          ╷       ╷           ╷         \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mResource\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mCurrent Task\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mProgress\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mQueue\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mCompleted\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mFailed\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ══════════╪═════════════╪══════════════╪══════════╪═══════╪═══════════╪════════ \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m1       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_1     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m261 (WT1)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m99.0%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m5    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m6        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m13    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m2       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_2     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m82 (RT2)    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m99.5%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m20   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m4        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m3       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_3     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m12       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m13    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m4       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_4     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m25       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m5       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_5     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m245 (WT1)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m99.0%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m6    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m6        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m12    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m6       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_6     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m106 (RT2)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m74.5%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m19   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m5        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m7       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_7     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m13       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m12    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m8       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_8     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m25       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m9       \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_9     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m269 (WT1)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m99.0%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m5    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m6        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m13    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m10      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mEdge_10    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m90 (RT2)    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m99.5%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m20   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m4        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m11      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_1\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m231 (WT3)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m59.2%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m6    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m5        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m13    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m12      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_2\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m152 (WT4)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m98.0%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m17   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m7        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m13      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_3\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m53 (WT1)    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m39.8%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m11   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m1        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m12    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m14      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_4\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m34 (RT2)    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m44.9%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m23   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m1        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m15      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_5\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m215 (WT3)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m59.2%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m7    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m5        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m12    \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m16      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_1    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m25       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m17      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_2    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m357 (WT1)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m47.5%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m7    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m17       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m18      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_3    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m278 (WT2)   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m95.0%   \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m11   \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m13       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m19      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_4    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m25       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m20      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_5    \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone        \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0    \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m25       \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m           ╵             ╵              ╵          ╵       ╵           ╵         \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Live Resource Processing Status                         </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">           ╷             ╷              ╷          ╷       ╷           ╷         </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Resource </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Current Task </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Progress </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Queue </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Completed </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Failed </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ══════════╪═════════════╪══════════════╪══════════╪═══════╪═══════════╪════════ </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 1        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_1      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 261 (WT1)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 99.0%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 5     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 6         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 2        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_2      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 82 (RT2)     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 99.5%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 20    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 4         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 3        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_3      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 12        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 4        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_4      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 25        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 5        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_5      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 245 (WT1)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 99.0%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 6     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 6         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 6        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_6      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 106 (RT2)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 74.5%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 19    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 5         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 7        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_7      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 13        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 8        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_8      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 25        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 9        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_9      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 269 (WT1)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 99.0%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 5     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 6         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 10       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Edge_10     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 90 (RT2)     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 99.5%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 20    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 4         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 11       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_1 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 231 (WT3)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 59.2%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 6     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 5         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 13     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 12       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_2 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 152 (WT4)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 98.0%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 17    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 7         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 13       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_3 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 53 (WT1)     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 39.8%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 11    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 1         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 14       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_4 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 34 (RT2)     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 44.9%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 23    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 1         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 15       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_5 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 215 (WT3)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 59.2%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 7     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 5         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 12     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 16       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_1     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 25        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 17       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_2     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 357 (WT1)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 47.5%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 7     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 17        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 18       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_3     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 278 (WT2)    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 95.0%    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 11    │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 13        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 19       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_4     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 25        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ──────────┼─────────────┼──────────────┼──────────┼───────┼───────────┼──────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 20       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_5     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0     │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 25        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">           ╵             ╵              ╵          ╵       ╵           ╵         </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "954db004304d487d8c8fd886c3b31990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18cf40d967244298ec27fa88194191f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3f9c1b89a3e04f80a800678c1f30c694",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32m╭─\u001b[0m\u001b[32m─\u001b[0m\u001b[32m Resource 1: Edge_Raspberry_Pi \u001b[0m\u001b[32m──\u001b[0m\u001b[32m─╮\u001b[0m\u001b[32m╭─\u001b[0m\u001b[32m──\u001b[0m\u001b[32m Resource 2: Edge_Smartphone \u001b[0m\u001b[32m───\u001b[0m\u001b[32m─╮\u001b[0m\u001b[32m╭─\u001b[0m\u001b[32m─────\u001b[0m\u001b[32m Resource 3: Cloud_Host \u001b[0m\u001b[32m──────\u001b[0m\u001b[32m─╮\u001b[0m\n\u001b[32m│\u001b[0m ┌────────────────────────────────┐ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m ┌────────────────────────────────┐ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m ┌─────────────────────────────────┐ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[1mResource Details\u001b[0m               │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mResource Details\u001b[0m               │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mResource Details\u001b[0m                │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[36mType:\u001b[0m Edge_Raspberry_Pi        │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[36mType:\u001b[0m Edge_Smartphone          │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[36mType:\u001b[0m Cloud_Host                │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[32mCPU Rating:\u001b[0m 80000 MI/s         │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCPU Rating:\u001b[0m 400000 MI/s        │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCPU Rating:\u001b[0m 1000000 MI/s        │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mMemory:\u001b[0m 1 GB                   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[34mMemory:\u001b[0m 4 GB                   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[34mMemory:\u001b[0m 32 GB                   │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[33mBandwidth:\u001b[0m 5 MB/s              │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[33mBandwidth:\u001b[0m 20 MB/s             │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[33mBandwidth:\u001b[0m 80 MB/s              │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │                                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │                                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │                                 │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[1mUtilization Metrics\u001b[0m            │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mUtilization Metrics\u001b[0m            │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mUtilization Metrics\u001b[0m             │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[32mCPU Usage:\u001b[0m 100.00%             │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCPU Usage:\u001b[0m 0.00% (0.00/400000  │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCPU Usage:\u001b[0m 0.00% (0.00/1000000  │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ (5500000.00/80000 MI/s)        │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ MI/s)                          │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ MI/s)                           │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │                                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[34mMemory Usage:\u001b[0m 0.00% (0.00/4    │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[34mMemory Usage:\u001b[0m 0.00% (0.00/32    │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[1mCurrent Tasks\u001b[0m                  │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ GB)                            │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ GB)                             │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1158 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │                                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │                                 │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (100.00%)  │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mTask Processing\u001b[0m                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[1mTask Processing\u001b[0m                 │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 437 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCompleted Tasks:\u001b[0m 265           │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[32mCompleted Tasks:\u001b[0m 500            │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (94.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[33mCurrent Tasks:\u001b[0m 0               │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[33mCurrent Tasks:\u001b[0m 0                │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1179 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[31mQueue Length:\u001b[0m 0                │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m │ \u001b[31mQueue Length:\u001b[0m 0                 │ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (92.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m └────────────────────────────────┘ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m └─────────────────────────────────┘ \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 309 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (84.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 481 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (82.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1056 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (80.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 32 (RT2):\u001b[0m Processed       │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (76.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 832 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (76.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 870 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (74.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 824 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (74.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 199 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (72.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 934 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (70.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 182 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (68.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 663 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (66.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 174 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (66.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 171 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (64.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1257 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (62.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1078 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (58.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 929 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (54.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1365 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (54.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 7 (RT2):\u001b[0m Processed        │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (54.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1337 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (52.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1254 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (50.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 35 (RT2):\u001b[0m Processed       │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (44.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1013 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (42.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1341 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (42.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1007 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (42.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 154 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (40.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 436 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (38.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 105 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (36.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 844 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (34.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1300 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (32.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1346 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (26.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 43 (RT2):\u001b[0m Processed       │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (26.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1440 (RT2):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (24.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 899 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (22.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 728 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (22.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 627 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (20.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 997 (RT4):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 20000.00/500000 MI (100.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 942 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (14.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 25 (RT4):\u001b[0m Processed       │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 20000.00/500000 MI (100.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 726 (RT2):\u001b[0m Processed      │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 80000.00/4000000 MI (14.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ \u001b[34mTask 1199 (RT4):\u001b[0m Processed     │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m│\u001b[0m │ 20000.00/500000 MI (100.00%)   │ \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                    \u001b[32m│\u001b[0m\u001b[32m│\u001b[0m                                     \u001b[32m│\u001b[0m\n\u001b[32m╰────────────────────────────────────╯\u001b[0m\u001b[32m╰────────────────────────────────────╯\u001b[0m\u001b[32m╰─────────────────────────────────────╯\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">╭── Resource 1: Edge_Raspberry_Pi ───╮╭─── Resource 2: Edge_Smartphone ────╮╭────── Resource 3: Cloud_Host ───────╮</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> ┌────────────────────────────────┐ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> ┌────────────────────────────────┐ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> ┌─────────────────────────────────┐ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"font-weight: bold\">Resource Details</span>               │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Resource Details</span>               │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Resource Details</span>                │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">Type:</span> Edge_Raspberry_Pi        │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">Type:</span> Edge_Smartphone          │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">Type:</span> Cloud_Host                │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Rating:</span> 80000 MI/s         │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Rating:</span> 400000 MI/s        │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Rating:</span> 1000000 MI/s        │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Memory:</span> 1 GB                   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Memory:</span> 4 GB                   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Memory:</span> 32 GB                   │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #808000; text-decoration-color: #808000\">Bandwidth:</span> 5 MB/s              │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #808000; text-decoration-color: #808000\">Bandwidth:</span> 20 MB/s             │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #808000; text-decoration-color: #808000\">Bandwidth:</span> 80 MB/s              │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │                                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │                                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │                                 │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"font-weight: bold\">Utilization Metrics</span>            │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Utilization Metrics</span>            │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Utilization Metrics</span>             │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Usage:</span> 100.00%             │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Usage:</span> 0.00% (0.00/400000  │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">CPU Usage:</span> 0.00% (0.00/1000000  │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ (5500000.00/80000 MI/s)        │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ MI/s)                          │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ MI/s)                           │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │                                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Memory Usage:</span> 0.00% (0.00/4    │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Memory Usage:</span> 0.00% (0.00/32    │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"font-weight: bold\">Current Tasks</span>                  │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ GB)                            │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ GB)                             │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1158 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │                                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │                                 │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (100.00%)  │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Task Processing</span>                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"font-weight: bold\">Task Processing</span>                 │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 437 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">Completed Tasks:</span> 265           │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">Completed Tasks:</span> 500            │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (94.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #808000; text-decoration-color: #808000\">Current Tasks:</span> 0               │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #808000; text-decoration-color: #808000\">Current Tasks:</span> 0                │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1179 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #800000; text-decoration-color: #800000\">Queue Length:</span> 0                │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> │ <span style=\"color: #800000; text-decoration-color: #800000\">Queue Length:</span> 0                 │ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (92.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> └────────────────────────────────┘ <span style=\"color: #008000; text-decoration-color: #008000\">││</span> └─────────────────────────────────┘ <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 309 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (84.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 481 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (82.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1056 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (80.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 32 (RT2):</span> Processed       │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (76.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 832 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (76.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 870 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (74.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 824 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (74.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 199 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (72.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 934 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (70.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 182 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (68.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 663 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (66.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 174 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (66.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 171 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (64.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1257 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (62.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1078 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (58.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 929 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (54.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1365 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (54.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 7 (RT2):</span> Processed        │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (54.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1337 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (52.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1254 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (50.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 35 (RT2):</span> Processed       │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (44.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1013 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (42.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1341 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (42.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1007 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (42.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 154 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (40.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 436 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (38.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 105 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (36.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 844 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (34.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1300 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (32.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1346 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (26.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 43 (RT2):</span> Processed       │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (26.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1440 (RT2):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (24.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 899 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (22.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 728 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (22.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 627 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (20.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 997 (RT4):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 20000.00/500000 MI (100.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 942 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (14.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 25 (RT4):</span> Processed       │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 20000.00/500000 MI (100.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 726 (RT2):</span> Processed      │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 80000.00/4000000 MI (14.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ <span style=\"color: #000080; text-decoration-color: #000080\">Task 1199 (RT4):</span> Processed     │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">│</span> │ 20000.00/500000 MI (100.00%)   │ <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                    <span style=\"color: #008000; text-decoration-color: #008000\">││</span>                                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">╰────────────────────────────────────╯╰────────────────────────────────────╯╰─────────────────────────────────────╯</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "3f9c1b89a3e04f80a800678c1f30c694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4283648150344b50b65cdf635d28f1a6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4731897c94b149858d9443630f70fe2d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[3m                                          Live Resource Processing Status                                          \u001b[0m\n\u001b[1;32m          ╷              ╷         ╷                    ╷            ╷            ╷          ╷         ╷           \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;35m         \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m              \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mCurrent\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m                    \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m            \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m            \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m          \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m         \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m          \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mResour…\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType        \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mTask   \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mPhase             \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mProgress  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mData Size \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mQueue   \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mComple…\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mFailed  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ═════════╪══════════════╪═════════╪════════════════════╪════════════╪════════════╪══════════╪═════════╪══════════ \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m1      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_1\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m12     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m2      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_2\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m9      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m3      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_3\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m9      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m4      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_4\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m9      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m5      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_5\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m13     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m6      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_6\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m11     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m7      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_7\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m8      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m8      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_8\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m11     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m9      \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_9\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m9      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m10     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mSmartphone_…\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m6      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m11     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_1 \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m4      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m12     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_2 \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m7      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m13     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_3 \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m190    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mTRANSFERRING_OUTP…\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m98.8%     \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m↓0.5GB    \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m6      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m         \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m              \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m(WT2)  \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m                    \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m            \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m            \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m          \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m         \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m          \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m14     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_4 \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m11     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m15     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mRaspberry_5 \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m1      \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m16     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_1     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m15     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m17     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_2     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m17     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m18     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_3     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m10     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m19     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_4     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m13     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── \u001b[0m\n\u001b[1;32m \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m20     \u001b[0m\u001b[1;34m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mCloud_5     \u001b[0m\u001b[1;36m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mNone   \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32mIdle              \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31mN/A       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33mN/A       \u001b[0m\u001b[1;33m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m0       \u001b[0m\u001b[1;32m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m18     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;32m│\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m0       \u001b[0m\u001b[1;31m \u001b[0m\u001b[1;32m \u001b[0m\n\u001b[1;32m          ╵              ╵         ╵                    ╵            ╵            ╵          ╵         ╵           \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                          Live Resource Processing Status                                          </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">          ╷              ╷         ╷                    ╷            ╷            ╷          ╷         ╷           </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">              </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Current </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">          </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">          </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Resour… </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Task    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Phase              </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Progress   </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Data Size  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Queue    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Comple… </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Failed   </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ═════════╪══════════════╪═════════╪════════════════════╪════════════╪════════════╪══════════╪═════════╪══════════ </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 1       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_1 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 12      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 2       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_2 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 9       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 3       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_3 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 9       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 4       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_4 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 9       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 5       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_5 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 13      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 6       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_6 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 11      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 7       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_7 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 8       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 8       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_8 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 11      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 9       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_9 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 9       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 10      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Smartphone_… </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 6       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 11      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_1  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 4       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 12      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_2  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 7       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 13      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_3  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 190     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ TRANSFERRING_OUTP… │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 98.8%      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ↓0.5GB     </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 6       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">              </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> (WT2)   </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│                    │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">            </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│          │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">         </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">          </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 14      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_4  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 11      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 15      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Raspberry_5  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 1       </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 16      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_1      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 15      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 17      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_2      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 17      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 18      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_3      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 10      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 19      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_4      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 13      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> ─────────┼──────────────┼─────────┼────────────────────┼────────────┼────────────┼──────────┼─────────┼────────── </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 20      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Cloud_5      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> None    </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ Idle               │</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> N/A        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│ 0        │</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 18      </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">│</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> 0        </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> </span>\n<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">          ╵              ╵         ╵                    ╵            ╵            ╵          ╵         ╵           </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "4731897c94b149858d9443630f70fe2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}